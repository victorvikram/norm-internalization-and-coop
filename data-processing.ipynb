{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6419b674",
   "metadata": {},
   "source": [
    "# This notebook processes the data output from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96d643",
   "metadata": {},
   "source": [
    "## basic utility functions and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0fc86d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import patches\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import defaultdict\n",
    "import statsmodels.api as sm\n",
    "import pickle as pkl\n",
    "from scipy import stats\n",
    "import pyvis.network as pn\n",
    "import importlib\n",
    "\n",
    "importlib.reload(pn)\n",
    "\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "\"\"\"\n",
    "calculates the cooperation levels for all agents and specifically for non-civic agents, spatial model\n",
    "\"\"\"\n",
    "def total_coop_level_spatial(dat):\n",
    "    civ_coop = 0 if dat[\"civ\"][\"pop\"] == 0 else dat[\"civ\"][\"pop\"]*dat[\"civ\"][\"coop\"]\n",
    "    coo_coop = 0 if dat[\"coo\"][\"pop\"] == 0 else dat[\"coo\"][\"pop\"]*dat[\"coo\"][\"coop\"]\n",
    "    final_civ_coop = civ_coop + coo_coop\n",
    "    sel_coop = 0 if dat[\"sel\"][\"pop\"] == 0 else dat[\"sel\"][\"pop\"]*dat[\"sel\"][\"coop\"]\n",
    "    sta_coop = 0 if dat[\"sta\"][\"pop\"] == 0 else dat[\"sta\"][\"pop\"]*dat[\"sta\"][\"coop\"]\n",
    "    \n",
    "    return final_civ_coop + sel_coop + sta_coop, sel_coop + sta_coop\n",
    "\n",
    "\"\"\"\n",
    "calculates cooperation levels for all agents and non-civic agents, abstract model\n",
    "\"\"\"\n",
    "def total_coop_level_pinhead(dat):\n",
    "    mis_coop = 0 if dat[\"mis\"][\"pop\"] == 0 else dat[\"mis\"][\"pop\"]*dat[\"mis\"][\"coop\"]\n",
    "    dec_coop = 0 if dat[\"dec\"][\"pop\"] == 0 else dat[\"dec\"][\"pop\"]*dat[\"dec\"][\"coop\"]\n",
    "    cit_coop = 0 if dat[\"cit\"][\"pop\"] == 0 else dat[\"cit\"][\"pop\"]*dat[\"cit\"][\"coop\"]\n",
    "    sai_coop = 0 if dat[\"sai\"][\"pop\"] == 0 else dat[\"sai\"][\"pop\"]*dat[\"sai\"][\"coop\"]\n",
    "    \n",
    "    civ_coop = 0 if dat[\"civ\"][\"pop\"] == 0 else dat[\"civ\"][\"pop\"]*dat[\"civ\"][\"coop\"]\n",
    "    sel_coop = 0 if dat[\"sel\"][\"pop\"] == 0 else dat[\"sel\"][\"pop\"]*dat[\"sel\"][\"coop\"]\n",
    "    sta_coop = 0 if dat[\"sta\"][\"pop\"] == 0 else dat[\"sta\"][\"pop\"]*dat[\"sta\"][\"coop\"]\n",
    "    \n",
    "    total_coop = mis_coop + dec_coop + cit_coop + sai_coop + civ_coop + sel_coop + sta_coop\n",
    "    badboi_coop = dec_coop + mis_coop + sel_coop + sta_coop\n",
    "    \n",
    "    return total_coop, badboi_coop\n",
    "\n",
    "\"\"\"\n",
    "gets total population and the non civic population\n",
    "\"\"\"\n",
    "def population(dat):\n",
    "    \n",
    "    if \"cit\" in dat:\n",
    "        addition_total = dat[\"cit\"][\"pop\"] + dat[\"sai\"][\"pop\"] + dat[\"dec\"][\"pop\"] + dat[\"mis\"][\"pop\"]\n",
    "        addition_nonciv = dat[\"dec\"][\"pop\"] + dat[\"mis\"][\"pop\"]\n",
    "    else:\n",
    "        addition_total = dat[\"coo\"][\"pop\"]\n",
    "        addition_nonciv = 0\n",
    "    \n",
    "    return dat[\"civ\"][\"pop\"] + dat[\"sel\"][\"pop\"] + dat[\"sta\"][\"pop\"] + addition_total, dat[\"sel\"][\"pop\"] + dat[\"sta\"][\"pop\"] + addition_nonciv\n",
    "\n",
    "\"\"\"\n",
    "gets total coop level and the coop level of non civic agents\n",
    "\"\"\"\n",
    "def total_coop_level(dat):\n",
    "    if \"cit\" in dat:\n",
    "        return total_coop_level_pinhead(dat) # this is the pinhead model\n",
    "    else:\n",
    "        return total_coop_level_spatial(dat)\n",
    "\n",
    "\"\"\"\n",
    "gets the name of the distribution from the fraction of civic agents\n",
    "\"\"\"\n",
    "def lookup_distrib_name_spatial(num):\n",
    "    if num == 0.00:\n",
    "        return \"noconscience\"\n",
    "    elif num == 0.02:\n",
    "        return \"conscience\"\n",
    "\n",
    "\"\"\"\n",
    "gets the name of the distribution from the fraction of civic and saints\n",
    "\"\"\"\n",
    "def lookup_distrib_name_pinhead(tup):\n",
    "    if tup == (0.01, 0.01):\n",
    "        return \"mix\"\n",
    "    elif tup == (0.02, 0.00):\n",
    "        return \"conscience\"\n",
    "    elif tup == (0.00, 0.02):\n",
    "        return \"coop\"\n",
    "    \n",
    "\"\"\"\n",
    "calculates the mean, standard deviation, and standard error of a list\n",
    "\"\"\"\n",
    "def calc_mean_sd_se(lst):\n",
    "    mean = sum(lst)/len(lst)\n",
    "    sd = math.sqrt(sum([(x - mean)**2 for x in lst]) / (len(lst) - 1))\n",
    "    se = sd / math.sqrt(len(lst))\n",
    "    return mean, sd, se\n",
    "\n",
    "\"\"\"\n",
    "gets the directory name from the set of parameters\n",
    "\"\"\"\n",
    "def get_dirname(params, model):\n",
    "    if model == \"spatial\":\n",
    "        defaults = {\n",
    "            \"y\": 20050,\n",
    "            \"n\": 20,\n",
    "            \"g\": 10,\n",
    "            \"c\": 20,\n",
    "            \"b\": 65,\n",
    "            \"r\": 20,\n",
    "            \"t\": 0.5,\n",
    "            \"pm\": 0.01,\n",
    "            \"ps\": 0.01,\n",
    "            \"distrib\": 0.02,\n",
    "            \"cd\": 5 \n",
    "        }\n",
    "    elif model == \"pinhead\":\n",
    "        defaults = {\n",
    "            \"y\": 15000,\n",
    "            \"n\": 35,\n",
    "            \"g\": 60,\n",
    "            \"c\": 1,\n",
    "            \"b\": 3.5,\n",
    "            \"pm\": 0.01,\n",
    "            \"ps\": 0.2,\n",
    "            \"r\": 1,\n",
    "            \"t\": 0.5,\n",
    "            \"distrib\": \"0.02_0\",\n",
    "        }\n",
    "    \n",
    "    dirname_list = []\n",
    "    for var in defaults.keys():\n",
    "        dirname_list.append(f'{var}{lookup_priority(var, params, defaults)}')\n",
    "    \n",
    "    dirname = \"_\".join(dirname_list)\n",
    "        \n",
    "    return dirname\n",
    "\n",
    "\"\"\"\n",
    "looks up key first in the pri_dict, but if its not in their, it looks in the backup dict\n",
    "\"\"\"\n",
    "def lookup_priority(key, pri_dict, backup_dict):\n",
    "    if key in pri_dict:\n",
    "        return pri_dict[key]\n",
    "    else:\n",
    "        return backup_dict[key]\n",
    "    \n",
    "\"\"\"\n",
    "generator function that allows you to iterate through all sets of parameters given in the parameter dict\n",
    "\"\"\"\n",
    "def make_tuples_from_param_dict(params):\n",
    "    if params:\n",
    "        first_key = list(params.keys())[0]\n",
    "        first_vals = params[first_key]\n",
    "        new_params = {key: params[key] for key in params if key != first_key}\n",
    "\n",
    "        for val in first_vals:\n",
    "            for tup in make_tuples_from_param_dict(new_params):\n",
    "                yield (val,) + tup\n",
    "    else:\n",
    "        yield ()\n",
    "\n",
    "\"\"\"\n",
    "interpolates a list with None elements by carrying values forward, but if a list starts with none values, it carries\n",
    "the first value backward\n",
    "\"\"\"\n",
    "def interpolate(lst):\n",
    "    # make sure you start with non-none entries\n",
    "    \n",
    "    new_lst = []\n",
    "    last_non_none = None\n",
    "    for i, item in enumerate(lst):\n",
    "        if lst[i] is not None:\n",
    "            \n",
    "            # if this is the first non-none value, fill in all vals before\n",
    "            if last_non_none is None:\n",
    "                new_lst += [item] * i\n",
    "            \n",
    "            # also add the new value to the list\n",
    "            new_lst.append(lst[i])\n",
    "            last_non_none = i\n",
    "        elif last_non_none is not None:\n",
    "            new_lst.append(lst[last_non_none])\n",
    "    \n",
    "    return new_lst\n",
    "    \n",
    "\"\"\"\n",
    "replaces a list with a 50-step rolling average\n",
    "\"\"\"\n",
    "def smoother(lst, window=50):\n",
    "    new_lst = [sum(lst[i:i+window])/window for i in range(len(lst) - window)]\n",
    "    return new_lst\n",
    "\n",
    "\"\"\"\n",
    "divides each element of the list by the sum\n",
    "\"\"\"\n",
    "def normalize(lst):\n",
    "    lst_sum = sum(lst)\n",
    "    normalized = [elt/lst_sum for elt in lst]\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eba594",
   "metadata": {},
   "source": [
    "## visual setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0b92e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the five colors\n",
    "light = '#E5EFFF'\n",
    "med = '#8282D1'\n",
    "dark = '#2B2347'\n",
    "turq = '#7CCFC9'\n",
    "red = '#994546'\n",
    "\n",
    "# specify properties for box plots\n",
    "medianprops = dict(linewidth=1.5)\n",
    "meanprops = dict(marker='D', markerfacecolor=turq, markeredgecolor=turq)\n",
    "flierprops = dict(marker='.')\n",
    "\n",
    "# specify font \n",
    "matplotlib.rcParams['font.family'] = \"Courier New\"\n",
    "\n",
    "# remove spines, hide ticks, add a light grid, and label axis\n",
    "def format_grid(ax, label=\"(A)\", show_horiz_gridlines=True, show_vert_gridlines=False):\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    \n",
    "    if show_horiz_gridlines:\n",
    "        ax.yaxis.grid(color=light, zorder=0)\n",
    "        \n",
    "    if show_vert_gridlines:\n",
    "        ax.xaxis.grid(color=light, zorder=0)\n",
    "    \n",
    "    ax.text(ax.get_xlim()[1], ax.get_ylim()[1], label, ha=\"right\", va=\"top\", fontweight='bold', fontsize=15, zorder=8)\n",
    "    ax.tick_params(axis=u'both', which=u'both',length=0)\n",
    "\n",
    "# set coloring for box plot boxes\n",
    "def set_box_colors(bp, color_range=[red, dark, turq]):\n",
    "    for i, color in enumerate(color_range):\n",
    "        plt.setp(bp['boxes'][i], color=color)  \n",
    "        plt.setp(bp['medians'][i], color='black')\n",
    "        \n",
    "        if i < len(bp['fliers']):\n",
    "            plt.setp(bp['fliers'][i], color=color)\n",
    "\n",
    "        for elem in ['caps', 'whiskers']:\n",
    "            plt.setp(bp[elem][i*2], color=color)\n",
    "            plt.setp(bp[elem][i*2 + 1], color=color)\n",
    "\n",
    "# make some colormaps\n",
    "cdict = {'red':   [(0.0,  0.6, 0.6),\n",
    "                   (1.0,  0.49, 0.49)],\n",
    "\n",
    "         'green': [(0.0, 0.27, 0.27),\n",
    "                   (1.0, 0.81, 0.81)],\n",
    "\n",
    "         'blue':  [(0.0,  0.27, 0.27),\n",
    "                   (1.0,  0.79, 0.79)]}\n",
    "red_turq_cmap = matplotlib.colors.LinearSegmentedColormap(\"red_turq_gradient\", cdict, N=255)\n",
    "light_dark_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"light_dark_gradient\", [\"#E5EFFF\",\"#2B2347\"])\n",
    "light_med_dark_edge_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    \"light_dark_gradient\", \n",
    "    [(0, \"#E5EFFF\"),(0.45,'#8282D1'),(0.55,'#8282D1'),(1.0, \"#2B2347\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f648a2",
   "metadata": {},
   "source": [
    "# aggregate visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f36bfd2",
   "metadata": {},
   "source": [
    "## imports relevant data from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5a1e4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function collects the data for the requested model and params and puts it into a dictionary\n",
    "\"\"\"\n",
    "def create_data_dict(model, params, data_dict=None):\n",
    "    if data_dict is None:\n",
    "        data_dict = {mig: {distrib: {benefit: {} for benefit in params[\"b\"]} for distrib in params[\"distrib\"]} for mig in params[\"ps\"]}\n",
    "    \n",
    "    for benefit, mig, distrib in make_tuples_from_param_dict(params):\n",
    "        # get file names from the directory\n",
    "        # distrib_name = lookup_distrib_name_spatial(distrib)\n",
    "        subdir = get_dirname({\"b\": benefit, \"ps\": mig, \"distrib\": distrib}, model)\n",
    "        # subdir = f\"{(benefit / 20):.2f}_{distrib_name}\"\n",
    "        dirname = f\"{model}/data/{subdir}\"\n",
    "        # print(dirname)\n",
    "        \n",
    "        if not os.path.exists(dirname):\n",
    "            continue\n",
    "            \n",
    "        files = os.listdir(dirname)\n",
    "\n",
    "        if \"Icon\\r\" in files:\n",
    "            files.remove(\"Icon\\r\")\n",
    "        if \"desktop.ini\" in files:\n",
    "            files.remove(\"desktop.ini\")\n",
    "\n",
    "        breakouts = []\n",
    "        avg_coops = []\n",
    "        max_coops = []\n",
    "        min_coops = []\n",
    "        avg_noncivic_coops = []\n",
    "        avg_civic_coops = []\n",
    "        avg_civs = []\n",
    "        max_civs = []\n",
    "        min_civs = []\n",
    "        eighty_pcts = []\n",
    "        civ_eighty_pcts = []\n",
    "        full_coop_levels = []\n",
    "        full_nc_coop_levels = []\n",
    "        full_civ_levels = []\n",
    "        full_civ_coop_levels = []\n",
    "        total_migs = []\n",
    "        total_deaths = []\n",
    "\n",
    "        for file in files:\n",
    "            f = open(f\"{dirname}/{file}\")\n",
    "            data = json.load(f)\n",
    "            \n",
    "            \n",
    "            if model == \"spatial\":\n",
    "                total_migs.append(data[\"demographics\"][\"migrated\"])\n",
    "                total_deaths.append(data[\"demographics\"][\"total\"])\n",
    "                data.pop(\"demographics\")\n",
    "            \n",
    "            data.pop(\"params\")\n",
    "\n",
    "            # construct the dictionary that I want\n",
    "            coop_levels = []\n",
    "            noncivic_coop_levels = []\n",
    "            civic_coop_levels = []\n",
    "            civ_percentages = []\n",
    "            pops = []\n",
    "            groups = []\n",
    "\n",
    "            on_tail = False\n",
    "            on_real_tail = False\n",
    "\n",
    "\n",
    "            # compile the yearly data in a list\n",
    "            for year, dat in data.items():\n",
    "                pop, noncivic_pop = population(dat)\n",
    "                \n",
    "                if pop > 2000 and not on_tail and model == \"spatial\":\n",
    "                    on_tail = True\n",
    "                    on_real_tail = True\n",
    "                    breakouts.append(int(year))\n",
    "                \n",
    "                elif int(year) > 2000 and model == \"pinhead\" and not on_tail:\n",
    "                    on_tail = True\n",
    "                \n",
    "                elif int(year) > 5000 and not on_tail:\n",
    "                    on_tail = True\n",
    "\n",
    "                elif on_tail:\n",
    "                    if pop > 2000 and not on_real_tail:\n",
    "                        on_real_tail = True\n",
    "                        breakouts.append(int(year))\n",
    "\n",
    "\n",
    "                    cooperators, noncivic_cooperators = total_coop_level(dat)\n",
    "\n",
    "                    if model == \"spatial\":\n",
    "                        pops.append(pop)\n",
    "                        groups.append(dat[\"g\"])\n",
    "\n",
    "                    coop_levels.append(cooperators/pop)\n",
    "\n",
    "                    if pop != noncivic_pop:   \n",
    "                        civic_coop_levels.append((cooperators - noncivic_cooperators)/(pop - noncivic_pop))\n",
    "                    else:\n",
    "                        civic_coop_levels.append(None)\n",
    "\n",
    "                    noncivic_coop_levels.append(noncivic_cooperators/noncivic_pop)\n",
    "                    civ_percentages.append((pop - noncivic_pop)/pop)\n",
    "\n",
    "            if not on_real_tail:\n",
    "                breakouts.append(\"never\")\n",
    "\n",
    "            # for a given run, calculaothe average cooperation levels and the average level of civic learners\n",
    "            full_coop_levels.append(coop_levels)\n",
    "            full_nc_coop_levels.append(noncivic_coop_levels)\n",
    "            full_civ_coop_levels.append(civic_coop_levels)\n",
    "            full_civ_levels.append(civ_percentages)\n",
    "\n",
    "            avg_coop = sum(coop_levels)/len(coop_levels)\n",
    "            deviations = [abs(x - avg_coop) for x in coop_levels]\n",
    "            deviations.sort()\n",
    "            eighty_pcts.append(deviations[math.ceil(len(deviations)*0.8)])\n",
    "\n",
    "            avg_coops.append(avg_coop)\n",
    "            min_coops.append(min(coop_levels))\n",
    "            max_coops.append(max(coop_levels))\n",
    "            avg_noncivic_coops.append(sum(noncivic_coop_levels)/len(noncivic_coop_levels))\n",
    "            \n",
    "            civic_coop_non_none = [civic_coop for civic_coop in civic_coop_levels if civic_coop is not None]\n",
    "            avg_civic_coops.append(sum(civic_coop_non_none)/len(civic_coop_non_none))\n",
    "\n",
    "            avg_civ = sum(civ_percentages)/len(civ_percentages)\n",
    "            deviations = [abs(x - avg_civ) for x in civ_percentages]\n",
    "            deviations.sort()\n",
    "            civ_eighty_pcts.append(deviations[math.ceil(len(deviations)*0.8)])\n",
    "            avg_civs.append(avg_civ)\n",
    "            min_civs.append(min(civ_percentages))\n",
    "            max_civs.append(max(civ_percentages))\n",
    "\n",
    "        # calculate effective migration rate\n",
    "        if model == \"spatial\":\n",
    "            eff_mig_rate = sum(total_migs)/sum(total_deaths)\n",
    "            eff_grp_size_simple = sum(pops)/sum(groups)\n",
    "            group_sizes = [pop / group for pop, group in zip(pops, groups)]\n",
    "            eff_grp_size_better = sum(group_sizes)/len(group_sizes)\n",
    "\n",
    "        # calculate the average cooperation levels\n",
    "        coop_max_mean, _, coop_max_se = calc_mean_sd_se(max_coops)\n",
    "        coop_min_mean, _, coop_min_se = calc_mean_sd_se(min_coops)\n",
    "        coop_sample_mean, _, coop_se = calc_mean_sd_se(avg_coops)\n",
    "        eighty_pct_mean, _, eighty_pct_se = calc_mean_sd_se(eighty_pcts)\n",
    "\n",
    "        nc_coop_sample_mean, _, nc_coop_se = calc_mean_sd_se(avg_noncivic_coops)\n",
    "        civ_coop_sample_mean, _, civ_coop_se = calc_mean_sd_se(avg_civic_coops)\n",
    "\n",
    "        # calculate the average civic learner levels\n",
    "        civ_max_mean, _, civ_max_se = calc_mean_sd_se(max_civs)\n",
    "        civ_min_mean, _, civ_min_se = calc_mean_sd_se(min_civs)\n",
    "        civ_sample_mean, _, civ_se = calc_mean_sd_se(avg_civs)\n",
    "        \n",
    "        civ_eighty_pct_mean, _, civ_eighty_pct_se = calc_mean_sd_se(civ_eighty_pcts)\n",
    "\n",
    "        # calculate the average civic learner levels\n",
    "        civ_max_mean, _, civ_max_se = calc_mean_sd_se(max_civs)\n",
    "        civ_min_mean, _, civ_min_se = calc_mean_sd_se(min_civs)\n",
    "        civ_sample_mean, _, civ_se = calc_mean_sd_se(avg_civs)\n",
    "\n",
    "        number_breakouts = [breakout for breakout in breakouts if breakout != \"never\"]\n",
    "        breakout_fract = len(number_breakouts)/len(breakouts)\n",
    "        breakout_fract_se = math.sqrt(breakout_fract*(1 - breakout_fract)/len(breakouts))\n",
    "\n",
    "        if len(number_breakouts) > 1:\n",
    "            breakout_mean, _, breakout_se = calc_mean_sd_se(number_breakouts)\n",
    "        else:\n",
    "            breakout_mean, breakout_se = 0, 0\n",
    "        \n",
    "        if mig not in data_dict:\n",
    "            data_dict[mig] = {}\n",
    "        if distrib not in data_dict[mig]:\n",
    "            data_dict[mig][distrib] = {}\n",
    "        if benefit not in data_dict[mig][distrib]:\n",
    "            data_dict[mig][distrib][benefit] = {}\n",
    "        \n",
    "        # demographic variables\n",
    "        if model == \"spatial\":\n",
    "            data_dict[mig][distrib][benefit][\"eff_mig\"] = eff_mig_rate\n",
    "            data_dict[mig][distrib][benefit][\"grp_size\"] = eff_grp_size_better\n",
    "            data_dict[mig][distrib][benefit][\"grp_size_check\"] = eff_grp_size_simple\n",
    "\n",
    "        # full lists of things\n",
    "        data_dict[mig][distrib][benefit][\"civ_coop_levels\"] = full_civ_coop_levels\n",
    "        data_dict[mig][distrib][benefit][\"coop_levels\"] = full_coop_levels\n",
    "        data_dict[mig][distrib][benefit][\"nc_coop_levels\"] = full_nc_coop_levels\n",
    "        data_dict[mig][distrib][benefit][\"civ_levels\"] = full_civ_levels\n",
    "\n",
    "        # fraction of groups that reached 2000 population\n",
    "        data_dict[mig][distrib][benefit][\"breakout_fract\"] = breakout_fract\n",
    "        data_dict[mig][distrib][benefit][\"breakout_fract_se\"] = breakout_fract_se\n",
    "        data_dict[mig][distrib][benefit][\"breakout_mean\"] = breakout_mean\n",
    "        data_dict[mig][distrib][benefit][\"breakout_se\"] = breakout_se\n",
    "\n",
    "        # coop mean, min, max\n",
    "        data_dict[mig][distrib][benefit][\"coop_min\"] = coop_min_mean\n",
    "        data_dict[mig][distrib][benefit][\"coop_min_se\"] = coop_min_se\n",
    "\n",
    "        data_dict[mig][distrib][benefit][\"coop_max\"] = coop_max_mean\n",
    "        data_dict[mig][distrib][benefit][\"coop_max_se\"] = coop_max_se\n",
    "\n",
    "        data_dict[mig][distrib][benefit][\"coop_mean\"] = coop_sample_mean\n",
    "        data_dict[mig][distrib][benefit][\"coop_se\"] = coop_se\n",
    "\n",
    "        data_dict[mig][distrib][benefit][\"eighty_pct_mean\"] = eighty_pct_mean\n",
    "        data_dict[mig][distrib][benefit][\"eighty_pct_se\"] = eighty_pct_se\n",
    "        \n",
    "        data_dict[mig][distrib][benefit][\"civ_coop_mean\"] = civ_coop_sample_mean\n",
    "        data_dict[mig][distrib][benefit][\"civ_coop_se\"] = civ_coop_se\n",
    "        \n",
    "        data_dict[mig][distrib][benefit][\"nc_coop_mean\"] = nc_coop_sample_mean\n",
    "        data_dict[mig][distrib][benefit][\"nc_coop_se\"] = nc_coop_se\n",
    "\n",
    "        data_dict[mig][distrib][benefit][\"civ_min\"] = civ_min_mean\n",
    "        data_dict[mig][distrib][benefit][\"civ_min_se\"] = civ_min_se\n",
    "\n",
    "        data_dict[mig][distrib][benefit][\"civ_max\"] = civ_max_mean\n",
    "        data_dict[mig][distrib][benefit][\"civ_max_se\"] = civ_max_se\n",
    "\n",
    "        data_dict[mig][distrib][benefit][\"civ_mean\"] = civ_sample_mean\n",
    "        data_dict[mig][distrib][benefit][\"civ_se\"] = civ_se\n",
    "\n",
    "        data_dict[mig][distrib][benefit][\"civ_eighty_pct_mean\"] = civ_eighty_pct_mean\n",
    "        data_dict[mig][distrib][benefit][\"civ_eighty_pct_se\"] = civ_eighty_pct_se\n",
    "\n",
    "    for benefit in params[\"b\"]:\n",
    "        for mig in params[\"ps\"]:\n",
    "            for distrib in params[\"distrib\"]:\n",
    "                if benefit not in data_dict[mig][distrib] or not data_dict[mig][distrib][benefit]:\n",
    "                    continue\n",
    "                if model == \"spatial\":\n",
    "                    demographics =  f'{data_dict[mig][distrib][benefit][\"eff_mig\"]:.3f} {data_dict[mig][distrib][benefit][\"grp_size\"]:.3f}'\n",
    "                    distrib_string =  f'{distrib:.2f}'\n",
    "                else:\n",
    "                    demographics = \"\"\n",
    "                    distrib_string = distrib\n",
    "                    \n",
    "                print(f'{benefit:.2f}', \n",
    "                      f'{mig:.2f}', \n",
    "                      distrib_string, \n",
    "                      f'{data_dict[mig][distrib][benefit][\"coop_mean\"]:.3f}', \n",
    "                      f'{data_dict[mig][distrib][benefit][\"nc_coop_mean\"]:.3f}', \n",
    "                      f'{data_dict[mig][distrib][benefit][\"civ_mean\"]:.3f}',\n",
    "                      demographics\n",
    "                     )\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\"\"\"\n",
    "prints the data dict line by line so we get some sense of the mean values for each parameter combo\n",
    "\"\"\"\n",
    "def print_dict_important_parts(model, data_dict, params):\n",
    "    for benefit in params[\"b\"]:\n",
    "        for mig in params[\"ps\"]:\n",
    "            for distrib in params[\"distrib\"]:\n",
    "                if benefit not in data_dict[mig][distrib] or not data_dict[mig][distrib][benefit]:\n",
    "                    continue\n",
    "\n",
    "                if model == \"spatial\":\n",
    "                    demographics =  f'{data_dict[mig][distrib][benefit][\"eff_mig\"]:.3f} {data_dict[mig][distrib][benefit][\"grp_size\"]:.3f}'\n",
    "                    distrib_string =  f'{distrib:.2f}'\n",
    "                else:\n",
    "                    demographics = \"\"\n",
    "                    distrib_string = distrib\n",
    "\n",
    "                print(f'{benefit:.2f}', \n",
    "                      f'{mig:.2f}', \n",
    "                      distrib_string, \n",
    "                      f'{data_dict[mig][distrib][benefit][\"coop_mean\"]:.3f}', \n",
    "                      f'{data_dict[mig][distrib][benefit][\"nc_coop_mean\"]:.3f}', \n",
    "                      f'{data_dict[mig][distrib][benefit][\"civ_mean\"]:.3f}',\n",
    "                      demographics\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae856396",
   "metadata": {},
   "source": [
    "## data collection for abstract (pinhead) and naturalistic (spatial) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "54a9cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the collection that I ran\n",
    "\n",
    "# ben     mig aggr                      mig deet\n",
    "# 55  ->  0.5                        -> 0.4\n",
    "# 60  ->  0 - 0.8                    -> \n",
    "# 65  ->  0, 0.005, 0.05, 0 - 0.8    -> 0.4\n",
    "# 70  ->  0 - 0.8                    -> 0.4\n",
    "# 75  ->  0.5\n",
    "\n",
    "\n",
    "# PINHEAD\n",
    "\n",
    "# ben       mig aggr     mig deet\n",
    "# 3     ->  0.2       -> 0.2\n",
    "# 3.25  ->  0 - 0.6   -> \n",
    "# 3.5   ->  0 - 0.6   -> 0.2\n",
    "# 3.75  ->  0 - 0.6   -> 0.2\n",
    "# 4     ->  0.2\n",
    "# 4.25  ->  0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7102d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_spatial = {\n",
    " \"b\": [55, 60, 65, 70, 75],\n",
    " \"ps\": [0, 0.005, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    " \"distrib\": [0, 0.02]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb5681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spatial_data_dict = create_data_dict(\"spatial\", params_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_pinhead = {\n",
    " \"b\": [3, 3.25, 3.5, 3.75, 4],\n",
    " \"ps\": [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    " \"distrib\": [\"0_0.02\", \"0.02_0\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79058b10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pinhead_data_dict = create_data_dict(\"pinhead\", params_pinhead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442083c8",
   "metadata": {},
   "source": [
    "## load or save pickle files of the data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/spatial_data_dict.pkl\", \"wb\") as spatial_f:\n",
    "    pkl.dump(spatial_data_dict, spatial_f)\n",
    "\n",
    "with open(\"pickle/pinhead_data_dict.pkl\", \"wb\") as pinhead_f:\n",
    "    pkl.dump(pinhead_data_dict, pinhead_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666cbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/spatial_data_dict.pkl\", \"rb\") as spatial_f:\n",
    "    spatial_data_dict = pkl.load(spatial_f)\n",
    "    \n",
    "with open(\"pickle/pinhead_data_dict.pkl\", \"rb\") as pinhead_f:\n",
    "    pinhead_data_dict = pkl.load(pinhead_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361fee9",
   "metadata": {},
   "source": [
    "## plot time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plots a smoothed time series of cooperation levels and populations of agent types over the course of a particular run\n",
    "specified by [ind]\n",
    "\"\"\"\n",
    "def plot_civ_nc_time_series(ind, model, data_dict, benefit, mig, window=500):\n",
    "    if model == \"pinhead\":\n",
    "        civ_distrib = \"0.02_0\"\n",
    "        other_distrib = \"0_0.02\"\n",
    "    elif model == \"spatial\":\n",
    "        civ_distrib = 0.02\n",
    "        other_distrib = 0\n",
    "        \n",
    "    civ_coops = data_dict[mig][civ_distrib][benefit][\"civ_coop_levels\"][ind]\n",
    "    nc_coops = data_dict[mig][civ_distrib][benefit][\"nc_coop_levels\"][ind]\n",
    "    coops = data_dict[mig][civ_distrib][benefit][\"coop_levels\"][ind]\n",
    "    nc_coops_nociv = data_dict[mig][other_distrib][benefit][\"nc_coop_levels\"][ind]\n",
    "    coops_nociv = data_dict[mig][other_distrib][benefit][\"coop_levels\"][ind]\n",
    "    pops_civ = data_dict[mig][other_distrib][benefit][\"civ_levels\"][ind]\n",
    "    civ_coops_interpolated = interpolate(civ_coops)\n",
    "    \n",
    "    civ_coops_pops = [pop * coop for pop, coop in zip(pops_civ, civ_coops_interpolated)]\n",
    "    \n",
    "    civ_coops_smoothed = normalize(smoother(civ_coops_interpolated, window=window))\n",
    "    coops_smoothed_non_norm = smoother(coops, window=window)\n",
    "    coops_smoothed = normalize(coops_smoothed_non_norm)\n",
    "    \n",
    "    nc_coops_smoothed = normalize(smoother(nc_coops, window=window))\n",
    "    coops_nociv_smoothed = smoother(coops_nociv, window=window)\n",
    "    nc_coops_nociv_smoothed = normalize(smoother(nc_coops_nociv, window=window))\n",
    "    pops_civ_smoothed = normalize(smoother(pops_civ, window=window))\n",
    "    civ_coops_pops_smoothed = normalize(smoother(civ_coops_pops, window=window))\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig1, ax1 = plt.subplots(1)\n",
    "    ax1.set_title(\"experimental: civ coops and nc coops\")\n",
    "    ax1.plot(range(len(civ_coops_smoothed)), civ_coops_smoothed)\n",
    "    ax1.plot(range(len(civ_coops_smoothed)), nc_coops_smoothed)\n",
    "    \n",
    "    fig2, ax2 = plt.subplots(1)\n",
    "    ax2.set_title(\"experimental: civ_coops*civ_poops and nc_coops\")\n",
    "    ax2.plot(range(len(civ_coops_smoothed)), civ_coops_pops_smoothed)\n",
    "    ax2.plot(range(len(civ_coops_smoothed)), nc_coops_smoothed)\n",
    "    \n",
    "    fig3, ax3 = plt.subplots(1)\n",
    "    ax3.set_title(\"experimental: civ coops and civ population\")\n",
    "    ax3.plot(range(len(civ_coops_smoothed)), civ_coops_smoothed)\n",
    "    ax3.plot(range(len(civ_coops_smoothed)), pops_civ_smoothed)\n",
    "    \n",
    "    fig4, ax4 = plt.subplots(1)\n",
    "    ax4.set_title(\"experimental: total coops and civ population\")\n",
    "    ax4.plot(range(len(civ_coops_smoothed)), pops_civ_smoothed)\n",
    "    ax4.plot(range(len(civ_coops_smoothed)), coops_smoothed)\n",
    "    \n",
    "    fig5, ax5 = plt.subplots(1)\n",
    "    ax5.set_title(\"total coops, total coops\")\n",
    "    ax5.plot(range(len(civ_coops_smoothed)), coops_nociv_smoothed)\n",
    "    ax5.plot(range(len(civ_coops_smoothed)), coops_smoothed_non_norm)\n",
    "    \n",
    "    return fig1, fig2, fig3, fig4, fig5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7558695",
   "metadata": {},
   "source": [
    "## functions for analyzing spikes in cooperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ecff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calls find spikes on a list of cooperation lists [coop_lists]\n",
    "\"\"\"\n",
    "def get_all_spikes(coop_lists, min_spike_length=0):\n",
    "    spikes_list = []\n",
    "    \n",
    "    for coop_list in coop_lists:\n",
    "        spikes, _, _ = find_spikes(coop_list, min_spike_length)\n",
    "        spikes_list.append(spikes)\n",
    "    \n",
    "    return spikes_list\n",
    "\n",
    "\"\"\"\n",
    "for a particular list of cooperation levels, returns a list of two-element lists that represent intervals\n",
    "in which cooperation was above average (possibly with some min_spike_length)\n",
    "\"\"\"\n",
    "def find_spikes(coop_levels, min_spike_length=0):\n",
    "    avg = sum(coop_levels) / len(coop_levels)\n",
    "    \n",
    "    spikes = []\n",
    "    curr_spike = []\n",
    "    on_spike = False\n",
    "    max_spike_length = 0\n",
    "    avg_spike_length = [0, 0]\n",
    "    \n",
    "    for i, lvl in enumerate(coop_levels):\n",
    "        # rose above, add fist index\n",
    "        if avg < lvl and not on_spike:\n",
    "            on_spike = True\n",
    "            curr_spike.append(i)\n",
    "            \n",
    "        # dropped below, reset and save spike\n",
    "        if avg >= lvl and on_spike:\n",
    "            curr_spike_length = i - curr_spike[0]\n",
    "            max_spike_length =  max_spike_length if curr_spike_length < max_spike_length else curr_spike_length\n",
    "            curr_spike.append(i)\n",
    "            on_spike = False\n",
    "            \n",
    "            if curr_spike_length > min_spike_length and curr_spike[0] != 0:\n",
    "                avg_spike_length[1] += 1\n",
    "                weight = 1 / avg_spike_length[1]\n",
    "                avg_spike_length[0] = avg_spike_length[0]*(1 - weight) + curr_spike_length*weight\n",
    "                \n",
    "                if len(spikes) > 0:\n",
    "                    last_spike = spikes[len(spikes) - 1]\n",
    "                    assert last_spike[1] < curr_spike[0]\n",
    "                \n",
    "                spikes.append(curr_spike)\n",
    "                \n",
    "            curr_spike = []\n",
    "    \n",
    "            \n",
    "    return spikes, max_spike_length, avg_spike_length[0]\n",
    "\n",
    "\"\"\"\n",
    "collects an array where each row is the values of cooperation on a spike/drop (extended 100 roudns before/after\n",
    "the start/end of spike/drop). Then, the average array takes the mean coop value for each step on the interval.\n",
    "the idea was to see if i could find the shape of a prototypical spike\n",
    "\"\"\"\n",
    "def calc_average_spike_drop_across_runs(coop_lists, spike_lists, interval, extension=100):\n",
    "    drop_arrs = []\n",
    "    spike_arrs = []\n",
    "    for spike_list, coop_list in zip(spike_lists, coop_lists):\n",
    "        drop_arr, _  = calc_average_drop(coop_list, spike_list, interval, extension)\n",
    "        spike_arr, _ = calc_average_spike(coop_list, spike_list, interval, extension)\n",
    "        drop_arrs.append(drop_arr)\n",
    "        spike_arrs.append(spike_arr)\n",
    "    \n",
    "    full_spike_arr = np.concatenate(spike_arrs, axis=0)\n",
    "    full_drop_arr = np.concatenate(drop_arrs, axis=0)\n",
    "    \n",
    "    full_spike_avgs = full_spike_arr.sum(axis=0) / full_spike_arr.shape[0]\n",
    "    full_drop_avgs = full_drop_arr.sum(axis=0) / full_drop_arr.shape[0]\n",
    "    \n",
    "    return full_spike_arr, full_spike_avgs, full_drop_arr, full_drop_avgs\n",
    "\n",
    "\"\"\"\n",
    "colects a list of the type of spike, specifically: who instigated it? who preserved it?\n",
    "also returns counts of the spikes instigated/preserved by civ and nc agents\n",
    "\"\"\"\n",
    "def compare_civ_nc_spikes(spike_lists, civ_spike_lists, nc_spike_lists):\n",
    "    \n",
    "    civ_inst_count = 0\n",
    "    civ_pres_count = 0\n",
    "    nc_inst_count = 0\n",
    "    nc_pres_count = 0\n",
    "    tot_spike_count = 0\n",
    "    spike_type_lists = []\n",
    "    \n",
    "    for i, spike_list in enumerate(spike_lists):\n",
    "        civ_spike_ind = 0\n",
    "        nc_spike_ind = 0\n",
    "        spike_type_list = []\n",
    "        \n",
    "        for spike in spike_list:\n",
    "            # print(\"---\\n\", spike)\n",
    "            civ_encompasser_start, civ_spike_ind = find_encompasser(spike[0], civ_spike_lists[i], civ_spike_ind)\n",
    "            civ_encompasser_end, civ_spike_ind = find_encompasser(spike[1], civ_spike_lists[i], civ_spike_ind)\n",
    "            \n",
    "            nc_encompasser_start, nc_spike_ind = find_encompasser(spike[0], nc_spike_lists[i], nc_spike_ind)\n",
    "            nc_encompasser_end, nc_spike_ind = find_encompasser(spike[1], nc_spike_lists[i], nc_spike_ind)\n",
    "            \n",
    "            # print(civ_encompasser_start, civ_encompasser_end)\n",
    "            # print(nc_encompasser_start, nc_encompasser_end)\n",
    "    \n",
    "            \n",
    "            spike_type = {\"instigator\": get_instigator_winner(civ_encompasser_start, nc_encompasser_start),\n",
    "                          \"preserver\": get_preserver_winner(civ_encompasser_end, nc_encompasser_end),\n",
    "                          \"length\": spike[1] - spike[0]}\n",
    "            \n",
    "            tot_spike_count += 1\n",
    "            civ_inst_count += (spike_type[\"instigator\"] in [\"civ\", \"tie\"])\n",
    "            civ_pres_count += (spike_type[\"preserver\"] in [\"civ\", \"tie\"])\n",
    "            nc_inst_count += (spike_type[\"instigator\"] in [\"nci\", \"tie\"])\n",
    "            nc_pres_count += (spike_type[\"preserver\"] in [\"nci\", \"tie\"])\n",
    "            \n",
    "            spike_type_list.append(spike_type)\n",
    "            # print(spike_type)\n",
    "            # print(tot_spike_count, civ_inst_count, civ_pres_count, nc_inst_count, nc_pres_count)\n",
    "        \n",
    "        spike_type_lists.append(spike_type_list)\n",
    "    \n",
    "    return tot_spike_count, civ_inst_count, civ_pres_count, nc_inst_count, nc_pres_count, spike_type_lists\n",
    "\n",
    "\"\"\"\n",
    "looks at two intervals surrounding the start of a spike (representing civic and noncivic spikes),\n",
    "whichever one starts first is the instigator winner\n",
    "\"\"\"\n",
    "def get_instigator_winner(civ_encompasser, nc_encompasser):\n",
    "    civ_start = float('inf') if civ_encompasser is None else civ_encompasser[0] # can never win if no encompasser\n",
    "    nc_start = float('inf') if nc_encompasser is None else nc_encompasser[0] # can never win if no encompasser\n",
    "    \n",
    "    if civ_start < nc_start:\n",
    "        return \"civ\"\n",
    "    elif nc_start < civ_start:\n",
    "        return \"nci\"\n",
    "    elif civ_start == nc_start:\n",
    "        return \"tie\"\n",
    "\n",
    "\"\"\"\n",
    "looks at two intervals surrounding the end of the spike, whichever one ends last is the preserver winner\n",
    "\"\"\"\n",
    "def get_preserver_winner(civ_encompasser, nc_encompasser):\n",
    "    civ_end = float('-inf') if civ_encompasser is None else civ_encompasser[1] # can never win if no encompasser\n",
    "    nc_end = float('-inf') if nc_encompasser is None else nc_encompasser[1] # can never win if no encompasser\n",
    "    \n",
    "    if civ_end > nc_end:\n",
    "        return \"civ\"\n",
    "    elif nc_end > civ_end:\n",
    "        return \"nci\"\n",
    "    elif nc_end == civ_end:\n",
    "        return \"tie\"\n",
    "\n",
    "\"\"\"\n",
    "finds the spike that starts before and ends after a particular time, returns none if there is none\n",
    "\"\"\"\n",
    "def find_encompasser(time, spike_list, ind):\n",
    "    closest_spike = spike_list[ind]\n",
    "    while ind < len(spike_list) - 1 and spike_list[ind + 1][0] <= time:\n",
    "        closest_spike = spike_list[ind + 1]\n",
    "        ind += 1\n",
    "    \n",
    "    encompasser = closest_spike if (closest_spike[0] <= time and closest_spike[1] >= time) else None\n",
    "    \n",
    "    return encompasser, ind\n",
    "\n",
    "\"\"\"\n",
    "this calculates a prototypical drop by looking at an interval of time leading up to the end of the spike, \n",
    "in addition to post_spike rounds afterwards. simply averages the cooperation levels on this \"drop\" stage\n",
    "\"\"\"\n",
    "def calc_average_drop(coop_levels, spikes, interval, post_spike=100):\n",
    "    drop_arr = np.zeros((len(spikes), interval))\n",
    "    \n",
    "    for i, spike in enumerate(spikes):\n",
    "        end = min(spike[1] + post_spike, len(coop_levels))\n",
    "        start = end - interval\n",
    "        \n",
    "        if start > 0:\n",
    "            drop_arr[i,0:interval] = coop_levels[start:end]\n",
    "    \n",
    "    drop_arr = drop_arr[drop_arr.sum(axis=1) > 0,:]\n",
    "    avg_drop = drop_arr.sum(axis=0) / drop_arr.shape[0]\n",
    "    \n",
    "    return drop_arr, avg_drop\n",
    "\n",
    "\"\"\"\n",
    "gets the properties of spikes and troughs, namely their length and their average cooperation level\n",
    "\"\"\"\n",
    "def get_spike_trough_properties(coop_lists, spike_lists):\n",
    "    spike_prop_lists = [] # {\"avg_val\": , \"peak_index\": , \"peak_value\": , \"length\": }\n",
    "    trough_prop_lists = []\n",
    "    \n",
    "    for spike_list, coop_list in zip(spike_lists, coop_lists):\n",
    "        last_spike = None\n",
    "        spike_prop_list = []\n",
    "        trough_prop_list = []\n",
    "        \n",
    "        for i, spike in enumerate(spike_list):\n",
    "            trough_start = 0 if last_spike is None else last_spike[1]\n",
    "            trough_coops = coop_list[trough_start:spike[0]]\n",
    "            spike_coops = coop_list[spike[0]:spike[1]]\n",
    "\n",
    "            spike_prop_list.append(get_props(spike_coops))\n",
    "            trough_prop_list.append(get_props(trough_coops))\n",
    "            last_spike = spike\n",
    "            \n",
    "            if i == len(spike_list) - 1:\n",
    "                trough_coops = coop_list[spike[1]:]\n",
    "                trough_prop_list.append(get_props(trough_coops))\n",
    "        \n",
    "        spike_prop_lists.append(spike_prop_list)\n",
    "        trough_prop_lists.append(trough_prop_list)\n",
    "    \n",
    "    return spike_prop_lists, trough_prop_lists\n",
    "\n",
    "\"\"\"\n",
    "gets the props of a spike corresponding to the cooperation values in lst\n",
    "\"\"\"\n",
    "def get_props(lst):\n",
    "    props = {}\n",
    "    props[\"length\"] = len(lst)\n",
    "    props[\"avg_val\"] = sum(lst) / props[\"length\"]\n",
    "    \n",
    "    peak_ind = np.argmax(lst)\n",
    "    props[\"peak_index\"] = peak_ind\n",
    "    props[\"peak_value\"] = lst[peak_ind]\n",
    "    \n",
    "    trough_ind = np.argmin(lst)\n",
    "    props[\"trough_index\"] = trough_ind\n",
    "    props[\"trough_value\"] = lst[trough_ind]\n",
    "    \n",
    "    return props\n",
    "\n",
    "\"\"\"\n",
    "returns lists of the avg coop values of spikes and troughs, along with who instigated which spikes\n",
    "\"\"\"\n",
    "def get_spike_type_by_trough_prop(trough_prop_lists, spike_prop_lists, spike_type_lists):\n",
    "    trough_coops = []\n",
    "    trough_lengths = []\n",
    "    spike_coops = []\n",
    "    spike_lengths = []\n",
    "    spike_instigators = []\n",
    "    spike_preservers = []\n",
    "\n",
    "    for trough_prop_list, spike_prop_list, spike_type_list in zip(trough_prop_lists, spike_prop_lists, spike_type_lists):\n",
    "        counter = 0\n",
    "        for trough_prop, spike_prop, spike_type in zip(trough_prop_list, spike_prop_list, spike_type_list):\n",
    "            trough_lengths.append(trough_prop[\"length\"])\n",
    "            trough_coops.append(trough_prop[\"avg_val\"])\n",
    "            spike_lengths.append(spike_prop[\"length\"])\n",
    "            spike_coops.append(spike_prop[\"avg_val\"])\n",
    "            spike_preservers.append(spike_type[\"preserver\"])\n",
    "            spike_instigators.append(spike_type[\"instigator\"])\n",
    "            counter += 1\n",
    "        \n",
    "        last_trough_prop = trough_prop_list[counter]\n",
    "        trough_lengths.append(trough_prop[\"length\"])\n",
    "        trough_coops.append(trough_prop[\"avg_val\"])\n",
    "        \n",
    "        # print(len(trough_coops), len(spike_coops))\n",
    "    return trough_coops, trough_lengths, spike_coops, spike_lengths, spike_instigators, spike_preservers\n",
    "\n",
    "\"\"\"\n",
    "calculates a prototypical spike by looking at [pre_spike] rounds before the spike and interval total steps,\n",
    "and averaging cooperation values at each of the time steps\n",
    "\"\"\"\n",
    "def calc_average_spike(coop_levels, spikes, interval, pre_spike=100):\n",
    "    spike_arr = np.zeros((len(spikes), interval))\n",
    "\n",
    "    for i, spike in enumerate(spikes):\n",
    "        start = max(0, spike[0] - pre_spike)\n",
    "        end = start + interval\n",
    "        \n",
    "        if end <= len(coop_levels):\n",
    "            spike_arr[i,0:interval] = coop_levels[start:end]\n",
    "    \n",
    "    spike_arr = spike_arr[spike_arr.sum(axis=1) > 0,:]\n",
    "    avg_spike = spike_arr.sum(axis=0) / spike_arr.shape[0]\n",
    "    \n",
    "    return spike_arr, avg_spike\n",
    "\n",
    "\"\"\"\n",
    "constructs a matrix of transition probabilities from no spike, to different types of spikes\n",
    "(defined by who instigated and who preserved the spike)\n",
    "\"\"\"\n",
    "def construct_markov_process(spike_lists, spike_prop_lists, threshold=200):\n",
    "    trans_mat = np.zeros((5, 5))\n",
    "    ind_dict = {\"none\": 0, \"civciv\": 1, \"civnci\": 2, \"nciciv\": 3, \"ncinci\": 4}\n",
    "    \n",
    "    for spike_list, spike_prop_list in zip(spike_lists, spike_prop_lists):\n",
    "        last_spike = None\n",
    "        \n",
    "        for spike, prop in zip(spike_list, spike_prop_list):\n",
    "            ind = civ_nci_dict_lookup(ind_dict, prop)\n",
    "            \n",
    "            if last_spike is None:\n",
    "                other_ind = 0\n",
    "            elif spike[0] - last_spike[1] > threshold:\n",
    "                other_ind = 0\n",
    "                trans_mat[last_ind, other_ind] += 1\n",
    "            else:\n",
    "                other_ind = last_ind\n",
    "            \n",
    "            trans_mat[other_ind, ind] += 1\n",
    "            \n",
    "            last_spike = spike\n",
    "            last_ind = ind\n",
    "    \n",
    "    return trans_mat\n",
    "\n",
    "\"\"\"\n",
    "lookup a val in dict by constructing correct key\n",
    "\"\"\"\n",
    "def civ_nci_dict_lookup(civ_nci_dict, prop):\n",
    "    inst = act_inst if (act_inst := prop[\"instigator\"]) != \"tie\" else np.random.choice([\"civ\", \"nci\"])\n",
    "    pres = act_pres if (act_pres := prop[\"preserver\"]) != \"tie\" else np.random.choice([\"civ\", \"nci\"])\n",
    "    \n",
    "    val = civ_nci_dict[inst + pres]\n",
    "        \n",
    "    return val\n",
    "\n",
    "\"\"\"\n",
    "looks up average length of each type of spike (define by who it is instigated by and who it is preserved by)\n",
    "\"\"\"\n",
    "def get_avg_length_of_each_type(spike_prop_lists):\n",
    "    counts = np.zeros((4))\n",
    "    lengths = np.zeros((4))\n",
    "    \n",
    "    ind_dict = {\"civciv\": 0, \"civnci\": 1, \"nciciv\": 2, \"ncinci\": 3}\n",
    "    for spike_prop_list in spike_prop_lists:\n",
    "        for prop in spike_prop_list:\n",
    "            ind = civ_nci_dict_lookup(ind_dict, prop)\n",
    "            lengths[ind] += prop[\"length\"]\n",
    "            counts[ind] += 1\n",
    "    \n",
    "    return lengths, counts\n",
    "\n",
    "\"\"\"\n",
    "returns a sequence of characterizations of 25-round chunks -- either very low cooperation, low cooperation,\n",
    "low civ high nc, high civ low nc, or high civ high nc\n",
    "\"\"\"\n",
    "def get_sequence_of_characterizations(civ_coop_lists, nc_coop_lists, coop_lists, window=25):\n",
    "    ind_dict = {(False, False): 1, (False, True): 2, (True, False): 3, (True, True): 4}\n",
    "    char_lists = []\n",
    "    for civ_coop_list, nc_coop_list, coop_list in zip(civ_coop_lists, nc_coop_lists, coop_lists):\n",
    "        avg_civ_coop, sd_civ_coop, _ = calc_mean_sd_se(civ_coop_list)\n",
    "        avg_nc_coop, sd_nc_coop, _ = calc_mean_sd_se(nc_coop_list)\n",
    "        avg_coop, sd_coop, _ = calc_mean_sd_se(coop_list)\n",
    "        char_list = []\n",
    "        for i, (civ_coop, nc_coop, coop) in enumerate(zip(civ_coop_list, nc_coop_list, coop_list)):\n",
    "            if i % window == 0:               \n",
    "                civ_above = (civ_coop > avg_civ_coop)\n",
    "                nc_above = (nc_coop > avg_nc_coop)\n",
    "\n",
    "                ind = ind_dict[(civ_above, nc_above)]\n",
    "                \n",
    "                if not civ_above and not nc_above and coop < (avg_coop - (0.5 * sd_coop)):\n",
    "                    ind = 0\n",
    "                \n",
    "                # print(civ_coop, avg_civ_coop)\n",
    "                # print(nc_coop, avg_nc_coop)\n",
    "                # print(coop, avg_coop, sd_coop)\n",
    "                # print(ind)\n",
    "                # y = input(\"x\")\n",
    "                char_list.append(ind)\n",
    "        \n",
    "        char_lists.append(char_list)\n",
    "        \n",
    "    return char_lists\n",
    "\n",
    "\"\"\"\n",
    "given a set of cutoffs, puts the val in the range of cutoffs\n",
    "\"\"\"\n",
    "def find_range(val, cutoffs):\n",
    "    ind = 0\n",
    "    for cutoff in cutoffs:\n",
    "        if val > cutoff:\n",
    "            ind += 1\n",
    "    \n",
    "    return ind\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "creates a markov process out of the list of characterizations (from get_sequence_characterizations())\n",
    "\"\"\"\n",
    "def sequence_markov_construction(char_lists):\n",
    "    trans_mat = np.zeros((5, 5), dtype=int)\n",
    "    for char_list in char_lists:\n",
    "        last_char = None\n",
    "        for char in char_list:\n",
    "            if last_char is not None:\n",
    "                trans_mat[last_char, char] += 1\n",
    "            \n",
    "            last_char = char\n",
    "            \n",
    "    return trans_mat\n",
    "        \n",
    "            \n",
    "\"\"\"\n",
    "gets spikes, the list of their properties, and the troughs and the list of their properties\n",
    "\"\"\"\n",
    "def get_spikes_and_props(lst):\n",
    "    spike_lists = get_all_spikes(lst, min_spike_length=10)\n",
    "    spike_props, trough_props = get_spike_trough_properties(lst, spike_lists)\n",
    "    \n",
    "    return spike_lists, spike_props, trough_props\n",
    "\n",
    "\"\"\"\n",
    "gives experimental and control keys for spatial and pinhead model\n",
    "\"\"\"\n",
    "def get_distrib_keys(model):\n",
    "    if model == \"spatial\":\n",
    "        exp = 0.02\n",
    "        control = 0\n",
    "    elif model == \"pinhead\":\n",
    "        exp = \"0.02_0\"\n",
    "        control = \"0_0.02\"\n",
    "    \n",
    "    return exp, control\n",
    "\n",
    "\"\"\"\n",
    "gets the info about spike types and props\n",
    "\"\"\"\n",
    "def get_spike_info(model, data_dict, benefit, mig):\n",
    "    exp, control = get_distrib_keys(model)\n",
    "    \n",
    "    coop_lists = [smoother(coop_list, window=25) for coop_list in data_dict[mig][exp][benefit][\"coop_levels\"]]\n",
    "    nc_coop_lists = [smoother(nc_coop_list, window=25) for nc_coop_list in data_dict[mig][exp][benefit][\"nc_coop_levels\"]]\n",
    "    civ_coop_lists = [smoother(interpolate(civ_coop_list), window=25) for civ_coop_list in data_dict[mig][exp][benefit][\"civ_coop_levels\"]]\n",
    "    \n",
    "    c_coop_lists = [smoother(coop_list, window=25) for coop_list in data_dict[mig][control][benefit][\"coop_levels\"]]\n",
    "    c_nc_coop_lists = [smoother(nc_coop_list, window=25) for nc_coop_list in data_dict[mig][control][benefit][\"nc_coop_levels\"]]\n",
    "    c_civ_coop_lists = [smoother(interpolate(civ_coop_list), window=25) for civ_coop_list in data_dict[mig][control][benefit][\"civ_coop_levels\"]]\n",
    "    \n",
    "    exp_spike_lists, exp_spike_props, exp_trough_props = get_spikes_and_props(coop_lists)\n",
    "    con_spike_lists, con_spike_props, con_trough_props = get_spikes_and_props(c_coop_lists)\n",
    "    civ_spike_lists, civ_spike_props, civ_trough_props = get_spikes_and_props(civ_coop_lists)  \n",
    "    nci_spike_lists, nci_spike_props, nci_trough_props = get_spikes_and_props(nc_coop_lists)\n",
    "        \n",
    "    return (exp_spike_lists, exp_spike_props, exp_trough_props, \n",
    "            con_spike_lists, con_spike_props, con_trough_props, \n",
    "            civ_spike_lists, civ_spike_props, civ_trough_props, \n",
    "            nci_spike_lists, nci_spike_props, nci_trough_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e2cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "flattens a list of lists into a list\n",
    "\"\"\"\n",
    "def flatten(lol):\n",
    "    cum = []\n",
    "    [(cum := cum + v) for v in lol]\n",
    "    return cum\n",
    "\n",
    "\"\"\"\n",
    "reshapes an array into a bigger one, with the new slots as zeros\n",
    "\"\"\"\n",
    "def extend_dim(extended_dims, arr):\n",
    "    extended = np.zeros(extended_dims)\n",
    "    slice_tuple = tuple(slice(0, dim) for dim in arr.shape)\n",
    "    extended[slice_tuple] = arr\n",
    "    \n",
    "    return extended\n",
    "\n",
    "\"\"\"\n",
    "makes the block diagram to show spike and trough lengths \n",
    "\"\"\"\n",
    "def make_block_diagram(spike_props_1, trough_props_1, spike_props_2, trough_props_2, title=\"Block diagram\", label=\"\", legend=True):\n",
    "    spike_props_1 = flatten(spike_props_1)\n",
    "    trough_props_1 = flatten(trough_props_1)\n",
    "    spike_props_2 = flatten(spike_props_2)\n",
    "    trough_props_2 = flatten(trough_props_2)\n",
    "    \n",
    "    plength_mean = {}\n",
    "    plength_sd = {}\n",
    "    plength_se = {}\n",
    "    p_share = {}\n",
    "    \n",
    "    pval_mean = {}\n",
    "    pval_se = {}\n",
    "    \n",
    "    tlength_mean = {}\n",
    "    tlength_sd = {}\n",
    "    tlength_se = {}\n",
    "    t_share = {}\n",
    "    \n",
    "    tval_mean = {}\n",
    "    tval_se = {}\n",
    "    \n",
    "    spike_contrib_fig, sc_ax = plt.subplots(figsize=(5,2))\n",
    "    plength_mean[0], plength_sd[0], plength_se[0] = calc_mean_sd_se([prop[\"length\"] for prop in spike_props_1])\n",
    "    tlength_mean[0], tlength_sd[0], tlength_se[0] = calc_mean_sd_se([prop[\"length\"] for prop in trough_props_1])\n",
    "    p_share[0] = plength_mean[0] / (plength_mean[0] + tlength_mean[0])\n",
    "    t_share[0] = tlength_mean[0] / (plength_mean[0] + tlength_mean[0])\n",
    "    \n",
    "    pval_mean[0], _, pval_se[0] = calc_mean_sd_se([prop[\"avg_val\"] for prop in spike_props_1])\n",
    "    tval_mean[0], _, tval_se[0] = calc_mean_sd_se([prop[\"avg_val\"] for prop in trough_props_1])\n",
    "    colors = [turq, med]\n",
    "    \n",
    "    sc_ax.add_patch(patches.Rectangle((0, 0), p_share[0], pval_mean[0], facecolor=turq, alpha=0.3, zorder=4, label=\"NI\"))\n",
    "    plot_block_error_bar(sc_ax, p_share[0] / 2, p_share[0] / 2, pval_mean[0] - pval_se[0] * 2.58, pval_mean[0] + pval_se[0] * 2.58)\n",
    "    sc_ax.add_patch(patches.Rectangle((p_share[0], 0), t_share[0], tval_mean[0], facecolor=turq, alpha=0.3, zorder=4))\n",
    "    plot_block_error_bar(sc_ax, p_share[0] + t_share[0] / 2, p_share[0]  + t_share[0] / 2, tval_mean[0] - tval_se[0] * 2.58, tval_mean[0] + tval_se[0] * 2.58)\n",
    "    \n",
    "    plength_mean[1], plength_sd[1], plength_se[1] = calc_mean_sd_se([prop[\"length\"] for prop in spike_props_2])\n",
    "    tlength_mean[1], tlength_sd[1], tlength_se[1] = calc_mean_sd_se([prop[\"length\"] for prop in trough_props_2])\n",
    "    p_share[1] = plength_mean[1] / (plength_mean[1] + tlength_mean[1])\n",
    "    t_share[1] = tlength_mean[1] / (plength_mean[1] + tlength_mean[1])\n",
    "    \n",
    "    pval_mean[1], _, pval_se[1] = calc_mean_sd_se([prop[\"avg_val\"] for prop in spike_props_2])\n",
    "    tval_mean[1], _, tval_se[1] = calc_mean_sd_se([prop[\"avg_val\"] for prop in trough_props_2])\n",
    "    \n",
    "    sc_ax.add_patch(patches.Rectangle((0, 0), p_share[1], pval_mean[1], facecolor=med, alpha=0.3, zorder=4, label=\"Non-NI\"))\n",
    "    plot_block_error_bar(sc_ax, p_share[1] / 2, p_share[1] / 2, pval_mean[1] - pval_se[1] * 2.58, pval_mean[1] + pval_se[1] * 2.58)\n",
    "    sc_ax.add_patch(patches.Rectangle((p_share[1], 0), t_share[1], tval_mean[1], facecolor=med, alpha=0.3, zorder=4))\n",
    "    plot_block_error_bar(sc_ax, p_share[1] + t_share[1] / 2, p_share[1]  + t_share[1] / 2, tval_mean[1] - tval_se[1] * 2.58, tval_mean[1] + tval_se[1] * 2.58)\n",
    "    \n",
    "    shorter = 0 if plength_mean[0] + tlength_mean[0] < plength_mean[1] + tlength_mean[1] else 1\n",
    "    longer = int(not shorter)\n",
    "    scale_factor = p_share[longer] / plength_mean[longer]\n",
    "    \n",
    "    \n",
    "    long_error_bar = plength_se[longer] * scale_factor\n",
    "    plot_block_error_bar(sc_ax, p_share[longer] - 2.58 * long_error_bar, p_share[longer] + 2.58*long_error_bar, pval_mean[longer] - 0.02, pval_mean[longer] - 0.02)\n",
    "    \n",
    "    assert abs(scale_factor - (t_share[longer] / tlength_mean[longer])) < 0.000001\n",
    "    \n",
    "    scale_plength = (plength_mean[shorter] / plength_mean[longer]) * p_share[longer]\n",
    "    scale_tlength = (tlength_mean[shorter] / tlength_mean[longer]) * t_share[longer]\n",
    "    short_error_bar = plength_se[shorter] * scale_factor\n",
    "    \n",
    "    print(\"1\", \"spike l mean, sd, se\", plength_mean[0], plength_sd[0], plength_se[0])\n",
    "    print(\"2\", \"spike l mean, sd, se\", plength_mean[1], plength_sd[1], plength_se[1])\n",
    "    \n",
    "    print(\"1\", \"trough l mean, sd, se\", tlength_mean[0], tlength_sd[0], tlength_se[0])\n",
    "    print(\"2\", \"trough l mean, sd, se\", tlength_mean[1], tlength_sd[1], tlength_se[1])\n",
    "    \n",
    "    print(\"1\", \"spike v mean\", pval_mean[0])\n",
    "    print(\"2\", \"spike v mean\", pval_mean[1])\n",
    "    \n",
    "    print(\"1\", \"trough v mean\", tval_mean[0])\n",
    "    print(\"2\", \"trough v mean\", tval_mean[1])\n",
    "    \n",
    "    start = 0\n",
    "    color = colors[shorter]\n",
    "    sc_ax.plot([start, start + scale_plength], [pval_mean[shorter], pval_mean[shorter]], color=color, zorder=5, label=\"Abs. length\")\n",
    "    while start < 1:\n",
    "        sc_ax.plot([start, start + scale_plength], [pval_mean[shorter], pval_mean[shorter]], color=color, zorder=5)\n",
    "        start = start + scale_plength\n",
    "        sc_ax.plot([start, start], [pval_mean[shorter], tval_mean[shorter]], color=color, zorder=5)\n",
    "        \n",
    "        # and the error bar\n",
    "        plot_block_error_bar(sc_ax, start - 2.58*short_error_bar, start + 2.58*short_error_bar, pval_mean[shorter] - 0.02, pval_mean[shorter] - 0.02)\n",
    "        \n",
    "        sc_ax.plot([start, start + scale_tlength], [tval_mean[shorter], tval_mean[shorter]], color=color, zorder=5)\n",
    "        start = start + scale_tlength\n",
    "        sc_ax.plot([start, start], [tval_mean[shorter], pval_mean[shorter]], color=color, zorder=5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    sc_ax.set_ylabel(\"Cooperation level\")\n",
    "    sc_ax.set_xlabel(\"Percentage of round\")\n",
    "    sc_ax.set_title(title, y=1.02)\n",
    "    sc_ax.set_xticks([0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    sc_ax.set_yticks([0.05, 0.15, 0.25, 0.35, 0.45, 0.55])\n",
    "    \n",
    "    if legend:\n",
    "        sc_ax.legend()\n",
    "    \n",
    "    sc_ax.set_xlim(left=0, right=1)\n",
    "    sc_ax.set_ylim(bottom=0, top=max(pval_mean[0] + 3 * pval_se[0], pval_mean[1] + 3 * pval_se[1]))\n",
    "    \n",
    "    format_grid(sc_ax, label=label, show_horiz_gridlines=False, show_vert_gridlines=False)\n",
    "    \n",
    "    return spike_contrib_fig\n",
    "\n",
    "\"\"\"\n",
    "adds error bars to the blcok diagram\n",
    "\"\"\"\n",
    "def plot_block_error_bar(ax, x_start, x_end, y_start, y_end):\n",
    "    x_mp = (x_start + x_end) / 2 \n",
    "    y_mp = (y_start + y_end) / 2\n",
    "    \n",
    "    ax.plot([x_start, x_end], [y_start, y_end], color=med, linewidth=0.5, zorder=6)\n",
    "    ax.plot(x_mp, y_mp, marker=\"o\", markersize=1.5, markeredgecolor=med, markerfacecolor=med, zorder=7)\n",
    "\n",
    "\"\"\"\n",
    "draws the peaks as dark lines\n",
    "\"\"\"  \n",
    "def peak_traces(spike_lists_1, spike_lists_2, label_1=\"\", label_2=\"\"):\n",
    "    # INCLUDE: plot for showing when peaks occur on various runs\n",
    "    fig0, (trace_ax0, trace_ax1) = plt.subplots(nrows=1, ncols=2, figsize=(10, 1.75))\n",
    "    # dot_color_dict = {\"civciv\": turq, \"civnci\": med, \"nciciv\": dark, \"ncinci\": red}\n",
    "    \n",
    "    for i, spike_list in enumerate(spike_lists_1):\n",
    "        for spike in spike_list:\n",
    "            trace_ax0.plot(spike, [i, i], color=med, zorder=3)\n",
    "    \n",
    "    for i, spike_list in enumerate(spike_lists_2):\n",
    "        for spike in spike_list:\n",
    "            trace_ax1.plot(spike, [i, i], color=med, zorder=3)\n",
    "    \n",
    "    trace_ax0.set_ylabel(\"Run #\")\n",
    "    trace_ax0.set_xlabel(\"Time\")\n",
    "    trace_ax0.set_yticks([])\n",
    "    trace_ax0.set_xticks([])\n",
    "    trace_ax0.set_title(\"With norm internalizers\", y=1.02)\n",
    "    \n",
    "    trace_ax1.set_ylabel(\"Run #\")\n",
    "    trace_ax1.set_xlabel(\"Time\")\n",
    "    trace_ax1.set_yticks([])\n",
    "    trace_ax1.set_xticks([])\n",
    "    trace_ax1.set_title(\"Without norm internalizers\", y=1.02)\n",
    "    \n",
    "    format_grid(trace_ax0, show_horiz_gridlines=False, label=label_1)\n",
    "    format_grid(trace_ax1, show_horiz_gridlines=False, label=label_2)\n",
    "    \n",
    "    return fig0\n",
    "\n",
    "\"\"\"\n",
    "creates a distribution on the items in length list\n",
    "\"\"\"\n",
    "def length_prob_distros(length_list, bins=10, bin_size=None):\n",
    "    if bin_size is None:\n",
    "        bin_size = max(length_list) / bins\n",
    "    elif bins is None:\n",
    "        bins = math.ceil(max(length_list) / bin_size)\n",
    "    \n",
    "    arr = np.zeros((bins,))\n",
    "    cutoffs = [i * bin_size for i in range(1, bins)]\n",
    "    \n",
    "    for length in length_list:\n",
    "        rng = find_range(length, cutoffs)\n",
    "        arr[rng] += length\n",
    "    \n",
    "    arr = arr / arr.sum()\n",
    "    return arr, bin_size\n",
    "\n",
    "\"\"\"\n",
    "makes a transition matrix and a sequence of states, which are defined by civ/nonciv coop levels, \n",
    "\"\"\"\n",
    "def make_sequence_of_states_and_trans_mat(model, data_dict, mig, benefit, exp=0.02, window=25):\n",
    "    coop_lists = [smoother(coop_list, window=25) for coop_list in data_dict[mig][exp][benefit][\"coop_levels\"]]\n",
    "    nc_coop_lists = [smoother(nc_coop_list, window=25) for nc_coop_list in data_dict[mig][exp][benefit][\"nc_coop_levels\"]]\n",
    "    civ_coop_lists = [smoother(interpolate(civ_coop_list), window=25) for civ_coop_list in data_dict[mig][exp][benefit][\"civ_coop_levels\"]]\n",
    "    \n",
    "    char_lists = get_sequence_of_characterizations(civ_coop_lists, nc_coop_lists, coop_lists, window=window)\n",
    "    char_trans = sequence_markov_construction(char_lists)\n",
    "    char_trans_no_id = char_trans - (char_trans * np.identity(char_trans.shape[0]))\n",
    "    \n",
    "    normalize_row_col_and_show(char_trans)\n",
    "    normalize_row_col_and_show(char_trans_no_id)\n",
    "    \n",
    "    return char_lists, char_trans\n",
    "\n",
    "\"\"\"\n",
    "divides by some of column and row\n",
    "\"\"\"\n",
    "def normalize_row_col_and_show(mat):\n",
    "    hm_fig, (hm_ax0, hm_ax1) = plt.subplots(nrows=1, ncols=2)\n",
    "    mat_row_norm = mat / mat.sum(axis=1, keepdims=True) # percentage in row i that go to col j\n",
    "    mat_col_norm = mat / mat.sum(axis=0, keepdims=True) # percentage in col j that came from row i\n",
    "    \n",
    "    im = hm_ax0.imshow(mat_row_norm)\n",
    "    im = hm_ax1.imshow(mat_col_norm)\n",
    "\n",
    "\"\"\"\n",
    "makes diagram about what percentage of peaks/troughs are instigated by civic lerners, by length and\n",
    "average cooperation level\n",
    "\"\"\"\n",
    "def plot_instigation_figure(model, trough_props, spike_props, spike_types):\n",
    "    \n",
    "    # what I want to plot here is \n",
    "    # 1. length of preceding trough vs. vanguard\n",
    "    # 2. mean of preceding trough vs. vanguard\n",
    "    # 3. length of succeeding trough vs. rearguard\n",
    "    # 4. mean of succeeding trough vs. rearguard\n",
    "    \n",
    "    (trough_coops, trough_lengths, \n",
    "    spike_coops, spike_lengths,\n",
    "    spike_instigators, spike_preservers) = get_spike_type_by_trough_prop(trough_props, spike_props, spike_types)\n",
    "    \n",
    "    # plot of \n",
    "\n",
    "    instig_coop_arr = np.zeros((2, 9))\n",
    "    instig_length_arr = np.zeros((2, 9))\n",
    "    preserv_length_arr = np.zeros((2, 9))\n",
    "    preserv_coop_arr = np.zeros((2, 9))\n",
    "    \n",
    "    flattened_trough_props = flatten(trough_props)\n",
    "    # print(len(flattened_trough_props))\n",
    "    lengths = [prop[\"length\"] for prop in flattened_trough_props]\n",
    "    # print(lengths, len(lengths))\n",
    "    coops = [prop[\"avg_val\"] for prop in flattened_trough_props]\n",
    "    \n",
    "    if model == \"spatial\":\n",
    "        length_cutoffs = [50, 100, 150, 200, 300, 400, 600, 1000]\n",
    "        min_coop = min(coops)\n",
    "        max_coop = 0.3\n",
    "        coop_cutoffs = [min_coop + ((max_coop - min_coop)/9)*i for i in range(1, 9)]\n",
    "    elif model == \"pinhead\":\n",
    "        min_length = min(lengths)\n",
    "        max_length = 100\n",
    "        length_cutoffs = [min_length + ((max_length - min_length) / 8)*i for i in range(1, 9)]\n",
    "        min_coop = 0.1\n",
    "        max_coop = 0.25\n",
    "        coop_cutoffs = [min_coop + ((max_coop - min_coop)/9)*i for i in range(1, 9)]\n",
    "    \n",
    "    #print(\"length_cutoffs\", length_cutoffs)\n",
    "    # print(\"coop_cutoffs\", coop_cutoffs)\n",
    "    \n",
    "    for trough_prop_list, spike_prop_list, spike_type_list in zip(trough_props, spike_props, spike_types):\n",
    "        l_trough_prop = None\n",
    "        l_spike_prop = None\n",
    "        l_spike_type = None\n",
    "        \n",
    "        lengths = [trough_prop[\"length\"] for trough_prop in trough_prop_list]\n",
    "        \n",
    "        for trough_prop, spike_prop, spike_type in zip(trough_prop_list, spike_prop_list, spike_type_list):\n",
    "            t_length = trough_prop[\"length\"]\n",
    "            t_coop = trough_prop[\"avg_val\"]\n",
    "        \n",
    "            length_range = find_range(t_length, length_cutoffs)\n",
    "            coop_range = find_range(t_coop, coop_cutoffs)\n",
    "            \n",
    "            \"\"\"print(\"6039 !!!! ------\")\n",
    "            print(\"t_length\", t_length)\n",
    "            print(\"t_coop\", t_coop)\n",
    "            print(\"length range\", length_range)\n",
    "            print(\"coop_range\", coop_range)\"\"\"\n",
    "\n",
    "            if l_spike_type is not None:\n",
    "                l_t_length = l_trough_prop[\"length\"]\n",
    "                l_t_coop = l_trough_prop[\"avg_val\"]\n",
    "                l_length_range = find_range(l_t_length, length_cutoffs)\n",
    "                l_coop_range = find_range(l_t_coop, coop_cutoffs)\n",
    "                \n",
    "                \"\"\"print(\"last round --\")\n",
    "                print(\"l_t_length\", l_t_length)\n",
    "                print(\"l_t_coop\", l_t_coop)\n",
    "                print(\"l_length_range\", l_length_range)\n",
    "                print(\"l_coop_range\", l_coop_range)\"\"\"\n",
    "\n",
    "                row_ind = int(l_spike_type[\"preserver\"] == \"civ\")\n",
    "                preserv_length_arr[row_ind, l_length_range] += 1\n",
    "                preserv_coop_arr[row_ind, l_coop_range] += 1\n",
    "            \n",
    "            row_ind = int(spike_type[\"instigator\"] == \"civ\")\n",
    "            instig_length_arr[row_ind, length_range] += 1\n",
    "            instig_coop_arr[row_ind, coop_range] += 1\n",
    "            \n",
    "            \"\"\"print(\"instig length arr\", instig_length_arr)\n",
    "            print(\"instig coop arr\", instig_coop_arr)\n",
    "            print(\"preserv length arr\", preserv_length_arr)\n",
    "            print(\"preserv coop arr\", preserv_coop_arr)\"\"\"\n",
    "            \n",
    "            # y = input(\"x\")\n",
    "            l_trough_prop = trough_prop\n",
    "            l_spike_prop = spike_prop\n",
    "            l_spike_type = spike_type\n",
    "    \n",
    "    # print(\"instig length arr\", instig_length_arr)\n",
    "    # print(\"instig coop arr\", instig_coop_arr)\n",
    "    # print(\"preserv length arr\", preserv_length_arr)\n",
    "    # print(\"preserv coop arr\", preserv_coop_arr)\n",
    "\n",
    "    \n",
    "    instig_coop_pct = instig_coop_arr / instig_coop_arr.sum(axis=0, keepdims=True)\n",
    "    instig_length_pct = instig_length_arr / instig_length_arr.sum(axis=0, keepdims=True)\n",
    "    preserv_coop_pct = preserv_coop_arr / preserv_coop_arr.sum(axis=0, keepdims=True)\n",
    "    preserv_length_pct = preserv_length_arr / preserv_length_arr.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    length_cutoffs = [length_cutoffs[0]  - (length_cutoffs[1] - length_cutoffs[0])] + length_cutoffs\n",
    "    coop_cutoffs = [coop_cutoffs[0] - (coop_cutoffs[1] - coop_cutoffs[0])] + coop_cutoffs\n",
    "    \n",
    "    fig1, (length_ax1, coop_ax1) = plt.subplots(nrows=1, ncols=2, figsize=(8, 1.75)) \n",
    "    plot_hist_from_buckets_freqs(length_ax1, length_cutoffs, instig_length_pct[1:,:], color_lists=[turq])\n",
    "    plot_hist_from_buckets_freqs(coop_ax1, coop_cutoffs, instig_coop_pct[1:,:], color_lists=[turq])\n",
    "    fig2, (length_ax2, coop_ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 2))\n",
    "    plot_hist_from_buckets_freqs(length_ax2, length_cutoffs, preserv_length_pct[1:,:], color_lists=[turq])\n",
    "    plot_hist_from_buckets_freqs(coop_ax2, coop_cutoffs, preserv_coop_pct[1:,:], color_lists=[turq])\n",
    "    \n",
    "    fig1.suptitle(\"Share of cooperation peaks instigated by norm internalizers\", y=1.1)\n",
    "    length_ax1.set_title(\"By trough length\")\n",
    "    coop_ax1.set_title(\"By trough cooperation average\")\n",
    "    format_grid(length_ax1, label=\"(D)\")\n",
    "    format_grid(coop_ax1, label=\"(E)\")\n",
    "    \n",
    "    \n",
    "    print(\"instig length pct\", instig_length_pct)\n",
    "    print(\"instig coop pct\", instig_coop_pct)\n",
    "    print(\"preserv length pct\", preserv_coop_pct)\n",
    "    print(\"preserv coop pct\", preserv_length_pct)\n",
    "    \n",
    "    return fig1, fig2\n",
    "\n",
    "\"\"\"\n",
    "shows how long and how many peaks there are of each type\n",
    "\"\"\"\n",
    "def characterize_peaks_of_each_type(spike_types):\n",
    "    lengths, counts = get_avg_length_of_each_type(spike_types)\n",
    "    print(lengths / counts)\n",
    "    print(counts)\n",
    "\n",
    "\"\"\"\n",
    "plots a histogram from frequency of buckets\n",
    "\"\"\"\n",
    "def plot_hist_from_buckets_freqs(ax, bucket_mins, freq_lists, color_lists, key_labels=None):\n",
    "    if key_labels is None:\n",
    "        key_labels = [None for i in range(len(color_lists))]\n",
    "        \n",
    "    for j, freqs in enumerate(freq_lists):\n",
    "        color = color_lists[j]\n",
    "        for i, (bucket_min, freq) in enumerate(zip(bucket_mins, freqs)):\n",
    "            if i != len(bucket_mins) - 1:\n",
    "                bucket_max = bucket_mins[i + 1]\n",
    "                next_freq = freqs[i + 1]\n",
    "                if i == 0:\n",
    "                    ax.plot([bucket_max, bucket_max], [freq, next_freq], color=color, label=key_labels[j])\n",
    "                else:\n",
    "                    ax.plot([bucket_max, bucket_max], [freq, next_freq], color=color) \n",
    "            else: \n",
    "                bucket_diff = bucket_min - bucket_mins[i - 1]\n",
    "                bucket_max = bucket_min + bucket_diff\n",
    "\n",
    "            ax.plot([bucket_min, bucket_max], [freq, freq], color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba420b43",
   "metadata": {},
   "source": [
    "## get the block diagram (characterizing peaks and troughs) and peak traces (where peaks are)\n",
    "## for the spatial model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(exp_spike_lists, exp_spike_props, exp_trough_props, \n",
    "con_spike_lists, con_spike_props, con_trough_props, \n",
    "civ_spike_lists, civ_spike_props, civ_trough_props, \n",
    "nci_spike_lists, nci_spike_props, nci_trough_props) = get_spike_info(\"spatial\", spatial_data_dict, 65, 0.5)\n",
    "\n",
    "print(\"---\\nINCLUDE\")\n",
    "print(\"Stats on internalizer spikes vs non-internalizer spikes: \\n1 - internalizer, \\n2 - non-internalizer\")\n",
    "fig = make_block_diagram(civ_spike_props, civ_trough_props, nci_spike_props, nci_trough_props, title=\"NI vs. others\", label=\"\", legend=True)\n",
    "fig.savefig(\"figures/spatial_norm_non_norm_comparison.png\", bbox_inches=\"tight\")\n",
    "\n",
    "print(\"Stats on internalizer spikes vs non-internalizer spikes: \\n1 - experimental, \\n2 - control\")\n",
    "fig = make_block_diagram(exp_spike_props, exp_trough_props, con_spike_props, con_trough_props, title=\"NI condition vs. non-NI conditions\", label=\"\", legend=False)\n",
    "fig.savefig(\"figures/spatial_exp_con_comparison.png\", bbox_inches=\"tight\")\n",
    "print(\"---\")\n",
    "\n",
    "fig0 = peak_traces(exp_spike_lists, con_spike_lists, \"(A)\", \"(B)\")\n",
    "fig0.savefig(\"figures/spatial_peak_traces.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94047fd",
   "metadata": {},
   "source": [
    "## get the block diagram (characterizing peaks and troughs) and peak traces (where peaks are)\n",
    "## for the pinhead model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p_exp_spike_lists, p_exp_spike_props, p_exp_trough_props, \n",
    "p_con_spike_lists, p_con_spike_props, p_con_trough_props, \n",
    "p_civ_spike_lists, p_civ_spike_props, p_civ_trough_props, \n",
    "p_nci_spike_lists, p_nci_spike_props, p_nci_trough_props) = get_spike_info(\"pinhead\", pinhead_data_dict, 3.5, 0.2)\n",
    "\n",
    "print(\"---\\nINCLUDE\")\n",
    "print(\"Stats on internalizer spikes vs non-internalizer spikes: \\n1 - internalizer, \\n2 - non-internalizer\")\n",
    "fig = make_block_diagram(p_civ_spike_props, p_civ_trough_props, p_nci_spike_props, p_nci_trough_props, title=\"Abstract: Spikes and troughs in norm-internalizer\\ncooperation compared to that of other agents\", label=\"(A)\")\n",
    "fig.savefig(\"figures/pinhead_norm_non_norm_comparison.png\", bbox_inches=\"tight\")\n",
    "\n",
    "print(\"Stats on internalizer spikes vs non-internalizer spikes: \\n1 - experimental, \\n2 - control\")\n",
    "fig = make_block_diagram(p_exp_spike_props, p_exp_trough_props, p_con_spike_props, p_con_trough_props, title=\"Abstract: Spikes and troughs of cooperation in the\\n norm-internalizer condition compared to control\", label=\"(B)\")\n",
    "fig.savefig(\"figures/pinhead_exp_con_comparison.png\", bbox_inches=\"tight\")\n",
    "print(\"---\")\n",
    "\n",
    "fig0 = peak_traces(p_exp_spike_lists, p_con_spike_lists)\n",
    "fig0.savefig(\"figures/pinhead_peak_traces.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbc9c4c",
   "metadata": {},
   "source": [
    "## trough length plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1172831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plots histogram of trough length (weighted by the length)\n",
    "\"\"\"\n",
    "def plot_trough_histograms(trough_props_0, trough_props_1, bin_size, title=\"Percentage of total trough length occuring in each range\", label=\"\"):\n",
    "\n",
    "    length_dist_0, _ = length_prob_distros([trough[\"length\"] for trough in flatten(trough_props_0)], bins=None, bin_size=bin_size)\n",
    "    length_dist_1, _ = length_prob_distros([trough[\"length\"] for trough in flatten(trough_props_1)], bins=None, bin_size=bin_size)\n",
    "\n",
    "    longer_dim = max(len(length_dist_0), len(length_dist_1))\n",
    "\n",
    "    length_dist_0 = extend_dim((longer_dim), length_dist_0)\n",
    "    length_dist_1 = extend_dim((longer_dim), length_dist_1)\n",
    "\n",
    "    print(\"0: percent of weight above\", 6 * bin_size, length_dist_0[6:].sum())\n",
    "    print(\"1: percent of weight above\", 6 * bin_size, length_dist_1[6:].sum())\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 1.75))\n",
    "    plot_hist_from_buckets_freqs(ax, [i * bin_size for i in range(len(length_dist_0))], [length_dist_0, length_dist_1], [turq, med], [\"NI cond.\", \"Non-NI cond.\"])\n",
    "    ax.set_title(title)\n",
    "    format_grid(ax, label)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779494e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_trough_histograms(exp_trough_props, con_trough_props, 500, label=\"(C)\")\n",
    "ax.legend()\n",
    "fig.savefig(\"figures/spatial_trough_histogram.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29683576",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_trough_histograms(p_exp_trough_props, p_con_trough_props, 100)\n",
    "ax.legend()\n",
    "fig.savefig(\"figures/pinhead_trough_histogram.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e87c2",
   "metadata": {},
   "source": [
    "## transition probabilities for the pinhead model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa19611",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_lists, p_char_trans = make_sequence_of_states_and_trans_mat(\"pinhead\", pinhead_data_dict, 0.2, 3.5, exp=\"0.02_0\", window=10)\n",
    "row_sums = p_char_trans.sum(axis=1, keepdims=True)\n",
    "row_norm = p_char_trans / row_sums\n",
    "\n",
    "# p_char_lists, p_char_trans = make_sequence_of_states_and_trans_mat(\"pinhead\", pinhead_data_dict, 0.2, 3.5, exp=\"0_0.02\")\n",
    "print(row_norm)\n",
    "print(p_char_trans)\n",
    "print(row_sums / row_sums.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbbe6b",
   "metadata": {},
   "source": [
    "## spatial model transtion probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "    \n",
    "    \n",
    "char_lists, char_trans = make_sequence_of_states_and_trans_mat(\"spatial\", spatial_data_dict, 0.5, 65)\n",
    "row_sums = char_trans.sum(axis=1, keepdims=True)\n",
    "row_norm = char_trans / row_sums\n",
    "\n",
    "print(row_norm)\n",
    "print(char_trans)\n",
    "print(row_sums / row_sums.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2cbd9f",
   "metadata": {},
   "source": [
    "## spatial figure for spike instigation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_count, civ_start_count, civ_end_count, nc_start_count, nc_end_count, spike_type_lists = compare_civ_nc_spikes(exp_spike_lists, civ_spike_lists, nci_spike_lists)\n",
    "fig, _ = plot_instigation_figure(\"spatial\", exp_trough_props, exp_spike_props, spike_type_lists)\n",
    "fig.savefig(\"figures/spatial_instigation.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a65be",
   "metadata": {},
   "source": [
    "## pinhead figure for spike instigation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, _, p_spike_type_lists = compare_civ_nc_spikes(p_exp_spike_lists, p_civ_spike_lists, p_nci_spike_lists)\n",
    "fig, _ = plot_instigation_figure(\"pinhead\", p_exp_trough_props, p_exp_spike_props, p_spike_type_lists)\n",
    "fig.savefig(\"figures/pinhead_instigation.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71414f99",
   "metadata": {},
   "source": [
    "## gets average lengths (top) and counts (bottom) of peaks of each type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b54f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "characterize_peaks_of_each_type(spike_type_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae518ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "characterize_peaks_of_each_type(p_spike_type_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f558bb8",
   "metadata": {},
   "source": [
    "## Granger causality of relationship between coop levels and internalizer pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e559f6e",
   "metadata": {},
   "source": [
    "### first test for stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5cc303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing for stationarity\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\"\"\"\n",
    "tests if a set of lsts are each stationary\n",
    "\"\"\"\n",
    "def test_stationarity(lsts):\n",
    "    failure = False\n",
    "    for i, lst in enumerate(lsts):\n",
    "        pval = adfuller(interpolate(lst))[1]   \n",
    "        if pval > 0.001:\n",
    "            print(\"over:\", i, pval)\n",
    "            failure = True\n",
    "    \n",
    "    if not failure:\n",
    "        print(\"All stationary!\")\n",
    "\n",
    "\"\"\"\n",
    "tests if the lists from a given set of parameters are stationary\n",
    "\"\"\"\n",
    "def test_stationarity_for_params(data_dict, benefit, distrib, mig):\n",
    "    for i, (coops, civ_pop, civ_coops, nc_coops) in enumerate(zip(data_dict[mig][distrib][benefit][\"civ_coop_levels\"],\n",
    "                                                         data_dict[mig][distrib][benefit][\"civ_levels\"],\n",
    "                                                         data_dict[mig][distrib][benefit][\"coop_levels\"],\n",
    "                                                         data_dict[mig][distrib][benefit][\"nc_coop_levels\"])):\n",
    "        print(i, \"--\")\n",
    "        test_stationarity([coops, civ_pop, civ_coops, nc_coops])\n",
    "\n",
    "print(\"SPATIAL EXP\")\n",
    "test_stationarity_for_params(spatial_data_dict, 65, 0.02, 0.5)\n",
    "print(\"SPATIAL CON\")\n",
    "test_stationarity_for_params(spatial_data_dict, 65, 0, 0.5)\n",
    "\n",
    "print(\"PINHEAD EXP\")\n",
    "test_stationarity_for_params(pinhead_data_dict, 3.75, \"0.02_0\", 0.2)\n",
    "print(\"PINHEAD CON\")\n",
    "test_stationarity_for_params(pinhead_data_dict, 3.75, \"0_0.02\", 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "\"\"\"\n",
    "checks outputs of granger causality to see if they are significant\n",
    "\"\"\"\n",
    "def analyze_gc_res(gc_res):\n",
    "    # from each lag level, get the\n",
    "    # 1. significance\n",
    "    # 2. net effect (sum of coefficients)\n",
    "    # 3 R^2\n",
    "    #\n",
    "    # get the coefficients at lag 3\n",
    "    \n",
    "    self_coeff_sums = []\n",
    "    other_coeff_sums = []\n",
    "    max_ps = []\n",
    "    rsquareds = []\n",
    "\n",
    "    for test in gc_res.items():\n",
    "        lag_value = test[0]\n",
    "        results = test[1][0]\n",
    "        \n",
    "        max_p = 0\n",
    "        for result in results.values():\n",
    "            max_p = max(max_p, result[1])\n",
    "            if result[1] > 0.01:\n",
    "                print(\"failure\", result[1])\n",
    "            elif result[1] > 0.001:\n",
    "                print(\"close call\", result[1])\n",
    "            \n",
    "        lin_reg = test[1][1][1]\n",
    "        \n",
    "        if lag_value == 3:\n",
    "            three_lag_coeffs = list(lin_reg.params)\n",
    "        \n",
    "        self_coeff_sum = lin_reg.params[0:lag_value].sum()\n",
    "        other_coeff_sum = lin_reg.params[lag_value:2*lag_value].sum()\n",
    "        \n",
    "        self_coeff_sums.append(self_coeff_sum)\n",
    "        other_coeff_sums.append(other_coeff_sum)\n",
    "        rsquareds.append(lin_reg.rsquared)\n",
    "        max_ps.append(max_p)\n",
    "    \n",
    "    return self_coeff_sums, other_coeff_sums, max_ps, rsquareds, three_lag_coeffs\n",
    "\n",
    "\"\"\"\n",
    "runs the granger tests for 10 lags on forward and backward dfs\n",
    "\"\"\"\n",
    "def run_granger_tests_forward_and_backward(lst1, lst2, long_step=50):\n",
    "    forward_df = pd.DataFrame(columns=[\"t2\", \"t1\"], data=zip(lst2, lst1))\n",
    "    l_forward_df = pd.DataFrame(columns=[\"t2\", \"t1\"], data=zip(lst2[::long_step], lst1[::long_step]))\n",
    "    \n",
    "    backward_df = pd.DataFrame(columns=[\"t2\", \"t1\"], data=zip(lst1, lst2))\n",
    "    l_backward_df = pd.DataFrame(columns=[\"t2\", \"t1\"], data=zip(lst1[::long_step], lst2[::long_step]))\n",
    "    \n",
    "    dfs = {\"forward_df\": forward_df, \n",
    "           \"l_forward_df\": l_forward_df, \n",
    "           \"backward_df\": backward_df, \n",
    "           \"l_backward_df\": l_backward_df}\n",
    "    \n",
    "    for name, df in dfs.items():\n",
    "        res = grangercausalitytests(df, 10)\n",
    "        print(name)\n",
    "        anal = analyze_gc_res(res)\n",
    "        print(\"self coeff sums\", anal[0])\n",
    "        print(\"other coeff sums\", anal[1])\n",
    "        print(\"max_ps\", anal[2])\n",
    "        print(\"rsquareds\", anal[3])\n",
    "        print(\"three lag coeffs\", anal[4])\n",
    "    \n",
    "\"\"\"\n",
    "runs granger tests on cooperation, civic cooperation, and civic population\n",
    "\"\"\"\n",
    "def run_all_granger(data_dict, benefit, mig, distrib):\n",
    "    coop_lol = data_dict[mig][distrib][benefit][\"coop_levels\"]\n",
    "    combined_coop = flatten(coop_lol)\n",
    "    \n",
    "    pop_lol = data_dict[mig][distrib][benefit][\"civ_levels\"]\n",
    "    combined_civ_pop = flatten(pop_lol)\n",
    "    \n",
    "    civ_coop_lol = data_dict[mig][distrib][benefit][\"civ_coop_levels\"]\n",
    "    civ_coop_lol = [interpolate(lst) for lst in civ_coop_lol]\n",
    "    combined_civ_coop = flatten(civ_coop_lol)\n",
    "    \n",
    "    print(\"--\\nINCLUDE\\n ->\")\n",
    "    print(\"TOTAL COOP <-> CIV POP\")\n",
    "    run_granger_tests_forward_and_backward(combined_coop, combined_civ_pop)\n",
    "\n",
    "    print(\"CIV COOP <-> CIV POP\")\n",
    "    run_granger_tests_forward_and_backward(combined_civ_coop, combined_civ_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_granger(spatial_data_dict, 65, 0.5, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331f022",
   "metadata": {},
   "source": [
    "## Calculate significance of difference between two conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribs = [0.00, 0.02]\n",
    "benefits = [55, 60, 65, 70, 75]\n",
    "migs = [0, 0.005, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "\"\"\"\n",
    "calculates the significance of the difference between the two conditions \n",
    "\"\"\"\n",
    "def calc_significance(model, data_dict, params):\n",
    "    if model == \"spatial\":\n",
    "        civic = 0.02\n",
    "        saint = 0\n",
    "    elif model == \"pinhead\":\n",
    "        civic = \"0.02_0\"\n",
    "        saint = \"0_0.02\"\n",
    "    \n",
    "    distribs = params[\"distrib\"]\n",
    "    benefits = params[\"b\"]\n",
    "    migs = params[\"ps\"]\n",
    "    \n",
    "    nc_sig_labels = {benefit: {} for benefit in benefits}\n",
    "    sig_labels = {benefit: {} for benefit in benefits}\n",
    "\n",
    "    for benefit in benefits:\n",
    "        for mig in migs:\n",
    "            # key is present and it is not just an empty dict\n",
    "            if benefit in data_dict[mig][civic] and data_dict[mig][civic][benefit]: \n",
    "                print(benefit, mig)\n",
    "                diff_level_mean = data_dict[mig][civic][benefit][\"coop_mean\"] - data_dict[mig][saint][benefit][\"coop_mean\"]\n",
    "                diff_level_var = data_dict[mig][civic][benefit][\"coop_se\"]**2 + data_dict[mig][saint][benefit][\"coop_se\"]**2\n",
    "                diff_level_std = math.sqrt(diff_level_var)\n",
    "\n",
    "                diff_nc_level_mean = data_dict[mig][civic][benefit][\"nc_coop_mean\"] - data_dict[mig][saint][benefit][\"nc_coop_mean\"]\n",
    "                diff_nc_level_var = data_dict[mig][civic][benefit][\"nc_coop_se\"]**2 + data_dict[mig][saint][benefit][\"nc_coop_se\"]**2\n",
    "                diff_nc_level_std = math.sqrt(diff_nc_level_var)\n",
    "\n",
    "                level_t_score = abs(diff_level_mean/diff_level_std)\n",
    "                df = min(len(data_dict[mig][saint][benefit][\"coop_levels\"]), len(data_dict[mig][civic][benefit][\"coop_levels\"])) - 1\n",
    "                print(\"c t stat\", diff_level_mean, diff_level_std, df, level_t_score)\n",
    "                p_value = scipy.stats.t.sf(level_t_score, df=df)*2\n",
    "\n",
    "                nc_level_t_score = abs(diff_nc_level_mean/diff_nc_level_std)\n",
    "                \n",
    "                print(\"nc t stat\", diff_nc_level_mean, diff_nc_level_std, df, nc_level_t_score)\n",
    "                nc_p_value = scipy.stats.t.sf(nc_level_t_score, df=df)*2\n",
    "\n",
    "                diff_level_conf = [diff_level_mean - diff_level_std *3.291, diff_level_mean + diff_level_std *3.291]\n",
    "                small_diff_level_conf = [diff_level_mean - diff_level_std *2.58, diff_level_mean + diff_level_std *2.58]\n",
    "                tiny_diff_level_conf = [diff_level_mean - diff_level_std *2.33, diff_level_mean + diff_level_std *2.33]\n",
    "                print(f\"The mean difference is {round(diff_level_mean, 2)}.\")\n",
    "                print(f\"The mean standard deviation is {diff_level_std}\")\n",
    "                print(f\"The p value is {p_value}\")\n",
    "                print(f\"The 0.999 confidence interval for the difference of benefit {benefit} is from {round(diff_level_conf[0], 2)} to {round(diff_level_conf[1], 2)}\")\n",
    "                print(f\"The 0.99 confidence interval for the difference of benefit {benefit} is from {round(small_diff_level_conf[0], 2)} to {round(small_diff_level_conf[1], 2)}\")\n",
    "                print(f\"The 0.98 confidence interval for the difference of benefit {benefit} is from {round(tiny_diff_level_conf[0], 2)} to {round(tiny_diff_level_conf[1], 2)}\")\n",
    "\n",
    "\n",
    "                if p_value < 0.0001:\n",
    "                    sig_label = \"***\"\n",
    "                elif p_value < 0.001:\n",
    "                    sig_label = \"**\"\n",
    "                elif p_value < 0.01:\n",
    "                    sig_label = \"*\"\n",
    "                else:\n",
    "                    sig_label = \"\"\n",
    "\n",
    "\n",
    "                diff_nc_level_conf = [diff_nc_level_mean - diff_nc_level_std *3.291, diff_nc_level_mean + diff_nc_level_std *3.291]  \n",
    "                small_diff_nc_level_conf = [diff_nc_level_mean - diff_nc_level_std *2.58, diff_nc_level_mean + diff_nc_level_std *2.58]\n",
    "                tiny_diff_nc_level_conf = [diff_nc_level_mean - diff_nc_level_std *2.33, diff_nc_level_mean + diff_nc_level_std *2.33]\n",
    "\n",
    "                print(f\"The mean difference is {round(diff_nc_level_mean, 2)}.\")\n",
    "                print(f\"The mean standard deviation is {diff_nc_level_std}\")\n",
    "                print(f\"The p value is {nc_p_value}\")\n",
    "                print(f\"The 0.999 confidence interval for the difference of benefit {benefit} is from {round(diff_nc_level_conf[0], 2)} to {round(diff_nc_level_conf[1], 2)}\")\n",
    "                print(f\"The 0.99 confidence interval for the difference of benefit {benefit} is from {round(small_diff_nc_level_conf[0], 2)} to {round(small_diff_nc_level_conf[1], 2)}\")\n",
    "                print(f\"The 0.98 confidence interval for the difference of benefit {benefit} is from {round(tiny_diff_nc_level_conf[0], 2)} to {round(tiny_diff_nc_level_conf[1], 2)}\")\n",
    "\n",
    "                if nc_p_value < 0.0001:\n",
    "                    nc_sig_label = \"***\"\n",
    "                elif nc_p_value < 0.001:\n",
    "                    nc_sig_label = \"**\"\n",
    "                elif nc_p_value < 0.01:\n",
    "                    nc_sig_label = \"*\"\n",
    "                else:\n",
    "                    nc_sig_label = \"\"\n",
    "\n",
    "                sig_labels[benefit][mig] = (sig_label, p_value, diff_level_std, diff_nc_level_std)\n",
    "                nc_sig_labels[benefit][mig] = (nc_sig_label, nc_p_value)\n",
    "                print(\"--------------------------\")\n",
    "                \n",
    "    return sig_labels, nc_sig_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48e301",
   "metadata": {},
   "source": [
    "### get significance figures for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_sig_labels, spatial_nc_sig_labels = calc_significance(\"spatial\", spatial_data_dict, params_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40453c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinhead_sig_labels, pinhead_nc_sig_labels = calc_significance(\"pinhead\", pinhead_data_dict, params_pinhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.t.sf(0.14 / 0.006, df=8)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc384bf",
   "metadata": {},
   "source": [
    "## Plots summary figures (migration vs. cooperation levels for different b2c)\n",
    "## labeled with significance stars from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d87d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "puts error bars on the dots in the summary plot\n",
    "\"\"\"\n",
    "def plot_error_bars(data_dict, ax, dict_prefix, benefit, distrib, migs, xs=None):\n",
    "    if xs is None:\n",
    "        xs = migs\n",
    "    \n",
    "    for i, mig in enumerate(migs):\n",
    "        coop_level = data_dict[mig][distrib][benefit][dict_prefix + \"_mean\"]\n",
    "        coop_se = data_dict[mig][distrib][benefit][dict_prefix + \"_se\"]\n",
    "        # 95% confidence intervals\n",
    "        ax.plot([xs[i], xs[i]], [coop_level - coop_se * 2.306, coop_level + coop_se *2.306], color=dark, zorder=6, lw=0.5, alpha=0.5)\n",
    "\n",
    "\"\"\"\n",
    "puts stars signifying the significance on things\n",
    "\"\"\"\n",
    "def add_error_stars(data_dict, ax, benefit, migs, sig_labels, nc_sig_labels, civic):\n",
    "    ylim = ax.get_ylim()\n",
    "    yrange = abs(ylim[1] - ylim[0])\n",
    "    \n",
    "    for mig in migs:\n",
    "        p_value_civ = sig_labels[benefit][mig][1]\n",
    "        p_value_nc = nc_sig_labels[benefit][mig][1]\n",
    "        \n",
    "        # choose the less significant sig label\n",
    "        if p_value_civ > p_value_nc:\n",
    "            sig_label = sig_labels[benefit][mig][0]\n",
    "        else:\n",
    "            sig_label = nc_sig_labels[benefit][mig][0]\n",
    "        \n",
    "        high_civ_est = data_dict[mig][civic][benefit][\"civ_coop_mean\"] + data_dict[mig][civic][benefit][\"civ_coop_se\"]\n",
    "        high_coop_est = data_dict[mig][civic][benefit][\"coop_mean\"] + data_dict[mig][civic][benefit][\"coop_se\"]\n",
    "        high_nc_est = data_dict[mig][civic][benefit][\"nc_coop_mean\"] + data_dict[mig][civic][benefit][\"nc_coop_se\"]\n",
    "        starting_point = max(high_coop_est, high_nc_est)\n",
    "        starting_point = starting_point if high_civ_est < starting_point or (high_civ_est - starting_point) > (0.1 * yrange) else high_civ_est\n",
    "        \n",
    "        ax.text(mig, starting_point + yrange * 0.02, sig_label, ha=\"center\", va=\"center\")\n",
    "\n",
    "\"\"\"\n",
    "plots the summary figures\n",
    "\"\"\"      \n",
    "def plot_coop_levels_mig(model, data_dict, benefits, migs, sig_labels, nc_sig_labels):\n",
    "    if model == \"spatial\":\n",
    "        civic = 0.02\n",
    "        saint = 0\n",
    "    else:\n",
    "        civic = \"0.02_0\"\n",
    "        saint = \"0_0.02\"\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(benefits), figsize=(14,3))\n",
    "    \n",
    "    # make a separate graph for every benefit level\n",
    "    \n",
    "    for i, benefit in enumerate(benefits):\n",
    "        ax = axs[i]\n",
    "            \n",
    "        restricted_migs = [mig for mig in migs if data_dict[mig][civic][benefit]]\n",
    "\n",
    "        exp_tot_coops = [data_dict[mig][civic][benefit][\"coop_mean\"] for mig in restricted_migs]\n",
    "        exp_civ_coops = [data_dict[mig][civic][benefit][\"civ_coop_mean\"] for mig in restricted_migs]\n",
    "        exp_nci_coops = [data_dict[mig][civic][benefit][\"nc_coop_mean\"] for mig in restricted_migs]\n",
    "        \n",
    "        con_tot_coops = [data_dict[mig][saint][benefit][\"coop_mean\"] for mig in restricted_migs]\n",
    "        \n",
    "        # nc_coops = [data_dict[mig][civic][benefit][\"nc_coop_mean\"] for mig in restricted_migs]\n",
    "        # tot_sai_coops = [data_dict[mig][saint][benefit][\"coop_mean\"] for mig in restricted_migs]\n",
    "        \n",
    "        \"\"\"this just finds the effective migration rates\"\"\"\n",
    "        # civ_migs = [spatial_data_dict[mig][0.02][benefit][\"eff_mig\"] for mig in restricted_migs]\n",
    "        # sai_migs = [spatial_data_dict[mig][0.00][benefit][\"eff_mig\"] for mig in restricted_migs]\n",
    "        \n",
    "        civ_xs = [rm - 0.01 for rm in restricted_migs]\n",
    "        ax.scatter(civ_xs, exp_civ_coops, color=turq, s=90, alpha=0.7, zorder=5, label=\"NI cond., NIs\")\n",
    "        # plot_error_bars(data_dict, ax, \"civ_coop\", benefit, civic, restricted_migs, xs=civ_xs)\n",
    "        \n",
    "        tot_xs = [rm for rm in restricted_migs]\n",
    "        ax.scatter(tot_xs, exp_tot_coops, color=med, s=90, alpha=0.7, zorder=4, label=\"NI cond., total\")\n",
    "        plot_error_bars(data_dict, ax, \"coop\", benefit, civic, restricted_migs, xs=tot_xs)\n",
    "        \n",
    "        nc_xs = [rm + 0.01 for rm in restricted_migs]\n",
    "        ax.scatter(nc_xs, exp_nci_coops, color=red, s=90, alpha=0.7, zorder=3, label=\"NI cond., non-NIs\")\n",
    "        # plot_error_bars(data_dict, ax, \"nc_coop\", benefit, civic, restricted_migs, xs=nc_xs)\n",
    "        \n",
    "        \n",
    "        ax.scatter(restricted_migs, con_tot_coops, color=dark, s=90, alpha=0.7, zorder=2, label=\"No NI cond., total\")\n",
    "        plot_error_bars(data_dict, ax, \"coop\", benefit, saint, restricted_migs)\n",
    "        \n",
    "        add_error_stars(data_dict, ax, benefit, restricted_migs, sig_labels, nc_sig_labels, civic)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ax.set_title(str(benefit / 20) if model == \"spatial\" else str(benefit))\n",
    "        \n",
    "        if model == \"spatial\" and i == 0:\n",
    "                ax.legend(loc='upper right') #, bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        format_grid(ax, label=\"\")\n",
    "            \n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Average cooperation\")\n",
    "        if i == 1:\n",
    "            ax.set_xlabel(\"Migration rate\")\n",
    "           \n",
    "    \n",
    "    if model == \"spatial\":\n",
    "        fig.suptitle(\"Level of cooperation vs. migration rate, by benefit to cost and condition\\nNaturalistic\", y=1.1, linespacing=2)\n",
    "            \n",
    "    elif model == \"pinhead\":\n",
    "        fig.suptitle(\"Abstract\", y=1.025)\n",
    "        \n",
    "                     \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe46f9d",
   "metadata": {},
   "source": [
    "## make the summary figures for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec05283",
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits = [60, 65, 70]\n",
    "migs = [0.005, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "fig, axs = plot_coop_levels_mig(\"spatial\", spatial_data_dict, benefits, migs, spatial_sig_labels, spatial_nc_sig_labels)\n",
    "fig.savefig(\"figures/spatial_summary.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits = [3.25, 3.5, 3.75]\n",
    "migs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "fig, axs = plot_coop_levels_mig(\"pinhead\", pinhead_data_dict, benefits, migs, pinhead_sig_labels, pinhead_nc_sig_labels)\n",
    "fig.savefig(\"figures/pinhead_summary.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1690e69",
   "metadata": {},
   "source": [
    "## show the variability of civic vs non civic learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a402ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plots the variability of the cooperation of different agent types, and prints the mean and SD\n",
    "\"\"\"\n",
    "def get_variability_numbers(data_dict, mig, ben, distrib, pref=\"\"):\n",
    "    # Variability of civic coop levels vs. noncivic coop levels\n",
    "    e_nc_coop_sequence = [nc_coop for nc_coop in data_dict[mig][distrib][ben][\"nc_coop_levels\"]]\n",
    "    e_civ_coop_sequence = [interpolate(civ_coop) for civ_coop in data_dict[mig][distrib][ben][\"civ_coop_levels\"]]\n",
    "    \n",
    "    combined_nc_coop = []\n",
    "    [(combined_nc_coop := combined_nc_coop + nc_coop) for nc_coop in e_nc_coop_sequence]\n",
    "    \n",
    "\n",
    "    mean, sd, _ = calc_mean_sd_se(combined_nc_coop)\n",
    "    print(\"nc coop\", mean, sd)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(4,3))\n",
    "    combined_civ_coop = []\n",
    "    [(combined_civ_coop := combined_civ_coop + nc_coop) for nc_coop in e_civ_coop_sequence]\n",
    "    ax.hist(combined_civ_coop, density=True, edgecolor=turq, fill=False, hatch=\"///\", histtype='step', label=\"NI\")\n",
    "    ax.hist(combined_nc_coop, density=True, edgecolor=med, fill=False, hatch=\"\\\\\\\\\\\\\", histtype='step', label=\"Non-NI\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Cooperation level\")\n",
    "    \n",
    "    ax.set_title(\"Cooperation distribution for\\ndifferent agent types\")\n",
    "    \n",
    "    format_grid(ax, \"(A)\")\n",
    "    mean, sd, _ = calc_mean_sd_se(combined_civ_coop)\n",
    "    \n",
    "    fig.savefig(f\"figures/{pref}_coop_level_hist.png\", bbox_inches=\"tight\")\n",
    "    print(\"civ coop\", mean, sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b164b",
   "metadata": {},
   "source": [
    "## variability numbers for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46578349",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_variability_numbers(spatial_data_dict, 0.5, 65, 0.02, pref=\"naturalistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_variability_numbers(pinhead_data_dict, 0.2, 3.5, \"0.02_0\", pref=\"abstract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3983cb4d",
   "metadata": {},
   "source": [
    "## population plotting of NIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50cd0e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "box plot of the frequency of norm internalizers\n",
    "\"\"\"\n",
    "def plot_ni_frequency(spatial_data_dict, sben, smig, sdistrib, pinhead_data_dict, pben, pmig, pdistrib):\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    meanprops_alt = dict(marker='D', markerfacecolor=red, markeredgecolor=red)\n",
    "    \n",
    "    civ_pops_spat = [flatten(spatial_data_dict[smig][sdistrib][benefit][\"civ_levels\"]) for benefit in sben]\n",
    "    civ_pops_pinh = [flatten(pinhead_data_dict[pmig][pdistrib][benefit][\"civ_levels\"]) for benefit in pben]\n",
    "    intervals = np.array(range(len(sben))) * 2\n",
    "    bp1 = make_bp(ax, civ_pops_spat, intervals - 0.25, med)\n",
    "    bp2 = make_bp(ax, civ_pops_pinh, intervals + 0.25, dark)\n",
    "    \n",
    "    ax.set_xticks(intervals)\n",
    "    ax.set_xticklabels([benefit for benefit in pben])\n",
    "    ax.set_ylabel(\"NI population share\")\n",
    "    ax.set_xlabel(\"Benefit to cost\")\n",
    "    ax.set_title(\"Norm internalizer frequency\", y=1.02)\n",
    "    ax.legend([bp1[\"boxes\"][0], bp2[\"boxes\"][0]], ['Naturalistic model', 'Abstract model'], loc='upper right')\n",
    "\n",
    "    format_grid(ax, label=\"(B)\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\"\"\"\n",
    "actually makes the box plot giveen the positions and the values\n",
    "\"\"\"\n",
    "def make_bp(ax, vals, positions, color):\n",
    "    bp = ax.boxplot(vals,\n",
    "                positions=positions,\n",
    "                patch_artist=True,\n",
    "               notch=True, showfliers=False, showmeans=True, meanprops=meanprops, medianprops=medianprops, flierprops=flierprops)\n",
    "    \n",
    "    set_box_colors(bp, color_range=[color for i in range(len(positions))])   \n",
    "    return bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf0bfe",
   "metadata": {},
   "source": [
    "### box plot of norm internalizer populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_ni_frequency(spatial_data_dict, [60, 65, 70, 75], 0.5, 0.02, pinhead_data_dict, [3, 3.25, 3.5, 3.75], 0.2, \"0.02_0\")\n",
    "fig.savefig(\"figures/ni_percentage.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bfebf8",
   "metadata": {},
   "source": [
    "# Group level visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae076649",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "imports the detailed json files for the parameters specified\n",
    "\"\"\"\n",
    "def collect_deet_datas(model, benefit, mig, distrib):\n",
    "    subdir = get_dirname({\"b\": benefit, \"ps\": mig, \"distrib\": distrib}, model)\n",
    "    dirname = f\"{model}/data/{subdir}\"\n",
    "    \n",
    "    # if not os.path.exists(dirname):\n",
    "        # continue\n",
    "            \n",
    "    files = os.listdir(dirname)\n",
    "    files = [file for file in files if \"deet\" in file]\n",
    "    deet_datas = []\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        print(i, file)\n",
    "        f = open(os.path.join(dirname, file))\n",
    "        deet_data = json.load(f)\n",
    "        deet_data.pop(\"params\")\n",
    "        \n",
    "        if \"demographics\" in deet_data:\n",
    "            deet_data.pop(\"demographics\")\n",
    "            \n",
    "        print(len(list(deet_data.keys())))\n",
    "        deet_datas.append(deet_data)\n",
    "    \n",
    "    return deet_datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76155ec",
   "metadata": {},
   "source": [
    "## collect the detailed data from spatial and pinhead models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_deet_datas = collect_deet_datas(\"spatial\", 65, 0.4, 0.02)\n",
    "pinhead_deet_datas = collect_deet_datas(\"pinhead\", 3.5, 0.2, \"0.02_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85f8b9",
   "metadata": {},
   "source": [
    "## process detailed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "returns how the group is indexed in the data\n",
    "\"\"\"\n",
    "def get_group_name(model, ind):\n",
    "    if model == \"spatial\":\n",
    "        return str(ind)\n",
    "    elif model == \"pinhead\":\n",
    "        return \"g\" + str(ind)\n",
    "    \n",
    "\"\"\"\n",
    "calculates averages of data and such, and sequences of group coop data, aggregating the important info\n",
    "\"\"\"\n",
    "def process_deet_stats(model, deet_datas):\n",
    "    # calculate the death rates \n",
    "    death_rate = {i/10: {\"died\": 0, \"survived\": 0} for i in range(0, 11)}\n",
    "    birth_rate = {i/10: {\"kids_born\": 0, \"total_rounds\": 0} for i in range(0, 11)}\n",
    "    population_dict = {i/10: [] for i in range(0, 11)}\n",
    "\n",
    "    # list of civic learner deviation from mean and cooperation levels in the previous rounds\n",
    "    civ_diffs = []\n",
    "    coop_levels = []\n",
    "\n",
    "    # find correlation between percentage of civic learners and \n",
    "    nc_coop_levels_long = []\n",
    "    coop_levels_long = []\n",
    "    civ_pcts = []\n",
    "\n",
    "    # list of rolling average (small window) cooperation levels in maj/min civic groups\n",
    "    coop_levels_pres_maj = []\n",
    "    coop_levels_futu_maj = []\n",
    "    coop_levels_pres_min = []\n",
    "    coop_levels_futu_min = []\n",
    "\n",
    "    # list of cooperation deviations from average in maj/min civic groups\n",
    "    coop_diffs_pres_maj = []\n",
    "    coop_diffs_futu_maj = []\n",
    "    coop_diffs_pres_min = []\n",
    "    coop_diffs_futu_min = []\n",
    "\n",
    "    high_civ_threshold = 0.2\n",
    "    \n",
    "    big_window = 20 if model == \"spatial\" else 10\n",
    "    small_window = 5 if model == \"pinhead\" else 2\n",
    "    \n",
    "    once = True\n",
    "    # collect group data from each run\n",
    "    for i, deet_data in enumerate(deet_datas):\n",
    "        print(i)\n",
    "        group = 0\n",
    "        while(True):\n",
    "            relevant_data = []\n",
    "            born = False\n",
    "\n",
    "            window_nc_coop = []\n",
    "            window_coop = []\n",
    "            window_civ = []\n",
    "\n",
    "\n",
    "            # gather up all necessary values for each year\n",
    "            group_name = get_group_name(model, group)\n",
    "                \n",
    "            for year, dat in deet_data.items():\n",
    "                # group is alive\n",
    "                \n",
    "                if group_name in dat['groups']:\n",
    "                    born = True # so that we know if the group is dead or if it is unborn\n",
    "                    little_dat = dat['groups'][group_name] # the data dictionary for the group this year\n",
    "\n",
    "                    pop, non_civic_pop = population(little_dat) # add up the population \n",
    "\n",
    "                    civ_pct = little_dat[\"civ\"][\"pop\"]/pop # find the percentage of civic learners\n",
    "                    window_civ.append(civ_pct) # add it to a rolling window to calculate mean\n",
    "\n",
    "                    cooperators, non_civic_cooperators = total_coop_level(little_dat) # get the total number of cooperators\n",
    "                    coop = cooperators/pop # calculate the percentage of cooperators\n",
    "                    noncivic_coop = 0 if non_civic_pop == 0 else non_civic_cooperators/non_civic_pop # percentage of noncivic cooperators\n",
    "                    window_nc_coop.append(noncivic_coop)\n",
    "                    window_coop.append(coop) # add it to rolling window to calculate mean\n",
    "\n",
    "                    # once the rolling windows become bigger than needed, remove the first element\n",
    "                    if len(window_coop) > big_window:\n",
    "                        window_coop.pop(0)\n",
    "                    if len(window_nc_coop) > big_window:\n",
    "                        window_coop.pop(0)\n",
    "                    if len(window_civ) > big_window:\n",
    "                        window_civ.pop(0)\n",
    "\n",
    "                    # average for the whole window\n",
    "                    bwindow_coop_avg = sum(window_coop)/len(window_coop)\n",
    "                    bwindow_civ_avg = sum(window_civ)/len(window_civ)\n",
    "                    bwindow_nc_coop_avg= sum(window_nc_coop)/len(window_nc_coop)\n",
    "\n",
    "                    # average for a smaller window that is closer to the present\n",
    "                    swindow_coop_avg = sum(window_coop[-small_window:])/len(window_coop[-small_window:])\n",
    "                    swindow_civ_avg = sum(window_civ[-small_window:])/len(window_civ[-small_window:])\n",
    "                    swindow_nc_coop_avg= sum(window_nc_coop[-small_window:])/len(window_nc_coop[-small_window:])\n",
    "\n",
    "                    coop_bucket = round(bwindow_coop_avg, 1)\n",
    "                    # keep track of all the data\n",
    "                    relevant_data.append({\"pop\": pop, \n",
    "                                          \"coop\": coop,\n",
    "                                          \"non_civic_coop\": noncivic_coop,\n",
    "                                          \"civ_pct\": civ_pct, \n",
    "                                          \"bwindow_coop_avg\": bwindow_coop_avg, \n",
    "                                          \"swindow_coop_avg\": swindow_coop_avg,\n",
    "                                          \"bwindow_civ_avg\": bwindow_civ_avg,\n",
    "                                          \"swindow_civ_avg\": swindow_civ_avg,\n",
    "                                          \"bwindow_nc_coop_avg\": bwindow_nc_coop_avg,\n",
    "                                          \"swindow_nc_coop_avg\": swindow_nc_coop_avg\n",
    "                                         })\n",
    "\n",
    "                    death_rate[coop_bucket][\"survived\"] += 1\n",
    "\n",
    "                    if \"exp\" in little_dat and little_dat[\"exp\"] is not None:\n",
    "                        birth_rate[coop_bucket][\"kids_born\"] += 1\n",
    "\n",
    "                    birth_rate[coop_bucket][\"total_rounds\"] += 1\n",
    "\n",
    "                    population_dict[coop_bucket].append(pop)\n",
    "\n",
    "                elif born: # group was born and died\n",
    "                    coop_bucket = round(bwindow_coop_avg, 1)\n",
    "                    death_rate[coop_bucket][\"died\"] += 1\n",
    "\n",
    "                    break\n",
    "\n",
    "            # the last group was never born\n",
    "            if not born:\n",
    "                print(group_name)\n",
    "                break\n",
    "\n",
    "            # make a dataframe\n",
    "            df = pd.DataFrame(relevant_data)\n",
    "            df[\"coop_deviation\"] = df[\"swindow_coop_avg\"] - df[\"bwindow_coop_avg\"]\n",
    "            df[\"civ_deviation\"] = df[\"swindow_civ_avg\"] - df[\"bwindow_civ_avg\"]\n",
    "            df[\"coop_deviation_future\"] = df[\"coop_deviation\"].shift(-small_window)\n",
    "            df[\"swindow_coop_avg_future\"] = df[\"swindow_coop_avg\"].shift(-small_window)\n",
    "\n",
    "            # constructs the lists of cooperation DIFFERENCES in majority civic vs. minority civic situations\n",
    "            diffs_lag_df = df.loc[big_window:len(df) - small_window - 1,[\"coop_deviation\", \"coop_deviation_future\", \"civ_pct\"]]\n",
    "            maj_civ_diff_df = diffs_lag_df.loc[diffs_lag_df.civ_pct > high_civ_threshold, :]\n",
    "            min_civ_diff_df = diffs_lag_df.loc[diffs_lag_df.civ_pct <= high_civ_threshold, :]\n",
    "\n",
    "            coop_diffs_pres_maj += list(maj_civ_diff_df.loc[:,\"coop_deviation\"])\n",
    "            coop_diffs_futu_maj += list(maj_civ_diff_df.loc[:,\"coop_deviation_future\"])\n",
    "\n",
    "            coop_diffs_pres_min += list(min_civ_diff_df.loc[:,\"coop_deviation\"])\n",
    "            coop_diffs_futu_min += list(min_civ_diff_df.loc[:,\"coop_deviation_future\"])\n",
    "\n",
    "\n",
    "            # constructs the lists of cooperation LEVELS in majority civic vs. minority civic situations\n",
    "            levels_lag_df = df.loc[small_window:len(df) - small_window - 1,[\"swindow_coop_avg\", \"swindow_coop_avg_future\", \"civ_pct\"]]\n",
    "            maj_civ_level_df = levels_lag_df.loc[levels_lag_df.civ_pct > high_civ_threshold, :]\n",
    "            min_civ_level_df = levels_lag_df.loc[levels_lag_df.civ_pct <= high_civ_threshold, :]\n",
    "\n",
    "            coop_levels_pres_maj += list(maj_civ_level_df.loc[:,\"swindow_coop_avg\"])\n",
    "            coop_levels_futu_maj += list(maj_civ_level_df.loc[:,\"swindow_coop_avg_future\"])\n",
    "\n",
    "            coop_levels_pres_min += list(min_civ_level_df.loc[:,\"swindow_coop_avg\"])\n",
    "            coop_levels_futu_min += list(min_civ_level_df.loc[:,\"swindow_coop_avg_future\"])\n",
    "\n",
    "\n",
    "            # constructs lists of civic learner differences and coop levels\n",
    "            coop_levels += list(df.loc[big_window - small_window:len(df) - small_window - 1, \"swindow_coop_avg\"])\n",
    "            civ_diffs += list(df.loc[big_window:, \"civ_deviation\"])\n",
    "\n",
    "            # constructs lists of cooperation levels and civic learner levels \n",
    "            coop_levels_long += list(df.loc[small_window:, \"swindow_coop_avg\"])\n",
    "            nc_coop_levels_long += list(df.loc[small_window:, \"swindow_nc_coop_avg\"])\n",
    "            civ_pcts += list(df.loc[small_window:, \"swindow_civ_avg\"])\n",
    "            \n",
    "            increment = 5 if model == \"spatial\" else 11 # TODO change back once finished debugging (1 and 3)\n",
    "            group += increment\n",
    "    \n",
    "    print(\"done\")\n",
    "    return  (coop_levels_long, nc_coop_levels_long, civ_pcts, civ_diffs, coop_levels,\n",
    "             coop_levels_pres_maj, coop_levels_futu_maj, coop_levels_pres_min, coop_levels_futu_min,\n",
    "             coop_diffs_pres_maj, coop_diffs_futu_maj, coop_diffs_pres_min, coop_diffs_futu_min,\n",
    "             birth_rate, death_rate, population_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981b735d",
   "metadata": {},
   "source": [
    "## collect the spatial and pinhead detailed stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac139f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "(coop_levels_long, nc_coop_levels_long, civ_pcts, civ_diffs, coop_levels,\n",
    " coop_levels_pres_maj, coop_levels_futu_maj, coop_levels_pres_min, coop_levels_futu_min,\n",
    " coop_diffs_pres_maj, coop_diffs_futu_maj, coop_diffs_pres_min, coop_diffs_futu_min, \n",
    " birth_rate, death_rate, population_dict) = process_deet_stats(\"spatial\", spatial_deet_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p_coop_levels_long, p_nc_coop_levels_long, p_civ_pcts, p_civ_diffs, p_coop_levels,\n",
    " p_coop_levels_pres_maj, p_coop_levels_futu_maj, p_coop_levels_pres_min, p_coop_levels_futu_min,\n",
    " p_coop_diffs_pres_maj, p_coop_diffs_futu_maj, p_coop_diffs_pres_min, p_coop_diffs_futu_min,\n",
    " p_birth_rate, p_death_rate, p_population_dict) = process_deet_stats(\"pinhead\", pinhead_deet_datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c916636",
   "metadata": {},
   "source": [
    "## Cooperation levels as function of civic percentage (polarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee63ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "aggregates the statistics (mean cooperation level, sd cooperation level) for every bucket of NI fraction\n",
    "\"\"\"\n",
    "def aggregate_bucket_statistics(coop_levels, nc_coop_levels, civ_fracts):    \n",
    "    # make arrays for the quantities of interest\n",
    "    coop_levels_arr = np.array(coop_levels).reshape(-1, 1)\n",
    "    nc_coop_levels_arr= np.array(nc_coop_levels).reshape(-1, 1)\n",
    "    civ_pct_arr = np.array(civ_fracts).reshape(-1, 1)\n",
    "\n",
    "    # the mean level of cooperation\n",
    "    coop_means = []\n",
    "    nc_coop_means = []\n",
    "\n",
    "    # the standard errors for the levels of cooperation\n",
    "    coop_ses = []\n",
    "    nc_coop_ses = []\n",
    "\n",
    "    # the ratio of (rounds under 20% coop)/(rounds under 80% coop)\n",
    "    ratios = []\n",
    "    ratio_ses = []\n",
    "\n",
    "    for bucket in range(10):\n",
    "        floor = bucket / 10\n",
    "        mask = np.logical_and(floor <= civ_pct_arr, civ_pct_arr <= floor + 0.1)\n",
    "\n",
    "        # mean and variance levels of cooperation for the bucket\n",
    "        coop_levels_for_bucket = coop_levels_arr[mask]\n",
    "        nc_coop_levels_for_bucket = nc_coop_levels_arr[mask]\n",
    "\n",
    "        mean = np.mean(coop_levels_for_bucket)\n",
    "        variance = np.var(coop_levels_for_bucket)\n",
    "\n",
    "        nc_mean = np.mean(nc_coop_levels_for_bucket)\n",
    "        nc_variance = np.var(nc_coop_levels_for_bucket)\n",
    "\n",
    "\n",
    "        # ratio of rounds under 20 to rounds under 80\n",
    "        mask_low = coop_levels_for_bucket < 0.2\n",
    "        mask_not_high = coop_levels_for_bucket < 0.8\n",
    "\n",
    "        low_percentage = np.sum(mask_low)/np.sum(mask_not_high)\n",
    "        low_percentage_error = math.sqrt(low_percentage*(1 - low_percentage)/np.sum(mask_not_high)) # binomial variance estimate\n",
    "\n",
    "        # add to the lists\n",
    "        coop_means.append(mean)\n",
    "        coop_ses.append(math.sqrt(variance/len(coop_levels_for_bucket)))\n",
    "        ratios.append(low_percentage)\n",
    "        ratio_ses.append(low_percentage_error)\n",
    "\n",
    "        nc_coop_means.append(nc_mean)\n",
    "        nc_coop_ses.append(math.sqrt(variance/len(nc_coop_levels_for_bucket)))\n",
    "\n",
    "        print(\"civ level\", floor, \"average coop\", mean, \"variance of coop\", variance, \"ratio\", low_percentage)\n",
    "    \n",
    "    return coop_means, coop_ses, nc_coop_means, nc_coop_ses, ratios, ratio_ses #, bucket_coop_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bd782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out what percentage of groups below 80% percent cooperation were also below 20% cooperation, \n",
    "# when they were majority civic\n",
    "\n",
    "def less_eighty_less_twenty(civ_pct_arr, coop_levels_arr):\n",
    "    mask = 0.5 < civ_pct_arr\n",
    "    maj_civic_coop_levels = coop_levels_arr[mask]\n",
    "\n",
    "    mask_low = maj_civic_coop_levels < 0.2\n",
    "    mask_not_high = maj_civic_coop_levels < 0.8\n",
    "\n",
    "    low_percentage = np.sum(mask_low)/np.sum(mask_not_high)\n",
    "\n",
    "    print(\"Among groups that were majority civic and had less than 80% cooperation,\", low_percentage, \"were less than 20%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"spatial\")\n",
    "less_eighty_less_twenty(np.array(civ_pcts), np.array(coop_levels_long))\n",
    "print(\"pinhead\")\n",
    "less_eighty_less_twenty(np.array(p_civ_pcts), np.array(p_coop_levels_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3dc98",
   "metadata": {},
   "source": [
    "### make the polarize figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f71b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plot NI percentage on x axis and cooperation level on the y axis, for each group\n",
    "\"\"\"\n",
    "def make_polarize_figure(coop_levels, nc_coop_levels, civ_fracts, pref=\"\"):\n",
    "    coop_means, coop_ses, nc_coop_means, nc_coop_ses, ratios, ratio_ses = aggregate_bucket_statistics(coop_levels, nc_coop_levels, civ_fracts)\n",
    "    # for the paper\n",
    "    fig, (coop_con_ax, ratio_ax) = plt.subplots(nrows=1, ncols=2, figsize=(12, 1.75))\n",
    "    # coop_con_fig = plt.figure(figsize=(6.4,3))\n",
    "    nc_coop_con_fig = plt.figure(figsize=(6.4, 3))\n",
    "    # ratio_fig = plt.figure(figsize=(6.4, 2))\n",
    "\n",
    "    # coop_con_ax = coop_con_fig.add_subplot(1, 1, 1)\n",
    "    nc_coop_con_ax = nc_coop_con_fig.add_subplot(1, 1, 1)\n",
    "    # ratio_ax = ratio_fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # figure for coop vs conscience prevalence\n",
    "    coop_con_ax.scatter(civ_fracts[::], coop_levels[::], color=turq, alpha=0.5, s=0.01, marker=\".\", zorder=3)\n",
    "    for i, (mean, se) in enumerate(zip(coop_means, coop_ses)):\n",
    "        coop_con_ax.plot([i/10, (i + 1)/10], [mean, mean], color=dark, zorder=5)\n",
    "        coop_con_ax.plot([(i + 0.5)/10, (i + 0.5)/10], [mean - 3.291*se, mean + 3.291*se], color='black', zorder=5)\n",
    "\n",
    "    coop_con_ax.set_title(\"Cooperation vs. norm-internalizer frequency\")\n",
    "    coop_con_ax.set_ylabel(\"Cooperation level\")\n",
    "\n",
    "    format_grid(coop_con_ax, label=\"(A)\")\n",
    "\n",
    "    # figure for non-civic coop vs conscience prevalence\n",
    "    nc_coop_con_ax.scatter(civ_fracts[::10], nc_coop_levels[::10], color=red, alpha=0.5, s=0.002, zorder=3)\n",
    "\n",
    "    for i, (mean, se) in enumerate(zip(nc_coop_means, nc_coop_ses)):\n",
    "        nc_coop_con_ax.plot([i/10, (i + 1)/10], [mean, mean], color=dark, zorder=5)\n",
    "        nc_coop_con_ax.plot([(i + 0.5)/10, (i + 0.5)/10], [mean - 3.291*se, mean + 3.291*se], color='black', zorder=5)\n",
    "\n",
    "    nc_coop_con_ax.set_title(\"Non-NI cooperation level vs.\\nprevalence of norm internalizers\")\n",
    "    nc_coop_con_ax.set_xlabel(\"Prevalence of norm internalizers\")\n",
    "    nc_coop_con_ax.set_ylabel(\"Cooperation level\")\n",
    "    format_grid(nc_coop_con_ax, label=\"\")\n",
    "\n",
    "    # figure for \n",
    "    errors = [ratio_se*3.291 for i, ratio_se in enumerate(ratio_ses) if i < 6 or pref == \"naturalistic\"]\n",
    "    X_axis = np.arange(10) / 10 if pref == \"naturalistic\" else np.arange(6) / 10\n",
    "    ratios = ratios if pref == \"naturalistic\" else ratios[:6]\n",
    "    ratio_ax.bar(X_axis, ratios, yerr=errors, color=med, width =0.095, zorder=3)\n",
    "    ratio_ax.set_xticks(X_axis)\n",
    "    ratio_ax.set_title(\"Groups <80% cooperation with <20% cooperation\")\n",
    "    ratio_ax.set_ylabel(\"Fract with <20%\\ncooperation\")\n",
    "    ratio_ax.set_xlabel(\"Prevalence of norm internalizers\")\n",
    "    coop_con_ax.set_xlabel(\"Prevalence of norm internalizers\")\n",
    "\n",
    "    format_grid(ratio_ax, \"(B)\")\n",
    "\n",
    "\n",
    "    fig.savefig(f\"figures/{pref}_coop_con.png\")\n",
    "    nc_coop_con_fig.savefig(f\"figures/{pref}_nc_coop_by_conscience_prev.png\", bbox_inches=\"tight\")\n",
    "    # ratio_fig.savefig(f\"figures/{pref}_extremity_of_coop.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_polarize_figure(coop_levels_long, nc_coop_levels_long, civ_pcts, pref=\"naturalistic\")\n",
    "make_polarize_figure(p_coop_levels_long, p_nc_coop_levels_long, p_civ_pcts, pref=\"abstract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39130e50",
   "metadata": {},
   "source": [
    "## Cooperation as a function of lagged cooperation levels (stabilize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6902ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "do regression on x array and y array\n",
    "\"\"\"\n",
    "def do_regression(coop_levels_pres, coop_levels_futu):\n",
    "    coop_p_arr = np.array(coop_levels_pres).reshape(-1, 1)\n",
    "    coop_f_arr = np.array(coop_levels_futu).reshape(-1, 1)\n",
    "    \n",
    "    coop_p_arr_const = sm.add_constant(coop_p_arr)\n",
    "\n",
    "    olsmod = sm.OLS(coop_f_arr, coop_p_arr_const)\n",
    "    olsres = olsmod.fit()\n",
    "    print(olsres.summary())\n",
    "\n",
    "    coop_f_pred = olsres.predict(coop_p_arr_const)\n",
    "    \n",
    "    return coop_p_arr, coop_f_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2ab16",
   "metadata": {},
   "source": [
    "### Make stabilize figures for the positive feedback part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17862bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "current coop vs lagged coop scatterplot with linear regression overlay\n",
    "\"\"\"\n",
    "def make_linear_reg_figures(coop_levels_pres_maj, coop_levels_futu_maj, coop_levels_pres_min, coop_levels_futu_min, pref=\"\"):\n",
    "    coop_p_maj_arr, coop_f_pred_maj = do_regression(coop_levels_pres_maj, coop_levels_futu_maj)\n",
    "    coop_p_min_arr, coop_f_min_pred = do_regression(coop_levels_pres_min, coop_levels_futu_min)\n",
    "    \n",
    "    # for paper\n",
    "    # high-civic graph\n",
    "    print(coop_levels_pres_maj[0:20])\n",
    "    print(len(coop_levels_pres_maj))\n",
    "    print(coop_levels_futu_maj[0:20])\n",
    "    print(len(coop_levels_futu_maj))\n",
    "\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(12,3))\n",
    "    \n",
    "    ax0.scatter(coop_levels_pres_maj[::], coop_levels_futu_maj[::], color=turq, alpha=0.5, s=0.002, zorder=3)\n",
    "    ax0.plot(coop_p_maj_arr, coop_p_maj_arr, color=med, zorder=4, linewidth=2)\n",
    "    ax0.plot(coop_p_maj_arr, coop_f_pred_maj, color=dark, zorder=5, linewidth=2)\n",
    "\n",
    "    ax0.set_title(\"High-NI groups: \\n Lagged (5 rounds) vs. present cooperation levels\")\n",
    "    ax0.set_xlabel(\"Lagged cooperation percentage\")\n",
    "    ax0.set_ylabel(\"Cooperation percentage\")\n",
    "\n",
    "    format_grid(ax0, label=\"(A)\")\n",
    "\n",
    "    ax1.scatter(coop_levels_pres_min[::], coop_levels_futu_min[::], s=0.002, alpha=0.5, color=red, zorder=3)\n",
    "    ax1.plot(coop_p_min_arr, coop_p_min_arr, color=med, zorder=4, linewidth=2)\n",
    "    ax1.plot(coop_p_min_arr, coop_f_min_pred, color=dark, zorder=5, linewidth=2)\n",
    "\n",
    "    ax1.set_title(\"Low-NI groups: \\n Lagged (5 rounds) vs. present cooperation levels\")\n",
    "    ax1.set_xlabel(\"Lagged cooperation percentage\")\n",
    "    # ax1.set_ylabel(\"Cooperation percentage\")\n",
    "\n",
    "    format_grid(ax1, label=\"(B)\")\n",
    "    \n",
    "    fig.savefig(f\"figures/{pref}_lagged_present_past.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5898d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_linear_reg_figures(coop_levels_pres_maj, coop_levels_futu_maj, coop_levels_pres_min, coop_levels_futu_min, pref=\"naturalistic\")\n",
    "make_linear_reg_figures(p_coop_levels_pres_maj, p_coop_levels_futu_maj, p_coop_levels_pres_min, p_coop_levels_futu_min, pref=\"abstract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd6290",
   "metadata": {},
   "source": [
    "## discrete transitions, low to high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba546767",
   "metadata": {},
   "source": [
    "### get the transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate transition matrix from low to high cooperation\n",
    "\"\"\"\n",
    "def make_lh_transition_mat(coop_levels_pres, coop_levels_futu):\n",
    "    cutoff = 0.5\n",
    "\n",
    "    matrix = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "    for pres, futu in zip(coop_levels_pres, coop_levels_futu):\n",
    "        increment = np.array([[pres <= cutoff and futu <= cutoff, pres <= cutoff and futu > cutoff], [pres > cutoff and futu <= cutoff, pres > cutoff and futu > cutoff]])\n",
    "\n",
    "        matrix += increment\n",
    "\n",
    "    print(matrix)\n",
    "    pct_matrix = matrix/matrix.sum(axis=1).reshape(2, 1)\n",
    "    print(pct_matrix)\n",
    "\n",
    "    print(\"Low coop groups that languished:\", matrix[0, 0]/(matrix[0, 0] + matrix[0, 1]))\n",
    "    print(\"Low coop groups that rose:\", matrix[0, 1]/(matrix[0, 0] + matrix[0, 1]))\n",
    "    print(\"High coop groups that fell:\", matrix[1, 0]/(matrix[1, 0] + matrix[1, 1]))\n",
    "    print(\"High coop groups that maintained:\", matrix[1, 1]/(matrix[1, 0] + matrix[1, 1]))\n",
    "\n",
    "    sd_matrix = np.sqrt(pct_matrix*(1 - pct_matrix)/matrix.sum(axis=1).reshape(2, 1))\n",
    "    conf_matrix = sd_matrix*3.291\n",
    "    \n",
    "    return pct_matrix, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ba20c1",
   "metadata": {},
   "source": [
    "### transition matrix for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HIGH CIVIC GROUPS\")\n",
    "high_s_mat, high_s_conf_mat = make_lh_transition_mat(coop_levels_pres_maj, coop_levels_futu_maj)\n",
    "print(\"LOW CIVIC GROUPS\")\n",
    "low_s_mat, low_s_conf_mat = make_lh_transition_mat(coop_levels_pres_min, coop_levels_futu_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313286e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HIGH CIVIC GROUPS\")\n",
    "high_p_mat, high_p_conf_mat = make_lh_transition_mat(p_coop_levels_pres_maj, p_coop_levels_futu_maj)\n",
    "print(\"LOW CIVIC GROUPS\")\n",
    "low_p_mat, low_p_conf_mat = make_lh_transition_mat(p_coop_levels_pres_min, p_coop_levels_futu_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d366f3",
   "metadata": {},
   "source": [
    "### make state transition figure (low to high coop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "shows a transition matrix for transitions from low to high cooperation for low and high NI groups\n",
    "\"\"\"\n",
    "def make_transition_figure(high_mat, low_mat, high_conf_mat, low_conf_mat, pref=\"\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "    fig.set_size_inches(6, 2)\n",
    "\n",
    "    fig.suptitle(\"Percentage of groups from \\n start state that go to end state\", y=1.2)\n",
    "\n",
    "    im = ax1.imshow(high_mat, cmap=light_med_dark_edge_cmap, vmin=0, vmax=1)\n",
    "\n",
    "    ax1.set_title(\"High NI\")\n",
    "    ax1.set_xticks(np.arange(2))\n",
    "    ax1.set_yticks(np.arange(2))\n",
    "    # ... and label them with the respective list entries\n",
    "    ax1.set_xticklabels([\"\", \"\"])\n",
    "    ax1.set_yticklabels([\"Low\", \"High\"])\n",
    "    ax1.set_xticks(np.arange(2))\n",
    "    ax1.set_xlabel(\"End state cooperation\")\n",
    "    ax1.set_xticklabels([\"Low\", \"High\"])\n",
    "\n",
    "    ax1.set_ylabel(\"Start state cooperation\")\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            color = 'w' if i == j else \"black\"\n",
    "            text = ax1.text(j, i - 0.075, str(round(high_mat[i, j]*100, 1)) + \"%\",\n",
    "                           ha=\"center\", va=\"center\", color=color)\n",
    "            text = ax1.text(j, i + 0.075, \"(±\" + str(round(high_conf_mat[i, j]*100, 3)) + \")\",\n",
    "                           ha=\"center\", va=\"center\", color=color)\n",
    "\n",
    "\n",
    "    im = ax2.imshow(low_mat, cmap=light_med_dark_edge_cmap, vmin=0, vmax=1)\n",
    "\n",
    "    ax2.set_title(\"Low NI\")\n",
    "    ax2.set_xticks(np.arange(2))\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xlabel(\"End state cooperation\")\n",
    "    # ... and label them with the respective list entries\n",
    "    ax2.set_xticklabels([\"Low\", \"High\"])\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            color = 'w' if i == j else \"black\"\n",
    "            text = ax2.text(j, i - 0.075, str(round(low_mat[i, j]*100, 1)) + \"%\",\n",
    "                           ha=\"center\", va=\"center\", color=color)\n",
    "            text = ax2.text(j, i + 0.075, \"(±\" + str(round(low_conf_mat[i, j]*100, 3)) + \")\",\n",
    "                           ha=\"center\", va=\"center\", color=color)\n",
    "\n",
    "    format_grid(ax1, label=\"\", show_horiz_gridlines=False)\n",
    "    format_grid(ax2, label=\"\", show_horiz_gridlines=False)\n",
    "\n",
    "    ax2.text(1.95, -1, \"(A)\", ha=\"right\", va=\"top\", fontweight='bold', fontsize=15, zorder=8)\n",
    "    fig.savefig(f\"figures/{pref}_coop_heatmap.png\", bbox_inches=\"tight\")\n",
    "    fig.savefig(f\"figures/{pref}_coop_heatmap.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_transition_figure(high_s_mat, low_s_mat, high_s_conf_mat, low_s_conf_mat, pref=\"naturalistic\")\n",
    "make_transition_figure(high_p_mat, low_p_mat, high_p_conf_mat, low_p_conf_mat, pref=\"abstract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b800a",
   "metadata": {},
   "source": [
    "### the flaw in stabilize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dadbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate the average civ change for every bucket of cooperation levels\n",
    "\"\"\"\n",
    "def get_bucket_stats_pop_change(civ_diffs, coop_levels, split=50):\n",
    "    # get arrays of desired quantities\n",
    "    coop_lvl_arr = np.array(coop_levels).reshape(-1, 1)\n",
    "    civ_diff_arr = np.array(civ_diffs).reshape(-1, 1)\n",
    "\n",
    "    print(len(coop_levels))\n",
    "\n",
    "    civ_diff_means = []\n",
    "    civ_diff_ses = []\n",
    "\n",
    "    for bucket in range(split):\n",
    "        floor = bucket / split\n",
    "        mask = np.logical_and(floor <= coop_lvl_arr, coop_lvl_arr <= floor + 1/split)\n",
    "\n",
    "        civ_diffs_for_bucket = civ_diff_arr[mask]\n",
    "        mean = np.mean(civ_diffs_for_bucket)\n",
    "        variance = np.var(civ_diffs_for_bucket)\n",
    "\n",
    "        civ_diff_means.append(mean)\n",
    "        civ_diff_ses.append(math.sqrt(variance/len(civ_diffs_for_bucket)))\n",
    "\n",
    "        print(\"bucket floor\", floor, \"mean\", mean, \"variance\", variance)\n",
    "    \n",
    "    return civ_diff_means, civ_diff_ses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903191b7",
   "metadata": {},
   "source": [
    "### make figure showing the relationship between civic population change and cooperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5db30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plot civ change vs cooperation level\n",
    "\"\"\"\n",
    "def population_change_graphic(civ_diffs, coop_levels, step=10, pref=\"\"):\n",
    "    split = 50\n",
    "    civ_diff_means, civ_diff_ses = get_bucket_stats_pop_change(civ_diffs, coop_levels, split)\n",
    "    print(len(coop_levels))\n",
    "    print(len(civ_diffs))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    ax.scatter(coop_levels[::step], civ_diffs[::step], color=med, alpha=1, s=0.005, zorder=3)\n",
    "    ax.set_ylim(bottom=-0.2, top=0.2)\n",
    "\n",
    "    for i, (mean, se) in enumerate(zip(civ_diff_means, civ_diff_ses)):\n",
    "        ax.plot([i/split, (i + 1)/split], [mean, mean], color=dark, zorder=5)\n",
    "        ax.plot([(i + 0.5)/split, (i + 0.5)/split], [mean - 3.291*se, mean + 3.291*se], color='black', zorder=6)\n",
    "\n",
    "    ax.set_title(\"Average NI change by cooperation level\")\n",
    "    ax.set_xlabel(\"Cooperation level\")\n",
    "    ax.set_ylabel(\"Change in NI frequency\")\n",
    "\n",
    "    format_grid(ax, label=\"(B)\")\n",
    "\n",
    "    fig.savefig(f\"figures/{pref}-conscience-change.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ecc82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_change_graphic(civ_diffs, coop_levels, step=10, pref=\"naturalistic\")\n",
    "population_change_graphic(p_civ_diffs, p_coop_levels, step=5, pref=\"abstract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda58249",
   "metadata": {},
   "source": [
    "# get session requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1106be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8a783",
   "metadata": {},
   "source": [
    "# end of paper code: scraps to follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c6f00fae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'civ_diff_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-1289f010e997>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mciv_diff_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mciv_diff_ses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzorder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmean\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m3.291\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m3.291\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzorder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'civ_diff_means' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ppt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.scatter(coop_levels[::500], civ_diffs[::500], color=med, alpha=0.1, s=10, marker=\".\", zorder=3)\n",
    "ax.set_ylim(bottom=-0.2, top=0.2)\n",
    "\n",
    "for i, (mean, se) in enumerate(zip(civ_diff_means, civ_diff_ses)):\n",
    "    ax.plot([i/split, (i + 1)/split], [mean, mean], color=light, zorder=5)\n",
    "    ax.plot([(i + 0.5)/split, (i + 0.5)/split], [mean - 3.291*se, mean + 3.291*se], color='black', zorder=6)\n",
    "\n",
    "ax.set_title(\"Average NI change by cooperation level\")\n",
    "ax.set_xlabel(\"Cooperation level\")\n",
    "ax.set_ylabel(\"Change in NI frequency\")\n",
    "\n",
    "format_grid(ax, label=\"\")\n",
    "\n",
    "fig.savefig(\"figures/conscience-change.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1821a",
   "metadata": {},
   "source": [
    "### Birth rates, death rates, population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1116350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# birth rates\n",
    "fig = plt.figure(figsize=(6,2))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "probs = [birth_rate[i/10][\"kids_born\"]/birth_rate[i/10][\"total_rounds\"] for i in range(11)]\n",
    "errors = [math.sqrt(probs[i]*(1 - probs[i])/birth_rate[i/10][\"total_rounds\"])*3.291 for i in range(11)]\n",
    "        \n",
    "X_axis = np.arange(11) / 10\n",
    "\n",
    "ax.bar(X_axis, probs, yerr=errors, color=turq, width =0.09, zorder=3)\n",
    "\n",
    "ax.set_xticks(X_axis)\n",
    "\n",
    "ax.set_title(\"Birth rate vs. cooperation level\")\n",
    "ax.set_xlabel(\"Cooperation level\")\n",
    "ax.set_ylabel(\"Birth rate\")\n",
    "\n",
    "format_grid(ax, label=\"(A)\")\n",
    "\n",
    "fig.savefig(\"figures/birth_rate.png\", bbox_inches=\"tight\")\n",
    "\n",
    "# death rates\n",
    "fig = plt.figure(figsize=(6,2))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "probs = [death_rate[i/10][\"died\"]/(death_rate[i/10][\"survived\"] + death_rate[i/10][\"died\"]) for i in range(11)]\n",
    "errors = [math.sqrt(probs[i]*(1 - probs[i])/(death_rate[i/10][\"survived\"] + death_rate[i/10][\"died\"]))*3.291 for i in range(11)]\n",
    "    \n",
    "X_axis = np.arange(11) / 10\n",
    "\n",
    "ax.bar(X_axis, probs, yerr=errors, color=red, width =0.09, zorder=3)\n",
    "\n",
    "ax.set_xticks(X_axis)\n",
    "\n",
    "ax.set_title(\"Death rate vs cooperation level\")\n",
    "ax.set_xlabel(\"Cooperation level\")\n",
    "ax.set_ylabel(\"Death rate\")\n",
    "\n",
    "format_grid(ax, label=\"(B)\")\n",
    "\n",
    "fig.savefig(\"figures/death_rate.png\", bbox_inches=\"tight\")\n",
    "\n",
    "# population\n",
    "fig = plt.figure(figsize=(6,2))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "pops = [sum(population_dict[i/10])/len(population_dict[i/10]) for i in range(11)]\n",
    "errors = [3.291*math.sqrt(np.var(population_dict[i/10])/len(population_dict[i/10])) for i in range(11)]\n",
    "print(errors)\n",
    "X_axis = np.arange(11) / 10\n",
    "\n",
    "ax.bar(X_axis, pops, yerr=errors, color=med, width =0.09, zorder=3)\n",
    "\n",
    "ax.set_xticks(X_axis)\n",
    "\n",
    "ax.set_title(\"Average population vs cooperation level\")\n",
    "ax.set_xlabel(\"Cooperation level\")\n",
    "ax.set_ylabel(\"Group population\")\n",
    "\n",
    "format_grid(ax, label=\"(C)\")\n",
    "\n",
    "fig.savefig(\"figures/population.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def make_lag_lists(lst, lst2=None, lags=[0, 1]):\n",
    "    highest_lag = max(lags)\n",
    "    \n",
    "    lds = {}\n",
    "    \n",
    "    if lst2 is not None:\n",
    "        assert len(lst) == len(lst2)\n",
    "    \n",
    "    for lag in lags:\n",
    "        lag_list = splice(lst, lag, highest_lag)\n",
    "        lds[str(lag) + \"_self\"] = lag_list\n",
    "        \n",
    "        if lst2 is not None:\n",
    "            lag_list = splice(lst2, lag, highest_lag)\n",
    "            lds[str(lag) + \"_other\"] = lag_list\n",
    "    \n",
    "    return lds\n",
    "\n",
    "def splice(lst, lag, highest_lag):\n",
    "    return lst[highest_lag - lag : len(lst) - lag]\n",
    "    \n",
    "\n",
    "def make_big_lag_list(lag_list_of_dicts):\n",
    "    lags = list(lag_list_of_dicts[0].keys())\n",
    "    mama_dict = {lag: [] for lag in lags}\n",
    "    \n",
    "    # append lists in each lag dict to the mama dict\n",
    "    for lag_dict in lag_list_of_dicts:\n",
    "        for lag in lags:\n",
    "            mama_dict[lag] += lag_dict[lag]\n",
    "    \n",
    "    return mama_dict\n",
    "\n",
    "def get_index_in_coop_sequence(i, coop_sequence, max_lag):\n",
    "    acc = 0\n",
    "    for j, lst in enumerate(coop_sequence):\n",
    "        old_acc = acc\n",
    "        acc += (len(lst) - max_lag)\n",
    "        if i < acc:\n",
    "            return j, i - old_acc, (len(lst) - max_lag)\n",
    "\n",
    "def make_full_lag_list_from_coop_sequence(sequence, other_sequence=None, lags=[0, 1]):\n",
    "    lag_list_of_dicts = []\n",
    "\n",
    "    for i, lst in enumerate(sequence):\n",
    "        other_lst = None if other_sequence is None else other_sequence[i]\n",
    "        lds = make_lag_lists(lst, lst2=other_lst, lags=lags)\n",
    "        lag_list_of_dicts.append(lds)\n",
    "\n",
    "    full_lag_dict = make_big_lag_list(lag_list_of_dicts)\n",
    "    \n",
    "    df = pd.DataFrame(full_lag_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719dd950",
   "metadata": {},
   "source": [
    "### Code for gathering average lifespan, group size, and number of groups in the spatial simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathering parameters so that group sizes, lifetime migration rates, etc. are comparable across simulations\n",
    "\n",
    "# single file open\n",
    "f = open(\"spatial_data/3.25_conscience/deet_stats (1).json\")\n",
    "data = json.load(f)\n",
    "\n",
    "# get average number of groups, average lifespan, and average population per group\n",
    "sum_of_groups = 0\n",
    "sum_of_average_sizes = 0\n",
    "sum_of_lifespans = 0\n",
    "\n",
    "for year in range(600, 1000):\n",
    "    year_string = str(year)\n",
    "    sum_of_groups += data[year_string][\"g\"]\n",
    "    sum_of_lifespans += data[year_string][\"span\"]\n",
    "    \n",
    "    # first adds up the population of each group, then averages it for the year, then adds\n",
    "    sum_of_sizes = 0\n",
    "    for group in data[year_string][\"groups\"].values():\n",
    "        size = group[\"civ\"][\"pop\"] + group[\"sel\"][\"pop\"] + group[\"sta\"][\"pop\"]\n",
    "        sum_of_sizes += size\n",
    "    \n",
    "    avg_size = sum_of_sizes/data[year_string][\"g\"]\n",
    "    sum_of_average_sizes += avg_size\n",
    "\n",
    "avg_g = sum_of_groups/400\n",
    "avg_lifespan = sum_of_lifespans/400\n",
    "avg_group_size = sum_of_average_sizes/400\n",
    "\n",
    "print(\"no of groups:\", avg_g, \"lifespan:\", avg_lifespan, \"group_size:\", avg_group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e241e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_decays(const1, coeff1, const2, coeff2):\n",
    "    counter_1 = count_decay(const1, coeff1)\n",
    "    counter_2 = count_decay(const2, coeff2)\n",
    "    \n",
    "    print(counter_1, counter_2)\n",
    "    \n",
    "\n",
    "def count_decay(const, coeff):\n",
    "    counter = 0\n",
    "    var = 1\n",
    "    while var > 0.5:\n",
    "        var = coeff * var + const\n",
    "        counter += 1\n",
    "    \n",
    "    return counter\n",
    "\n",
    "0.0207\n",
    "0.0124\n",
    "compare_decays(0, 0.9225, 0, 0.9518)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746306fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    bp_datas = [[exp_trough_lengths, con_trough_lengths], [exp_spike_lengths, con_spike_lengths]]\n",
    "    for i, bp_data in enumerate(bp_datas):\n",
    "        bp = ax.boxplot(bp_data,\n",
    "                    positions=[i * 3, i * 3 + 1],\n",
    "                    patch_artist=True,\n",
    "                   notch=True,\n",
    "                    showfliers=False, showmeans=True, meanprops=meanprops, medianprops=medianprops, flierprops=flierprops)\n",
    "\n",
    "        set_box_colors(bp, color_range=[red, turq])\n",
    "\n",
    "    ax.legend([bp[\"boxes\"][0], bp[\"boxes\"][1]], ['No norm internalizers', 'With norm internalizers'], loc='lower right')\n",
    "\n",
    "    ax.set_xticks([0.5, 3.5])\n",
    "    ax.set_xticklabels([\"Troughs\", \"Peaks\"])\n",
    "    ax.set_ylabel(\"Cooperation fraction\")\n",
    "    ax.set_title(\"Cooperation fraction vs. benefit to cost\", y=1.02)\n",
    "    ax.set_xlabel(\"Benefit to cost\")\n",
    "    format_grid(ax, label=\"(B)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00815be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2270bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind = 5\n",
    "\n",
    "coop_levels = smoother(spatial_data_dict[0.5][0][65][\"coop_levels\"][ind], window=50)\n",
    "nc_coop_levels = smoother(spatial_data_dict[0.5][0][65][\"nc_coop_levels\"][ind], window=50)\n",
    "civ_coop_levels = smoother(interpolate(spatial_data_dict[0][0.02][65][\"civ_coop_levels\"][ind]), window=50)\n",
    "\n",
    "nc_coop_diffs = smoother(np.diff(nc_coop_levels), window=25)\n",
    "civ_coop_diffs = smoother(np.diff(civ_coop_levels), window=25)\n",
    "\n",
    "\n",
    "spikes, max_spike_length, avg_spike_length = find_spikes(coop_levels, min_spike_length=100)\n",
    "print(max_spike_length, avg_spike_length)\n",
    "\n",
    "tot_spike_arr, tot_avg_spike = calc_average_spike(coop_levels, spikes, 200)\n",
    "nc_spike_arr, nc_avg_spike = calc_average_spike(nc_coop_levels, spikes, 200)\n",
    "civ_spike_arr, civ_avg_spike = calc_average_spike(civ_coop_levels, spikes, 200)\n",
    "civ_diff_arr, civ_diff_avg = calc_average_spike(civ_coop_diffs, spikes, 200)\n",
    "nc_diff_arr, nc_diff_avg = calc_average_spike(nc_coop_diffs, spikes, 200)\n",
    "\n",
    "tot_drop_arr, tot_avg_drop = calc_average_drop(coop_levels, spikes, 200)\n",
    "nc_drop_arr, nc_avg_drop = calc_average_drop(nc_coop_levels, spikes, 200)\n",
    "civ_drop_arr, civ_avg_drop = calc_average_drop(civ_coop_levels, spikes, 200)\n",
    "\n",
    "fig1, ax1 = plt.subplots(1)\n",
    "fig2, ax2 = plt.subplots(1)\n",
    "fig3, ax3 = plt.subplots(1)\n",
    "\n",
    "coop_mean = sum(coop_levels)/len(coop_levels)\n",
    "\n",
    "ax1.hlines(y=coop_mean, xmin=0, xmax=len(tot_avg_spike), color=dark)\n",
    "ax1.plot(range(len(tot_avg_spike)), civ_avg_spike, color=turq)\n",
    "ax1.plot(range(len(tot_avg_spike)), tot_avg_spike, color=med)\n",
    "ax1.plot(range(len(tot_avg_spike)), nc_avg_spike, color=red)\n",
    "\n",
    "ax2.plot(range(len(tot_avg_spike)), civ_diff_avg, color=turq)\n",
    "ax2.plot(range(len(tot_avg_spike)), nc_diff_avg, color=red)\n",
    "\n",
    "ax3.hlines(y=coop_mean, xmin=0, xmax=len(tot_avg_spike), color=dark)\n",
    "ax3.plot(range(len(tot_avg_drop)), civ_avg_drop, color=turq)\n",
    "ax3.plot(range(len(tot_avg_spike)), tot_avg_drop, color=med)\n",
    "ax3.plot(range(len(tot_avg_spike)), nc_avg_drop, color=red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d449e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lag lists for benefit = 65, mig = 0.5, spatial\n",
    "e_coop_sequence = [coop_levels for coop_levels in spatial_data_dict[0][0.02][65][\"coop_levels\"]]\n",
    "e_civ_pop_sequence = [civ_pop for civ_pop in spatial_data_dict[0][0.02][65][\"civ_levels\"]]\n",
    "\n",
    "e_civ_pop_sequence_diff = [list(np.diff(civ_pop)) for civ_pop in e_civ_pop_sequence]\n",
    "e_coop_sequence_shortened = [coop_levels[1:] for coop_levels in e_coop_sequence]\n",
    "\n",
    "print([len(lst) for lst in e_civ_pop_sequence_diff])\n",
    "print([len(lst) for lst in e_coop_sequence_shortened])\n",
    "\n",
    "df_coop_pop = make_full_lag_list_from_coop_sequence(e_civ_pop_sequence, e_coop_sequence, lags=[0, 50, 100])\n",
    "df_coop_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self is civic pop, other is coop level\n",
    "x = df_coop_pop[['50_self', '100_self', '50_other', '100_other']]\n",
    "y = df_coop_pop['0_self']\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x) \n",
    "\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_nc_coop_sequence = [nc_coop for nc_coop in spatial_data_dict[0.5][0.02][65][\"nc_coop_levels\"]]\n",
    "e_civ_coop_sequence = [interpolate(civ_coop) for civ_coop in spatial_data_dict[0.5][0.02][65][\"civ_coop_levels\"]]\n",
    "\n",
    "df_nc_civ = make_full_lag_list_from_coop_sequence(e_nc_coop_sequence, e_civ_coop_sequence, lags=[0, 1, 2])\n",
    "df_nc_civ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_nc_civ[['1_self', '2_self', '1_other', '2_other']]\n",
    "y = df_nc_civ['0_other']\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x) \n",
    "\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f647d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_civ_pop_sequence = [nc_coop for nc_coop in spatial_data_dict[0.5][0.02][65][\"nc_coop_levels\"]]\n",
    "e_civ_coop_sequence = [interpolate(civ_coop) for civ_coop in spatial_data_dict[0.5][0.02][65][\"civ_coop_levels\"]]\n",
    "\n",
    "df_civ_pop_coop = make_full_lag_list_from_coop_sequence(e_civ_pop_sequence, e_civ_coop_sequence, lags=[0, 200, 400])\n",
    "df_civ_pop_coop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125cf1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_civ_pop_coop[['200_self', '400_self', '200_other', '400_other']]\n",
    "y = df_civ_pop_coop['0_other']\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x) \n",
    "\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1a7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0d948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coop_con_fig = plt.figure(figsize=(6.4,3))\n",
    "nc_coop_con_fig = plt.figure(figsize=(6.4, 3))\n",
    "ratio_fig = plt.figure(figsize=(6.4, 2))\n",
    "\n",
    "coop_con_ax = coop_con_fig.add_subplot(1, 1, 1)\n",
    "nc_coop_con_ax = nc_coop_con_fig.add_subplot(1, 1, 1)\n",
    "ratio_ax = ratio_fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# figure for coop vs conscience prevalence\n",
    "coop_con_ax.scatter(civ_pcts[::300], coop_levels_long[::300], color=turq, alpha=0.1, s=10, marker=\".\", zorder=3)\n",
    "for i, (mean, se) in enumerate(zip(coop_means, coop_ses)):\n",
    "    coop_con_ax.plot([i/10, (i + 1)/10], [mean, mean], color=dark, zorder=5)\n",
    "    coop_con_ax.plot([(i + 0.5)/10, (i + 0.5)/10], [mean - 3.291*se, mean + 3.291*se], color='black', zorder=5)\n",
    "\n",
    "coop_con_ax.set_title(\"Cooperation level vs.\\nprevalence of norm internalization\")\n",
    "coop_con_ax.set_ylabel(\"Cooperation level\")\n",
    "\n",
    "format_grid(coop_con_ax, label=\"(A)\")\n",
    "\n",
    "# figure for non-civic coop vs conscience prevalence\n",
    "nc_coop_con_ax.scatter(civ_pcts[::200], nc_coop_levels_long[::200], color=red, alpha=0.1, s=0.1, zorder=3)\n",
    "\n",
    "for i, (mean, se) in enumerate(zip(nc_coop_means, nc_coop_ses)):\n",
    "    nc_coop_con_ax.plot([i/10, (i + 1)/10], [mean, mean], color=dark, zorder=5)\n",
    "    nc_coop_con_ax.plot([(i + 0.5)/10, (i + 0.5)/10], [mean - 3.291*se, mean + 3.291*se], color='black', zorder=5)\n",
    "\n",
    "nc_coop_con_ax.set_title(\"Non-conscience cooperation level vs.\\nprevalence of norm internalization\")\n",
    "nc_coop_con_ax.set_xlabel(\"Prevalence of conscience\")\n",
    "nc_coop_con_ax.set_ylabel(\"Cooperation level\")\n",
    "format_grid(nc_coop_con_ax, label=\"(B)\")\n",
    "\n",
    "# figure for \n",
    "errors = [ratio_se*3.291 for ratio_se in ratio_ses]\n",
    "X_axis = np.arange(10) / 10\n",
    "ratio_ax.bar(X_axis, ratios, yerr=errors, color=med, width =0.095, zorder=3)\n",
    "ratio_ax.set_xticks(X_axis)\n",
    "ratio_ax.set_title(\"Groups <80% cooperation with <20% cooperation\")\n",
    "ratio_ax.set_ylabel(\"Fract with <20% cooperation\")\n",
    "ratio_ax.set_xlabel(\"Prevalence of conscience\")\n",
    "\n",
    "format_grid(ratio_ax, \"(C)\")\n",
    "\n",
    "coop_con_fig.savefig(\"figures/coop_by_conscience_prev.svg\")\n",
    "nc_coop_con_fig.savefig(\"figures/nc_coop_by_conscience_prev.svg\")\n",
    "ratio_fig.savefig(\"figures/extremity_of_coop.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5150df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for powerpoint\n",
    "# high-civic graph\n",
    "print(coop_levels_pres_maj[0:20])\n",
    "print(len(coop_levels_pres_maj))\n",
    "print(coop_levels_futu_maj[0:20])\n",
    "print(len(coop_levels_futu_maj))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(coop_levels_pres_maj[::100], coop_levels_futu_maj[::100], color=turq, alpha=0.1, s=10, zorder=3)\n",
    "ax.plot(coop_p_maj_arr, coop_p_maj_arr, color=med, zorder=4, linewidth=2)\n",
    "ax.plot(coop_p_maj_arr, coop_f_pred_maj, color=dark, zorder=5, linewidth=2)\n",
    "\n",
    "ax.set_title(\"High-consience groups: \\n Lagged (5 rounds) vs. present cooperation levels\")\n",
    "ax.set_xlabel(\"Lagged fract of cooperators\")\n",
    "ax.set_ylabel(\"Fract of cooperators\")\n",
    "\n",
    "format_grid(ax, label=\"(A)\")\n",
    "\n",
    "fig.savefig(\"figures/lagged-vs-present-coop-high-conscience.svg\")\n",
    "\n",
    "# low civic graph\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(coop_levels_pres_min[::500], coop_levels_futu_min[::500], s=10, alpha=0.1, color=red, zorder=3)\n",
    "\n",
    "ax.plot(coop_p_min_arr, coop_p_min_arr, color=med, zorder=4, linewidth=2)\n",
    "ax.plot(coop_p_min_arr, coop_f_min_pred, color=dark, zorder=5, linewidth=2)\n",
    "\n",
    "ax.set_title(\"Low-conscience groups: \\n Lagged (5 rounds) vs. present cooperation levels\")\n",
    "ax.set_xlabel(\"Lagged fract of cooperators\")\n",
    "ax.set_ylabel(\"Fract of cooperators\")\n",
    "\n",
    "format_grid(ax, label=\"(B)\")\n",
    "\n",
    "fig.savefig(\"figures/lagged-vs-present-coop-low-conscience.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1bd9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dictionary that stores the highly cooperative groups and the level of civic learners that were present\n",
    "# when they started being highly cooperative\n",
    "high_coop_dict = {} \n",
    "\n",
    "# Tally up the number of rounds that are highly cooperative that were instigated \n",
    "# by a high civic population vs low civic population\n",
    "high_civic_instigated_coop_rounds = 0\n",
    "low_civic_instigated_coop_rounds = 0\n",
    "\n",
    "# Tally up the number of rounds that are highly cooperative that have high numbers of civic learners\n",
    "high_civic_coop_rounds = 0\n",
    "low_civic_coop_rounds = 0\n",
    "\n",
    "total_coop_rounds = 0\n",
    "\n",
    "high_civic_rounds = 0\n",
    "low_civic_rounds = 0\n",
    "\n",
    "for deet_data in spatial_deet_datas:\n",
    "    for year, dat in deet_data.items():\n",
    "        for group, little_dat in dat['groups'].items():\n",
    "\n",
    "            # calculate the cooperation level\n",
    "            pop, _ = population(little_dat)\n",
    "            civ_pct = little_dat[\"civ\"][\"pop\"]/pop\n",
    "            coop_pct = total_coop_level(little_dat)[0]/pop\n",
    "\n",
    "            high_civic_rounds += (civ_pct > 0.3)\n",
    "            low_civic_rounds += (civ_pct <= 0.3)\n",
    "\n",
    "            # if it's under 50% for the first time, pop its value \n",
    "            if coop_pct <= 0.5 and group in high_coop_dict:\n",
    "                high_coop_dict.pop(group)\n",
    "\n",
    "\n",
    "            if coop_pct > 0.5:\n",
    "\n",
    "                # if it's over 50% for the first time, save its threshold value\n",
    "                if group not in high_coop_dict:\n",
    "                    high_coop_dict[group] = civ_pct\n",
    "\n",
    "                # increment the correct counters \n",
    "                high_civic_instigated_coop_rounds += (high_coop_dict[group] > 0.3)\n",
    "                low_civic_instigated_coop_rounds += (high_coop_dict[group] <= 0.3)\n",
    "                total_coop_rounds += 1\n",
    "\n",
    "\n",
    "                high_civic_coop_rounds += (civ_pct > 0.3)\n",
    "                low_civic_coop_rounds += (civ_pct <= 0.3)\n",
    "\n",
    "\n",
    "print(\"Number of cooperative rounds INSTIGATED by high civic:\", high_civic_instigated_coop_rounds)\n",
    "print(\"Ratio of cooperative rounds instigated by high civic / high civic rounds:\", high_civic_instigated_coop_rounds/high_civic_rounds)\n",
    "\n",
    "print(\"Number of cooperative rounds INSTIGATED by low civic:\", low_civic_instigated_coop_rounds)\n",
    "print(\"Ratio of cooperative rounds instigated by low civic / low civic rounds:\", low_civic_instigated_coop_rounds/low_civic_rounds)\n",
    "\n",
    "print(\"-------------\")\n",
    "\n",
    "print(\"Number of cooperative rounds with high civic:\", high_civic_coop_rounds)\n",
    "print(\"Percentage of high civic rounds that are cooperative:\", high_civic_coop_rounds/high_civic_rounds)\n",
    "\n",
    "print(\"Number of cooperative rounds with low civic:\", low_civic_coop_rounds)\n",
    "print(\"Percentage of low civic rounds that are cooperative:\", low_civic_coop_rounds/low_civic_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558de82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = [low_civic_instigated_coop_rounds/low_civic_rounds, high_civic_instigated_coop_rounds/high_civic_rounds]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "X_axis = np.arange(2) + 0.5\n",
    "ax.set_title(\"Ratio of number of cooperative rounds \\n instigated by low/high conscience populations \\n to the number of low/high conscience rounds\")\n",
    "ax.bar(X_axis, data, width=0.95, color=med, zorder=3)\n",
    "ax.set_xticks(X_axis)\n",
    "ax.set_ylabel(\"Ratio of cooperative rounds instigated\")\n",
    "ax.set_xticklabels([\"Low conscience\", \"High conscience\"])\n",
    "ax.plot([0, 2], [1, 1], color=turq, linestyle=\"dashed\", zorder=5)\n",
    "\n",
    "\n",
    "format_grid(ax, label=\"\")\n",
    "fig.savefig(\"figures/instigation_of_coop.png\")\n",
    "fig.savefig(\"figures/instigation_of_coop.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616d0fb3",
   "metadata": {},
   "source": [
    "# Pinhead Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ff983",
   "metadata": {},
   "source": [
    "## Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c744b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits = [3.25, 3.5, 3.75, 4, 4.25]\n",
    "distribs = [(0.01, 0.01), (0.02, 0.00), (0.00, 0.02)]\n",
    "con = 1/13\n",
    "\n",
    "transition_dict = {\n",
    "                    distrib: {\n",
    "                        benefit: defaultdict(lambda: 0) for benefit in benefits\n",
    "                            } for distrib in distribs   \n",
    "                  }\n",
    "\n",
    "old_data = False\n",
    "pop = 40*80\n",
    "\n",
    "for benefit in benefits:\n",
    "    for distrib in distribs:\n",
    "        print(con, benefit, distrib)\n",
    "        \n",
    "        # get file names from the directory\n",
    "        distrib_name = lookup_distrib_name_pinhead(distrib)\n",
    "        subdir = f\"{benefit:.2f}_{distrib_name}\"\n",
    "        dirname = f\"pinhead_data/{subdir}\"\n",
    "        \n",
    "        if not os.path.isdir(dirname):\n",
    "            continue\n",
    "\n",
    "        files = os.listdir(dirname)\n",
    "        \n",
    "        # remove annoying files \n",
    "        if \"Icon\\r\" in files:\n",
    "            files.remove(\"Icon\\r\")\n",
    "        if \".DS_Store\" in files:\n",
    "            files.remove(\".DS_Store\")\n",
    "        if \"desktop.ini\" in files:\n",
    "            files.remove(\"desktop.ini\")\n",
    "        \n",
    "        # initialize lists of things to keep track of\n",
    "        up_transitions = []\n",
    "        up_transition_times = []\n",
    "        down_transitions = []\n",
    "        down_transition_times = []\n",
    "        end_years = []\n",
    "        never_counter_up = 0\n",
    "        never_counter_down = 0\n",
    "\n",
    "        for file in files:\n",
    "            \n",
    "            # load the data\n",
    "            f = open(f\"{dirname}/{file}\")\n",
    "            data = json.load(f)\n",
    "            params = data.pop(\"params\")\n",
    "            \n",
    "            # verify that this data has the correct parameters\n",
    "            expected_saint = distrib[1]\n",
    "            expected_citizen = distrib[0]\n",
    "\n",
    "            assert params[\"distrib\"][\"citizen\"] == expected_citizen\n",
    "            assert params[\"distrib\"][\"saint\"] == expected_saint\n",
    "            assert params[\"p_con\"] == con\n",
    "            assert params[\"benefit\"] == benefit\n",
    "            \n",
    "            coop_window = [] # levels of cooperation for the chosen window\n",
    "            coop_mean = 0 # mean cooperation in the window\n",
    "            transitions = {\"up\": [], \"down\": []} # when the simulation transitions from low to high coop\n",
    "            last_low_coop = 0 # the last time coop was low\n",
    "            last_high_coop = 0 # the last time coop was high\n",
    "\n",
    "            for year, dat in data.items():\n",
    "                cooperators, noncivic_cooperators = total_coop_level(dat)\n",
    "                coop_level = cooperators/pop\n",
    "\n",
    "                coop_window.append(coop_level)\n",
    "\n",
    "                if len(coop_window) > 50:\n",
    "                    coop_window.pop(0)\n",
    "\n",
    "                prev_coop_mean = coop_mean\n",
    "                coop_mean = sum(coop_window)/len(coop_window)\n",
    "                \n",
    "                # keep track of the last time cooperation was low/high\n",
    "                if coop_mean < 0.15:\n",
    "                    last_low_coop = int(year)\n",
    "                elif coop_mean > 0.9:\n",
    "                    last_high_coop = int(year)\n",
    "                \n",
    "                # keep track of when cooperation exceeds high or low thresholds\n",
    "                if prev_coop_mean < 0.9 and coop_mean >= 0.9:\n",
    "                    transitions[\"up\"].append({\"start\": last_low_coop, \"end\": int(year)})\n",
    "                elif prev_coop_mean >= 0.15 and coop_mean < 0.15:\n",
    "                    transitions[\"down\"].append({\"start\": last_high_coop, \"end\": int(year)})\n",
    "\n",
    "\n",
    "            end_years.append(year)\n",
    "            \n",
    "            # store the up and down transitions, in addition to how long they took\n",
    "            if len(transitions[\"up\"]) > 0:\n",
    "                trans_end = transitions[\"up\"][0][\"end\"]\n",
    "                trans_start = transitions[\"up\"][0][\"start\"]\n",
    "                up_transitions.append(trans_end)\n",
    "                up_transition_times.append(trans_end - trans_start)\n",
    "            else:\n",
    "                never_counter_up += 1\n",
    "\n",
    "            if len(transitions[\"down\"]) > 0:\n",
    "                trans_end = transitions[\"down\"][0][\"end\"]\n",
    "                trans_start = transitions[\"down\"][0][\"start\"]\n",
    "                down_transitions.append(trans_end)\n",
    "                down_transition_times.append(trans_end - trans_start)\n",
    "            else:\n",
    "                never_counter_down += 1\n",
    "\n",
    "        # if we start from common, pay attention to down transitions, otherwise, do the opposite\n",
    "        if distrib[0] + distrib[1] == 0.98:\n",
    "            print(\"starting from common!!\")\n",
    "            transitions = down_transitions\n",
    "            transition_times = down_transition_times\n",
    "            never_counter = never_counter_down\n",
    "        else:\n",
    "            transitions = up_transitions\n",
    "            transition_times = up_transition_times\n",
    "            never_counter = never_counter_up\n",
    "        \n",
    "        # save the average round and average time, along with the standard errors\n",
    "        avg = 50000\n",
    "        std = 10000\n",
    "        stderr = 10000\n",
    "        if len(transitions) > 0:\n",
    "            avg = sum(transitions)/len(transitions)\n",
    "            std = math.sqrt(sum([(x - avg)**2 for x in transitions])/(max([len(transitions) - 1, 1])))\n",
    "            stderr = std / math.sqrt(len(transitions))\n",
    "\n",
    "        fract = len(transitions)/(len(transitions) + never_counter)\n",
    "\n",
    "        avg_time = sum(transition_times)/len(transition_times)\n",
    "        std_time = math.sqrt(sum([(x - avg_time)**2 for x in transition_times])/(max([len(transition_times) - 1, 1])))\n",
    "        stderr_time = std_time/math.sqrt(len(transition_times))\n",
    "        \n",
    "        # store in a dictionary\n",
    "        transition_dict[distrib][benefit][\"data\"] = transitions # when all the transitions occurred\n",
    "        transition_dict[distrib][benefit][\"times\"] = transition_times # how long all the transitions occurred\n",
    "        transition_dict[distrib][benefit][\"n\"] = len(transitions) + never_counter \n",
    "        \n",
    "        # transition round stats\n",
    "        transition_dict[distrib][benefit][\"avg\"] = avg # average round of transition\n",
    "        transition_dict[distrib][benefit][\"std\"] = std # std for round of transition\n",
    "        transition_dict[distrib][benefit][\"stderr\"] = stderr # stderr for round of transition\n",
    "        \n",
    "        # transition time stats \n",
    "        transition_dict[distrib][benefit][\"avg_time\"] = avg_time\n",
    "        transition_dict[distrib][benefit][\"std_time\"] = std_time\n",
    "        transition_dict[distrib][benefit][\"stderr_time\"] = stderr_time\n",
    "        \n",
    "        # fraction stats\n",
    "        transition_dict[distrib][benefit][\"fract\"] = fract\n",
    "        transition_dict[distrib][benefit][\"fract_stderr\"] = math.sqrt(fract*(1 - fract)/(len(up_transitions) + never_counter))\n",
    "\n",
    "\n",
    "        print(len(transitions), len(transitions) + never_counter)\n",
    "        print(\"avg\", avg, \"stderr\", stderr, \"fract\", fract)\n",
    "        print(\"avg_time\", avg_time, \"stderr_time\", stderr_time)\n",
    "        print(\"-------------------\")\n",
    "    print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364022be",
   "metadata": {},
   "source": [
    "## Calculate average time to high cooperation for each level of benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a4ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the time for each of the three conditions\n",
    "average_across_distribs = {benefit: sum([transition_dict[distrib][benefit][\"avg\"]/3 for distrib in distribs]) \n",
    "                           for benefit in benefits}\n",
    "\n",
    "# the variance of the sum of RVs is the sum of the variances. Then divide by 9 because of the constant 1/3\n",
    "sd_across_distribs = {benefit: math.sqrt(sum([transition_dict[distrib][benefit][\"stderr\"]**2/9 for distrib in distribs])) \n",
    "                      for benefit in benefits}\n",
    "\n",
    "print(\"Mean time to achieve high cooperation:\")\n",
    "print(average_across_distribs)\n",
    "print(\"Standard error time to achieve high cooperation:\")\n",
    "print(sd_across_distribs)\n",
    "print(\"95 pct confidence intervals\")\n",
    "\n",
    "# t-test with two degrees of freedom\n",
    "print({benefit: [average_across_distribs[benefit] - 4.303 * x, average_across_distribs[benefit] + 4.303 * x] \n",
    "       for benefit, x in sd_across_distribs.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd97fc",
   "metadata": {},
   "source": [
    "## Calculate the significance of differences between (1) fraction of high coop and (2) time for high coop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits = [3.25, 3.5, 3.75, 4, 4.25]\n",
    "# add correct number of asterisks for significance\n",
    "sig_labels = []\n",
    "fract_sig_labels = []\n",
    "for i, benefit in enumerate(benefits):\n",
    "    print(benefit)\n",
    "    # calculate the difference of the times and the standard deviation of the quantity\n",
    "    diff_time_mean = transition_dict[(0.02, 0.0)][benefit][\"avg\"] - transition_dict[(0.0, 0.02)][benefit][\"avg\"]\n",
    "    diff_time_var =  transition_dict[(0.02, 0.0)][benefit][\"stderr\"]**2 + transition_dict[(0.0, 0.02)][benefit][\"stderr\"]**2\n",
    "    diff_time_std = math.sqrt(diff_time_var)\n",
    "    \n",
    "    # get t-score and the p value based on the degrees of freedom\n",
    "    time_t_score = abs(diff_time_mean/diff_time_std)\n",
    "    df = min(transition_dict[(0.02, 0.0)][benefit][\"n\"], transition_dict[(0.0, 0.02)][benefit][\"n\"]) - 1\n",
    "    p_value = scipy.stats.t.sf(time_t_score, df=df)*2\n",
    "\n",
    "    # calculate z confidence intervals (quick and dirty check)\n",
    "    diff_time_95_conf = [diff_time_mean - diff_time_std *1.96, diff_time_mean + diff_time_std *1.96]\n",
    "    diff_time_98_conf = [diff_time_mean - diff_time_std *2.33, diff_time_mean + diff_time_std *2.33]\n",
    "    diff_time_99_conf = [diff_time_mean - diff_time_std *2.58, diff_time_mean + diff_time_std *2.58]\n",
    "    print(\"level statistics\")\n",
    "    print(f\"The mean difference is {round(diff_time_mean, 2)}.\")\n",
    "    print(f\"The standard deviation is {diff_time_std}\") \n",
    "    print(f\"The 0.98 confidence interval for the difference of benefit {benefit} is from {round(diff_time_98_conf[0], 2)} to {round(diff_time_98_conf[1], 2)}\")\n",
    "    print(f\"The 0.99 confidence interval for the difference of benefit {benefit} is from {round(diff_time_99_conf[0], 2)} to {round(diff_time_99_conf[1], 2)}\")\n",
    "    print(\"-------\")\n",
    "    # calculate the number of stars and append them to the significance list\n",
    "    if p_value < 0.01:\n",
    "        stars = \"**\"\n",
    "    elif p_value < 0.02:\n",
    "        stars = \"*\"\n",
    "    else:\n",
    "        stars = \"\"\n",
    "        \n",
    "    sig_labels.append(stars)\n",
    "    \n",
    "    # calculate the difference in the fraction of runs that converged\n",
    "    diff_fract_mean = transition_dict[(0.02, 0.0)][benefit][\"fract\"] - transition_dict[(0.0, 0.02)][benefit][\"fract\"]\n",
    "    diff_fract_var =  transition_dict[(0.02, 0.0)][benefit][\"fract_stderr\"]**2 + transition_dict[(0.0, 0.02)][benefit][\"fract_stderr\"]**2\n",
    "    diff_fract_std = math.sqrt(diff_fract_var)\n",
    "    \n",
    "    # use this thing to get the z score \n",
    "    # https://stats.stackexchange.com/questions/113602/test-if-two-binomial-distributions-are-statistically-different-from-each-other\n",
    "    n1 = transition_dict[(0.02, 0.0)][benefit][\"n\"]\n",
    "    n2 = transition_dict[(0.0, 0.02)][benefit][\"n\"]\n",
    "    p1 = transition_dict[(0.02, 0.0)][benefit][\"fract\"]\n",
    "    p2 = transition_dict[(0.0, 0.02)][benefit][\"fract\"]\n",
    "    p_hat = (p1*n1 + p2*n2)/(n1 + n2)\n",
    "    \n",
    "    if p_hat < 1:\n",
    "        z_score = (p1 - p2)/(p_hat*(1 - p_hat)*(1/n1 + 1/n2))\n",
    "    else:\n",
    "        z_score = 5\n",
    "        \n",
    "    p_value = scipy.stats.norm.sf(abs(z_score))\n",
    "    \n",
    "    \n",
    "    # confidence intervals for sanity\n",
    "    diff_fract_95_conf = [diff_fract_mean - diff_fract_std *1.96, diff_fract_mean + diff_fract_std *1.96]  \n",
    "    diff_fract_98_conf = [diff_fract_mean - diff_fract_std *2.33, diff_fract_mean + diff_fract_std *2.33]\n",
    "    diff_fract_99_conf = [diff_fract_mean - diff_fract_std *2.58, diff_fract_mean + diff_fract_std *2.58]\n",
    "    print(\"fraction statistics\")\n",
    "    print(f\"The mean difference is {round(diff_fract_mean, 2)}.\")\n",
    "    print(f\"The standard deviation is {diff_fract_std}\") \n",
    "    print(f\"The 0.98 confidence interval for the difference of benefit {benefit} is from {round(diff_fract_98_conf[0], 2)} to {round(diff_fract_98_conf[1], 2)}\")\n",
    "    print(f\"The 0.99 confidence interval for the difference of benefit {benefit} is from {round(diff_fract_99_conf[0], 2)} to {round(diff_fract_99_conf[1], 2)}\")\n",
    "    print(\"-----------------------\")\n",
    "    stars = \"\"\n",
    "    # calculate the number of stars and append them to the significance list\n",
    "    if p_value < 0.001:\n",
    "        stars = \"***\"\n",
    "    elif p_value < 0.01:\n",
    "        stars = \"**\"\n",
    "    elif p_value < 0.02:\n",
    "        stars = \"*\"\n",
    "    else:\n",
    "        stars = \"\"\n",
    "\n",
    "    fract_sig_labels.append(stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb6cd5",
   "metadata": {},
   "source": [
    "## create the figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf068fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribs = [(0.0, 0.02), (0.01, 0.01), (0.02, 0.00)]\n",
    "\n",
    "benefits = [3.25, 3.5, 3.75, 4, 4.25]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "gs = fig.add_gridspec(8, 6)\n",
    "\n",
    "trans_time_ax = fig.add_subplot(gs[0:2, 1:5])\n",
    "fraction_ax = fig.add_subplot(gs[2:6, 0:1])\n",
    "trans_round_ax = fig.add_subplot(gs[2:6,1:5])\n",
    "trans_time_abs_ax = fig.add_subplot(gs[6:8,1:5])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=13) \n",
    "\n",
    "X_axis = np.arange(len(benefits))\n",
    "\n",
    "# transition time bar chart\n",
    "barchart_levels_trans_times = defaultdict(list)\n",
    "barchart_errors_trans_times = defaultdict(list)\n",
    "\n",
    "for distrib in distribs:\n",
    "    for benefit in benefits:\n",
    "        t_value = scipy.stats.t.ppf(0.975, transition_dict[distrib][benefit][\"n\"] - 1, loc = 0, scale = 1)\n",
    "        barchart_levels_trans_times[distrib].append(transition_dict[distrib][benefit][\"avg_time\"])\n",
    "        barchart_errors_trans_times[distrib].append(transition_dict[distrib][benefit][\"stderr_time\"]*t_value)\n",
    "\n",
    "    \n",
    "trans_time_ax.bar(X_axis - 0.2, barchart_levels_trans_times[(0.0, 0.02)][0], yerr=barchart_errors_trans_times[(0.0, 0.02)][0], color=red, width =0.15, label=\"No conscience\", zorder=3)\n",
    "trans_time_ax.bar(X_axis, barchart_levels_trans_times[(0.01, 0.01)][0], yerr=barchart_errors_trans_times[(0.01, 0.01)][0], color=dark, width =0.15, label=\"Mix\", zorder=3)\n",
    "trans_time_ax.bar(X_axis + 0.2, barchart_levels_trans_times[(0.02, 0.0)][0], yerr=barchart_errors_trans_times[(0.02, 0.0)][0], color=turq, width =0.15, label=\"Conscience\", zorder=3)\n",
    "trans_time_ax.set_xticks(X_axis)\n",
    "trans_time_ax.set_xticklabels([benefit for benefit in benefits])\n",
    "\n",
    "trans_time_ax.legend()\n",
    "trans_time_ax.set_title(\"Transition time\\n(Time spent between low and high cooperation)\")\n",
    "trans_time_ax.set_ylabel(\"Rounds\")\n",
    "format_grid(trans_time_ax, label=\"(A)\")\n",
    "\n",
    "\n",
    "# fraction bar chart\n",
    "barchart_levels_fract = defaultdict(list)\n",
    "barchart_errors_fract = defaultdict(list)\n",
    "\n",
    "for distrib in distribs:\n",
    "    for benefit in benefits:\n",
    "        t_value = scipy.stats.t.ppf(0.975, transition_dict[distrib][benefit][\"n\"] - 1, loc = 0, scale = 1)\n",
    "        barchart_levels_fract[distrib].append(transition_dict[distrib][benefit][\"fract\"])\n",
    "        barchart_errors_fract[distrib].append(transition_dict[distrib][benefit][\"fract_stderr\"]*t_value)\n",
    "\n",
    "fraction_ax.bar([-0.2], barchart_levels_fract[(0.0, 0.02)][0], yerr=barchart_errors_fract[(0.0, 0.02)][0], color=red, width =0.15, zorder=3)\n",
    "fraction_ax.bar([0], barchart_levels_fract[(0.01, 0.01)][0], yerr=barchart_errors_fract[(0.01, 0.01)][0], color=dark, width =0.15, zorder=3)\n",
    "fraction_ax.bar([0.2], barchart_levels_fract[(0.02, 0.0)][0], yerr=barchart_errors_fract[(0.02, 0.0)][0], color=turq, width =0.15, zorder=3)\n",
    "fraction_ax.set_xticks([0])\n",
    "fraction_ax.set_xticklabels([benefits[0]])\n",
    "\n",
    "\n",
    "fraction_ax.set_title(\"Fraction of time high\\ncoop is reached\", y=1.02)\n",
    "fraction_ax.set_ylabel(\"Fraction\")\n",
    "fraction_ax.set_yticks([0.3, 0.6, 0.9])\n",
    "fraction_ax.set_ylim(bottom=0, top=1)\n",
    "fraction_ax.text(0.2, barchart_levels_fract[(0.02, 0.0)][0] + barchart_errors_fract[(0.02, 0.0)][0] + 0.02, \n",
    "                 fract_sig_labels[0], ha=\"center\", va=\"center\")\n",
    "format_grid(fraction_ax, label=\"(B)\")\n",
    "\n",
    "\n",
    "# number of rounds box plot\n",
    "\n",
    "for i, benefit in enumerate(benefits):\n",
    "    bp = trans_round_ax.boxplot([np.array(transition_dict[distrib][benefit][\"data\"])/average_across_distribs[benefit] for distrib in distribs],\n",
    "                positions=[i * 4, i * 4 + 1, i * 4 + 2],\n",
    "                patch_artist=True,\n",
    "               notch=True, showmeans=True, meanprops=meanprops, medianprops=medianprops, showfliers=False)\n",
    "\n",
    "    trans_round_ax.text(i * 4 + 2, bp[\"whiskers\"][5].get_data()[1][1] + 0.05, sig_labels[i], ha=\"center\", va=\"center\")\n",
    "    set_box_colors(bp)\n",
    "\n",
    "trans_round_ax.set_xticks([1, 5, 9, 13, 17])\n",
    "trans_round_ax.set_yticks([i/2 for i in range(5)])\n",
    "trans_round_ax.set_xticklabels([benefit for benefit in benefits])\n",
    "trans_round_ax.set_ylim(bottom=0, top=2.1)\n",
    "trans_round_ax.set_title(\"Time from start relative to average\\n to achieve high cooperation\", y=1.02)\n",
    "\n",
    "trans_round_ax.set_ylabel(\"Ratio relative to average\")\n",
    "\n",
    "format_grid(trans_round_ax, label=\"(C)\")\n",
    "\n",
    "\n",
    "trans_time_abs_ax.bar(X_axis, [rounds for ben, rounds in average_across_distribs.items()], yerr=barchart_errors_trans_times[(0.0, 0.02)][0], color=med, width=0.45, zorder=3)\n",
    "trans_time_abs_ax.set_xticks(X_axis)\n",
    "trans_time_abs_ax.set_xticklabels([benefit for benefit in benefits])\n",
    "trans_time_abs_ax.set_xlabel(\"Benefit to cost\")\n",
    "trans_time_abs_ax.set_ylabel(\"Rounds\")\n",
    "trans_time_abs_ax.set_title(\"Average time from start (across conditions) \\n to achieve high cooperation\", y=1.02)\n",
    "\n",
    "format_grid(trans_time_abs_ax, label=\"(D)\")\n",
    "\n",
    "\n",
    "fig.savefig(f\"figures/pinhead_model_stats.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc1c112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b72b35f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_exp_length_dist, _ = length_prob_distros([trough[\"length\"] for trough in flatten(p_exp_trough_props)], bins=None, bin_size=100)\n",
    "p_con_length_dist, _ = length_prob_distros([trough[\"length\"] for trough in flatten(p_con_trough_props)], bins=None, bin_size=100)\n",
    "\n",
    "longer_dim = max(len(p_exp_length_dist), len(p_con_length_dist))\n",
    "\n",
    "p_exp_length_dist = extend_dim((longer_dim), p_exp_length_dist)\n",
    "p_con_length_dist = extend_dim((longer_dim), p_con_length_dist)\n",
    "\n",
    "\n",
    "print(p_exp_length_dist) #[4:].sum())\n",
    "print(p_con_length_dist) #[4:].sum())\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "ax.plot([i * 500 for i in range(len(p_exp_length_dist))], p_exp_length_dist)\n",
    "ax.plot([i * 500 for i in range(len(p_con_length_dist))], p_con_length_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d8f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba2a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coop_p_min_arr = np.array(coop_levels_pres_min).reshape(-1, 1)\n",
    "coop_f_min_arr = np.array(coop_levels_futu_min).reshape(-1, 1)\n",
    "coop_p_min_arr_const = sm.add_constant(coop_p_min_arr)\n",
    "\n",
    "olsmod = sm.OLS(coop_f_min_arr, coop_p_min_arr_const)\n",
    "olsres = olsmod.fit()\n",
    "print(olsres.summary())\n",
    "\n",
    "coop_f_min_pred = olsres.predict(coop_p_min_arr_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f67640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_low = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for pres, futu in zip(coop_levels_pres_min, coop_levels_futu_min):\n",
    "    increment = np.array([[pres <= cutoff and futu <= cutoff, pres <= cutoff and futu > cutoff], [pres > cutoff and futu <= cutoff, pres > cutoff and futu > cutoff]])\n",
    "        \n",
    "    matrix_low += increment\n",
    "\n",
    "print(matrix_low)\n",
    "pct_matrix_low = matrix_low/matrix_low.sum(axis=1).reshape(2, 1)\n",
    "print(pct_matrix_low)\n",
    "print(pct_matrix_low)\n",
    "\n",
    "print(\"LOW CIVIC GROUPS\")\n",
    "print(\"Low coop groups that languished:\", matrix_low[0, 0]/(matrix_low[0, 0] + matrix_low[0, 1]))\n",
    "print(\"Low coop groups that rose:\", matrix_low[0, 1]/(matrix_low[0, 0] + matrix_low[0, 1]))\n",
    "print(\"High coop groups that fell:\", matrix_low[1, 0]/(matrix_low[1, 0] + matrix_low[1, 1]))\n",
    "print(\"High coop groups that maintained:\", matrix_low[1, 1]/(matrix_low[1, 0] + matrix_low[1, 1]))\n",
    "\n",
    "sd_matrix_low = np.sqrt(pct_matrix_low*(1 - pct_matrix_low)/matrix_low.sum(axis=1).reshape(2, 1))\n",
    "conf_matrix_low = sd_matrix_low*3.291\n",
    "print(conf_matrix_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_civ_nc_time_series(ind, data_dict, benefit, mig, run_length=20050, window=500)\n",
    "plot_civ_nc_time_series(6, \"spatial\", spatial_data_dict, 60, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print(char_trans)\n",
    "    \n",
    "    tot_spike_count, civ_start_count, civ_end_count, nc_start_count, nc_end_count, spike_prop_lists = compare_civ_nc_spikes(spike_lists, civ_spike_lists, nc_spike_lists)\n",
    "    trans_mat = construct_markov_process(spike_lists, spike_prop_lists)\n",
    "    lengths, counts = get_avg_length_of_each_type(spike_prop_lists)\n",
    "    print(lengths, counts, lengths / counts)\n",
    "    \n",
    "    print(trans_mat)\n",
    "    \n",
    "    _, tot_avg_spike, _, tot_avg_drop = calc_average_spike_drop_across_runs(coop_lists, spike_lists, 200, extension=100)\n",
    "    _, nc_avg_spike, _, nc_avg_drop = calc_average_spike_drop_across_runs(nc_coop_lists, spike_lists, 200, extension=100)\n",
    "    _, civ_avg_spike, _, civ_avg_drop = calc_average_spike_drop_across_runs(civ_coop_lists, spike_lists, 200, extension=100)\n",
    "    \n",
    "    fig1, ax1 = plt.subplots(1)\n",
    "    fig2, ax2 = plt.subplots(1)\n",
    "    \n",
    "    coop_mean = sum([elt for coop_list in coop_lists for elt in coop_list]) / sum([len(coop_list) for coop_list in coop_lists])\n",
    "    ax1.hlines(y=coop_mean, xmin=0, xmax=len(tot_avg_spike), color=dark)\n",
    "    ax1.plot(range(len(tot_avg_spike)), civ_avg_spike, color=turq)\n",
    "    ax1.plot(range(len(tot_avg_spike)), tot_avg_spike, color=med)\n",
    "    ax1.plot(range(len(tot_avg_spike)), nc_avg_spike, color=red)\n",
    "    \n",
    "    ax2.hlines(y=coop_mean, xmin=0, xmax=len(tot_avg_spike), color=dark)\n",
    "    ax2.plot(range(len(tot_avg_drop)), civ_avg_drop, color=turq)\n",
    "    ax2.plot(range(len(tot_avg_drop)), tot_avg_drop, color=med)\n",
    "    ax2.plot(range(len(tot_avg_drop)), nc_avg_drop, color=red)\n",
    "    \n",
    "    fig, ((hist1, hist2), (hist3, hist4), (hist5, hist6)) = plt.subplots(nrows=3, ncols=2)\n",
    "\n",
    "    \n",
    "    hist1.hist([prop[\"avg_val\"] for prop in spike_props_civ])\n",
    "    print(\"average civic coop val on peak\", calc_mean_sd_se([prop[\"avg_val\"] for prop in spike_props_civ]))\n",
    "    \n",
    "    hist3.hist([prop[\"avg_val\"] for prop in trough_props_civ])\n",
    "    print(\"average civic coop val on trough\", calc_mean_sd_se([prop[\"avg_val\"] for prop in trough_props_civ]))\n",
    "    \n",
    "    hist5.hist([prop[\"peak_index\"] for prop in spike_props_civ])\n",
    "    print(\"average civic peak index\", calc_mean_sd_se([prop[\"peak_index\"] for prop in spike_props_civ]))\n",
    "    \n",
    "    hist2.hist([prop[\"avg_val\"] for prop in spike_props_nc])\n",
    "    print(\"average nc coop val on peak\", calc_mean_sd_se([prop[\"avg_val\"] for prop in spike_props_nc]))\n",
    "    \n",
    "    hist4.hist([prop[\"avg_val\"] for prop in trough_props_nc])\n",
    "    print(\"average nc coop val on trough\", calc_mean_sd_se([prop[\"avg_val\"] for prop in trough_props_nc]))\n",
    "    \n",
    "    hist6.hist([prop[\"peak_index\"] for prop in spike_props_nc])\n",
    "    print(\"average nc peak index\", calc_mean_sd_se([prop[\"peak_index\"] for prop in spike_props_nc]))\n",
    "    \n",
    "    \n",
    "    # INCLUDE: plot for showing when peaks occur on various runs\n",
    "    trace_fig, (trace_ax0, trace_ax1) = plt.subplots(nrows=2, ncols=1)\n",
    "    \n",
    "    dot_color_dict = {\"civciv\": turq, \"civnci\": med, \"nciciv\": dark, \"ncinci\": red}\n",
    "    \n",
    "    for i, (spike_list, spike_prop_list) in enumerate(zip(spike_lists, spike_prop_lists)):\n",
    "        for spike, prop in zip(spike_list, spike_prop_list):\n",
    "            color = civ_nci_dict_lookup(dot_color_dict, prop)\n",
    "            trace_ax0.plot(spike, [i, i], color=med, zorder=3)\n",
    "    \n",
    "    for i, spike_list in enumerate(c_spike_lists):\n",
    "        for spike in spike_list:\n",
    "            trace_ax1.plot(spike, [i, i], color=med, zorder=3)\n",
    "    \n",
    "    exp_trough_lengths = [prop[\"length\"] for prop in trough_props_tot]\n",
    "    con_trough_lengths = [prop[\"length\"] for prop in c_trough_props]\n",
    "    exp_spike_lengths = [prop[\"length\"] for prop in spike_props_tot]\n",
    "    con_spike_lengths = [prop[\"length\"] for prop in c_spike_props]\n",
    "    \n",
    "    print(\"---\\nINCLUDE.\")\n",
    "    print(\"Noteworthy: the variance of the trough length is much higher. Also, peaks are longer in the control, but var is similar.\")\n",
    "    print(\"average trough length exp\", calc_mean_sd_se(exp_trough_lengths))\n",
    "    print(\"average trough length control\", calc_mean_sd_se(con_trough_lengths))\n",
    "    print(\"average spike length exp\", calc_mean_sd_se(exp_spike_lengths))\n",
    "    print(\"average spike length control\", calc_mean_sd_se(con_spike_lengths))\n",
    "    print(\"---\")\n",
    "    \n",
    "    \n",
    "    print(\"average spike value exp\", calc_mean_sd_se([prop[\"avg_val\"] for prop in spike_props_tot]))\n",
    "    print(\"average spike value control\", calc_mean_sd_se([prop[\"avg_val\"] for prop in c_spike_props]))\n",
    "    \n",
    "    \n",
    "    print(\"average trough value exp\", calc_mean_sd_se([prop[\"avg_val\"] for prop in trough_props_tot]))\n",
    "    print(\"average trough value control\", calc_mean_sd_se([prop[\"avg_val\"] for prop in c_trough_props]))\n",
    "    print(\"----\")\n",
    "    print(\"average spike length civ\", calc_mean_sd_se([prop[\"length\"] for prop in civ_spike_props]))\n",
    "    print(\"average spike length nc\", calc_mean_sd_se([prop[\"length\"] for prop in nc_spike_props]))\n",
    "    print(\"average spike value civ\", calc_mean_sd_se([prop[\"avg_val\"] for prop in civ_spike_props]))\n",
    "    print(\"average spike value nc\", calc_mean_sd_se([prop[\"avg_val\"] for prop in nc_spike_props]))\n",
    "    \n",
    "    print(\"average trough length civ\", calc_mean_sd_se([prop[\"length\"] for prop in civ_trough_props]))\n",
    "    print(\"average trough length nc\", calc_mean_sd_se([prop[\"length\"] for prop in nc_trough_props]))\n",
    "    print(\"average trough value civ\", calc_mean_sd_se([prop[\"avg_val\"] for prop in civ_spike_props]))\n",
    "    print(\"average trough value nc\", calc_mean_sd_se([prop[\"avg_val\"] for prop in nc_trough_props]))\n",
    "    \n",
    "    print([length for length in con_trough_lengths if length > 2000])\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19651414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(row_norm)\n",
    "G=nx.MultiDiGraph()\n",
    "\n",
    "G.add_node(0,pos=(0,8))\n",
    "G.add_node(1,pos=(2,6))\n",
    "G.add_node(2,pos=(6,6))\n",
    "G.add_node(3,pos=(2,2))\n",
    "G.add_node(4,pos=(6,2))\n",
    "\n",
    "\n",
    "\n",
    "pos=nx.get_node_attributes(G,'pos')\n",
    "\n",
    "for i, row in enumerate(row_norm):\n",
    "    for j, elt in enumerate(row):\n",
    "        if elt > 0.05 and i != j:\n",
    "            G.add_edge(i,j, weight=(str(round(elt * 100)) + \"%\"))\n",
    "            \n",
    "labels = nx.get_edge_attributes(G,'weight')\n",
    "labels = {(start, end): labels[(start, end, 0)] for start, end, _ in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461a25c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nx.draw_networkx(G, pos, connectionstyle='arc3, rad = 0.1')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, label_pos=0.25)\n",
    "\"\"\"\n",
    "g = pn.Network('500px', '500px', directed=True, notebook=True)\n",
    "g.add_nodes([0,1,2,3,4], value=[100, 100, 100, 100, 100],\n",
    "                         title=['', '', '', '',''],\n",
    "                         x=[-150, -50, -50, 150, 150],\n",
    "                         y=[-150, -50, 150, -50, 150],\n",
    "                         label=['0', '1', '2', '3', '4'],\n",
    "                         color=['#dd4b39', '#dd4b39', '#dd4b39', '#dd4b39', '#dd4b39'])\n",
    "\n",
    "for n in g.nodes:\n",
    "    n.update({'physics': False})\n",
    "\n",
    "for i, row in enumerate(row_norm):\n",
    "    for j, elt in enumerate(row):\n",
    "        if elt > 0.05 and i != j:\n",
    "            weight = round(100 * elt)\n",
    "            g.add_edge(i, j, weight=weight, label=str(weight))\n",
    "\n",
    "g.show_buttons()\n",
    "\n",
    "g.show('nx.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for i, benefit in enumerate(benefits):\n",
    "    bp_data = []\n",
    "    for distrib in [0.0, 0.02]:\n",
    "        if distrib == 0.0:\n",
    "            bp_data.append(data_dict[distrib][benefit][\"coop_levels\"])\n",
    "        else:\n",
    "            bp_data.append(data_dict[distrib][benefit][\"nc_coop_levels\"])\n",
    "            bp_data.append(data_dict[distrib][benefit][\"coop_levels\"])\n",
    "    \n",
    "    bp = ax.boxplot(bp_data,\n",
    "                positions=[i * 4, i * 4 + 1, i * 4 + 2],\n",
    "                patch_artist=True,\n",
    "               notch=True,\n",
    "                showfliers=False, showmeans=True, meanprops=meanprops, medianprops=medianprops, flierprops=flierprops)\n",
    "    \n",
    "    ax.text(i * 4 + 1, bp[\"whiskers\"][3].get_data()[1][1] + 0.01, nc_sig_labels[i], ha=\"center\", va=\"center\")\n",
    "    ax.text(i * 4 + 2, bp[\"whiskers\"][5].get_data()[1][1] + 0.01, sig_labels[i], ha=\"center\", va=\"center\")\n",
    "    set_box_colors(bp, color_range=[red, dark, turq])\n",
    "\n",
    "ax.legend([bp[\"boxes\"][0], bp[\"boxes\"][1], bp[\"boxes\"][2]], ['No conscience, total', 'With conscience, non-conscience', \"With conscience, total\"], loc='lower right')\n",
    "\n",
    "ax.set_xticks([1, 5, 9, 13, 17])\n",
    "ax.set_xticklabels([benefit/20 for benefit in benefits])\n",
    "ax.set_ylim(bottom=0, top=1)\n",
    "ax.set_ylabel(\"Cooperation fraction\")\n",
    "ax.set_title(\"Cooperation fraction vs. benefit to cost\", y=1.02)\n",
    "ax.set_xlabel(\"Benefit to cost\")\n",
    "format_grid(ax, label=\"(B)\")\n",
    "\n",
    "fig.savefig(\"figures/spatial_mean_coop.png\", bbox_inches=\"tight\")\n",
    "fig.savefig(\"figures/spatial_mean_coop.svg\", bbox_inches=\"tight\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
